{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71cfc538",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6c71794d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "data1 = pd.read_csv(\"concrete-data1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "60e1394c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Cement</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAsh</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>CoarseAggregate</th>\n",
       "      <th>FineAggregate</th>\n",
       "      <th>Age</th>\n",
       "      <th>CC_Strength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>45.856716</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>45.856716</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>45.856716</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1025</td>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1026</td>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1027</td>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1028</td>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1029</td>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1005 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  Cement  BlastFurnaceSlag  FlyAsh  Water  Superplasticizer   \n",
       "0              0   540.0               0.0     0.0  162.0               2.5  \\\n",
       "1              1   540.0               0.0     0.0  162.0               2.5   \n",
       "2              2   332.5             142.5     0.0  228.0               0.0   \n",
       "3              3   332.5             142.5     0.0  228.0               0.0   \n",
       "4              4   198.6             132.4     0.0  192.0               0.0   \n",
       "...          ...     ...               ...     ...    ...               ...   \n",
       "1000        1025   276.4             116.0    90.3  179.6               8.9   \n",
       "1001        1026   322.2               0.0   115.6  196.0              10.4   \n",
       "1002        1027   148.5             139.4   108.6  192.7               6.1   \n",
       "1003        1028   159.1             186.7     0.0  175.6              11.3   \n",
       "1004        1029   260.9             100.5    78.3  200.6               8.6   \n",
       "\n",
       "      CoarseAggregate  FineAggregate        Age  CC_Strength  \n",
       "0              1040.0          676.0  28.000000    79.986111  \n",
       "1              1055.0          676.0  28.000000    61.887366  \n",
       "2               932.0          594.0  45.856716    40.269535  \n",
       "3               932.0          594.0  45.856716    41.052780  \n",
       "4               978.4          825.5  45.856716    44.296075  \n",
       "...               ...            ...        ...          ...  \n",
       "1000            870.1          768.3  28.000000    44.284354  \n",
       "1001            817.9          813.4  28.000000    31.178794  \n",
       "1002            892.4          780.0  28.000000    23.696601  \n",
       "1003            989.6          788.9  28.000000    32.768036  \n",
       "1004            864.5          761.5  28.000000    32.401235  \n",
       "\n",
       "[1005 rows x 10 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a71adcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0670607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc9b19d",
   "metadata": {},
   "source": [
    "# data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88044273",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['Unnamed: 0','CC_Strength'], axis = 1)\n",
    "Y = data['CC_Strength']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b3c9e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2, random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f50a6f",
   "metadata": {},
   "source": [
    "# min max scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de5a1900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import preprocessing\n",
    "# scaler = preprocessing.MinMaxScaler()\n",
    "# minmax = scaler.fit_transform(X)\n",
    "# minmax = pd.DataFrame(minmax, columns =['Cement','BlastFurnaceSlag','FlyAsh','Water','Superplasticizer','CoarseAggregate','FineAggregate','Age'])                          "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d78f4",
   "metadata": {},
   "source": [
    "# standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "68780477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler()\n",
    "# standard = scaler.fit_transform(X)\n",
    "# standard = pd.DataFrame(standard, columns =['Cement','BlastFurnaceSlag','FlyAsh','Water','Superplasticizer','CoarseAggregate','FineAggregate','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "91871636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\033[1m'+'Without scaling:'+'\\033[0m')\n",
    "# display(X.head())\n",
    "# print('*' * 45)\n",
    "# print('\\033[1m'+'With minmax scaling:'+'\\033[0m')\n",
    "# display(minmax.head())\n",
    "# print('*' * 45)\n",
    "# print('\\033[1m'+'With standard scaling:'+'\\033[0m')\n",
    "# display(standard.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586842c3",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6957b",
   "metadata": {},
   "source": [
    "#LDA is for supervised.\n",
    "#PCA is for unsupervised with huge number of features , not for regression better to use classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "11b4abb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #dimensionality reduction on train data.\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA()\n",
    "# pca2=PCA(n_components=4)\n",
    "# x_pca2=pca.fit_transform(X)\n",
    "# x_pca2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be151e30",
   "metadata": {},
   "source": [
    "# linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "6dcdb7a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.54582091, 36.40025678, 50.98376853, 44.07065537, 21.36177305,\n",
       "       48.28519984, 40.97640362, 26.69434974, 22.25374315, 22.1763818 ,\n",
       "       59.09258219, 20.77824919, 40.88195871, 28.54763747, 27.66308925,\n",
       "       13.4316615 , 56.60310016, 58.65337316, 44.59637523, 34.46760758,\n",
       "       26.37470873, 35.98960306, 49.39590858, 39.66436745, 40.44873663,\n",
       "       33.03089903, 55.56367474, 21.62268565, 16.26477736, 50.00745214,\n",
       "       30.40090802, 35.35988327, 55.93171623, 48.55243644, 17.85013486,\n",
       "       18.76553025, 48.90679669, 56.87605094, 20.12942048, 30.45516482,\n",
       "       52.3950891 , 31.79768245, 35.10389153, 19.28100751, 21.05780416,\n",
       "       31.17320431, 23.65989935, 33.98850974, 44.53406873, 31.3615508 ,\n",
       "       55.34716407, 46.38347762, 42.21036593, 36.82122099, 54.46707597,\n",
       "       30.20324666, 41.41308198, 23.60522398, 32.20623147, 36.21976438,\n",
       "       29.05778384, 27.72561594, 46.46980713, 31.1379558 , 27.54011833,\n",
       "       58.03202825, 38.46657079, 27.23933293, 28.7654591 , 50.41988049,\n",
       "       54.86997476, 31.35373905, 63.63213067, 49.18635165, 47.39952739,\n",
       "       48.47892302, 30.12217163, 44.35639125, 30.52216586, 35.131054  ,\n",
       "       33.60737541, 41.21900524, 34.18722016, 33.86404771, 62.18154978,\n",
       "       29.89278815, 39.42353485, 49.9065899 , 36.72684216, 24.25534844,\n",
       "       20.27047918, 18.71215842, 42.78922264, 44.3457563 , 36.72684216,\n",
       "       30.57176688, 52.06724011, 27.99684721, 34.84377544, 73.94420236,\n",
       "       26.01031681, 15.26800413, 48.6991476 , 31.32049314, 57.85236734,\n",
       "       15.75299808, 63.63213067, 47.99116233, 26.60494363, 48.41946689,\n",
       "       27.68902379, 71.7084703 , 28.43913925, 27.6534133 , 48.67301055,\n",
       "       48.35936588, 77.38098512, 49.65782145, 47.1319929 , 45.60730479,\n",
       "       36.40600641, 18.6291581 , 33.21909858, 37.6772221 , 40.78699169,\n",
       "       55.95196699, 18.53987348, 26.98323331, 11.68088772, 27.50291276,\n",
       "       39.15909074, 33.84873447, 56.33109932, 41.58518578, 25.8929822 ,\n",
       "       25.42189312, 44.39666772, 34.42835433, 27.89576354, 29.90992543,\n",
       "       39.9366936 , 31.23540702, 31.63772072, 16.67591326, 24.28166587,\n",
       "       35.98066429, 50.7817922 , 29.61490225, 45.33306924, 27.77215141,\n",
       "       48.58097175, 19.51212044, 18.00842634, 60.3831218 , 27.5574986 ,\n",
       "       26.83280902, 27.24787467, 19.27097989, 44.85300983, 57.59155718,\n",
       "       21.82405565, 18.1878505 , 68.56040108, 21.56560216, 42.35764989,\n",
       "       53.30007881, 26.60540919, 13.27786061, 41.13313009, 42.60189273,\n",
       "       51.93187669, 44.53214202, 17.96834832, 77.48184736, 34.5154468 ,\n",
       "       34.8071028 , 45.15804647, 33.197517  , 50.3049293 , 43.70261492,\n",
       "       42.37017353, 45.1615026 , 27.62723411, 59.2665033 , 41.09906985,\n",
       "       33.27341868, 48.00433622, 26.66687209, 27.61602222, 24.25342173,\n",
       "       41.4809181 , 13.38201002, 18.02484818, 54.12218655, 18.46409973,\n",
       "       54.12218655, 10.95167616, 19.47650996, 28.15754849, 64.67538801,\n",
       "       52.0617154 ])"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear=LinearRegression()\n",
    "linear.fit(X_train,Y_train)\n",
    "y_pred=linear.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c897f724",
   "metadata": {},
   "source": [
    "# cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4feb780e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold:1, Train set: 804, Test set:201\n",
      "Fold:2, Train set: 804, Test set:201\n",
      "Fold:3, Train set: 804, Test set:201\n",
      "Fold:4, Train set: 804, Test set:201\n",
      "Fold:5, Train set: 804, Test set:201\n"
     ]
    }
   ],
   "source": [
    "kf =KFold(n_splits=5, shuffle=True, random_state=None)\n",
    "\n",
    "cnt = 1\n",
    "# split()  method generate indices to split data into training and test set.\n",
    "for train_index, test_index in kf.split(X, Y):\n",
    "    print(f'Fold:{cnt}, Train set: {len(train_index)}, Test set:{len(test_index)}')\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdb6553",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6762de8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.70963611 0.72600497 0.70246729 0.77243859 0.73297459]\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression (CROSS VALIDATION)\n",
    "#from sklearn.metrics import rmse\n",
    "from sklearn import linear_model\n",
    "score1 = cross_val_score(linear_model.LinearRegression(), X, Y, cv= kf)\n",
    "print(f'Scores for each fold: {score1}')\n",
    "#rmse(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "37c55b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7287043085848597"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = score1.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f88f9",
   "metadata": {},
   "source": [
    "# Linear Regressor with hyper tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2f7678f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.70511234 0.71243708 0.75674595 0.76938266 0.70771305]\n",
      "0.7302782146035027\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression (CROSS VALIDATION)\n",
    "#from sklearn.metrics import rmse\n",
    "from sklearn import linear_model\n",
    "score1 = cross_val_score(linear_model.LinearRegression(fit_intercept=True,\n",
    "    copy_X=True,\n",
    "    n_jobs=None,\n",
    "    positive=False,), X, Y, cv= kf)\n",
    "print(f'Scores for each fold: {score1}')\n",
    "print(score1.mean())\n",
    "#rmse(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8eebf073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302782146035027"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = score1.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "eb0fe0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b00d6",
   "metadata": {},
   "source": [
    "# XG Boost regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecd2f8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.91073134 0.91774294 0.92984509 0.90881646 0.93967411]\n",
      "0.9213619887473035\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "scores = cross_val_score(xgb.XGBRegressor(), X, Y, cv= kf)\n",
    "print(f'Scores for each fold: {scores}')\n",
    "print(scores.mean())\n",
    "#rmse(score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959574c8",
   "metadata": {},
   "source": [
    "# DT Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6e5d8d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.80058973 0.82648499 0.82434469 0.81890199 0.81033514]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regressor(CROSS VALIDATION)\n",
    "from sklearn import tree\n",
    "score2 = cross_val_score(tree.DecisionTreeRegressor(random_state= None), X, Y, cv=kf)\n",
    "print(f'Scores for each fold: {score2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc17c750",
   "metadata": {},
   "source": [
    "# DT Regressor hyper tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96c356b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8161313088192899"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean1 = score2.mean()\n",
    "mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "98e5c180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.88787843 0.80987423 0.85305966 0.88040346 0.81218096]\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Regressor(CROSS VALIDATION)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import tree\n",
    "score2 = cross_val_score(tree.DecisionTreeRegressor(criterion='squared_error',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    random_state=None,\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    ccp_alpha=0.0,), X, Y, cv=kf)\n",
    "print(f'Scores for each fold: {score2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d14124a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8200715617777329"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean1 = score2.mean()\n",
    "mean1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef340cd",
   "metadata": {},
   "source": [
    "# RF Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8919c084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold are: [0.90233716 0.93672993 0.89609528 0.92623836 0.89112134]\n"
     ]
    }
   ],
   "source": [
    "# Random forest Regressor(CROSS VALIDATION)\n",
    "from sklearn import ensemble\n",
    "score3 = cross_val_score(ensemble.RandomForestRegressor(random_state= None), X, Y, cv= kf)\n",
    "print(f'Scores for each fold are: {score3}')\n",
    "#rmse(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e106147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9105044134065847\n"
     ]
    }
   ],
   "source": [
    "print(score3.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83d6aed",
   "metadata": {},
   "source": [
    "# RF Regressor hyper tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "1719eaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold are: [0.91204525 0.90577702 0.91289118 0.89602483 0.91150359]\n"
     ]
    }
   ],
   "source": [
    "# Random forest Regressor(CROSS VALIDATION)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn import ensemble\n",
    "score3 = cross_val_score(ensemble.RandomForestRegressor(n_estimators=100,\n",
    "    criterion='squared_error',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features='auto',\n",
    "    max_leaf_nodes=None,\n",
    "    min_impurity_decrease=0.0,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    n_jobs=None,random_state= None), X, Y, cv= kf)\n",
    "print(f'Scores for each fold are: {score3}')\n",
    "#rmse(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "0deefe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_acc = score3.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "df26a624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9076483759518496"
      ]
     },
     "execution_count": 609,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "13e7be18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8396e916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\dell\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install scikit-learn --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd53fcb",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ad88f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.2337925  0.21862004 0.2393278  0.23664418 0.20739122]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "score4 = cross_val_score(svm.SVR(), X, Y, cv=kf)\n",
    "print(f'Scores for each fold: {score4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "551fd0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22715514893259708"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean2 = score4.mean()\n",
    "mean2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384933ad",
   "metadata": {},
   "source": [
    "# svr with hyper tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0f4428fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for each fold: [0.69751682 0.69744965 0.7385234  0.74373136 0.73872237]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "score4 = cross_val_score(svm.SVR(kernel='linear',\n",
    "    degree=3,\n",
    "    gamma='scale',\n",
    "    coef0=1.0,\n",
    "    tol=1e-3,\n",
    "    C=1.0, epsilon=0.1,\n",
    "    shrinking=True,\n",
    "    cache_size=200,\n",
    "    verbose=False,\n",
    "    max_iter=-1,), X, Y, cv=kf)\n",
    "print(f'Scores for each fold: {score4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "abcb7b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7231887208747665"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean2 = score4.mean()\n",
    "mean2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec4275",
   "metadata": {},
   "source": [
    "# Grid search cv for all regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca8f92",
   "metadata": {},
   "source": [
    "# gridsearch for RFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c88e1be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c9bbe8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d067dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "parameters = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [1,2],\n",
    "    'min_samples_split': [2,4],\n",
    "    'min_samples_leaf': [1,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "04178660",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(rfr, param_grid = parameters, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "46b9864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 2], &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [150, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [1, 2], &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                         &#x27;n_estimators&#x27;: [150, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': [1, 2], 'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 4],\n",
       "                         'n_estimators': [150, 200]})"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "f0c3c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_score=cross_val_score(clf,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "2dd93bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.17656583,  0.39167453,  0.4623168 ,  0.23420689, -1.70627775])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cd3c7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.523401651731732\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'max_depth': 2, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\", clf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f61bd0",
   "metadata": {},
   "source": [
    "# Grid search for GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "925cf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "21502737",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "f1159fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " parameters1 = {'learning_rate': [0.01,0.02],\n",
    "                  'subsample'    : [0.9, 0.5],\n",
    "                  'n_estimators' : [50,100],\n",
    "                  'max_depth'    : [4,6]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c2773dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GBR = GridSearchCV(GBR, param_grid = parameters1, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "394ef3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02], &#x27;max_depth&#x27;: [4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;subsample&#x27;: [0.9, 0.5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=GradientBoostingRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02], &#x27;max_depth&#x27;: [4, 6],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100], &#x27;subsample&#x27;: [0.9, 0.5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=GradientBoostingRegressor(),\n",
       "             param_grid={'learning_rate': [0.01, 0.02], 'max_depth': [4, 6],\n",
       "                         'n_estimators': [50, 100], 'subsample': [0.9, 0.5]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2ae4cfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GBR_score=cross_val_score(grid_GBR,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ec0b2766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.69163517,  0.70459489,  0.74255792,  0.74490996, -0.71997813])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_GBR_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "6fdf5e00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8712027860410358\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 0.02, 'max_depth': 6, 'n_estimators': 100, 'subsample': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_GBR.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_GBR.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20a8a23",
   "metadata": {},
   "source": [
    "# grid search for DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "461693e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2d5d6274",
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_tree = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a126c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters2 = {'max_depth': [1,2,3],\n",
    "               'criterion': ['squared_error', \"friedman_mse\", \"absolute_error\"],\n",
    "               'min_samples_split': [2,3,4],\n",
    "               'min_samples_leaf': [1,2,3],\n",
    "               'splitter': [\"best\", \"random\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "d8554df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dtr = GridSearchCV(dec_tree, param_grid = parameters2, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f8cd258b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3], &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;, &#x27;friedman_mse&#x27;,\n",
       "                                       &#x27;absolute_error&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [1, 2, 3], &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                         &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                       'absolute_error'],\n",
       "                         'max_depth': [1, 2, 3], 'min_samples_leaf': [1, 2, 3],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtr.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "90297b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dtr_score=cross_val_score(grid_dtr,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "77358598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16148646,  0.39140556,  0.37025977,  0.46993799, -1.84897516])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bcc5ef0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.5662628323921366\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'criterion': 'squared_error', 'max_depth': 3, 'min_samples_leaf': 1, 'min_samples_split': 4, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_dtr.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_dtr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809cb67",
   "metadata": {},
   "source": [
    "# grid search for xgb reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7fd4a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "800e6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "817f708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters3 = {'n_estimators':[100,500,1000], \n",
    "              'learning_rate': [.03, 0.05, .07],\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'subsample': [0.7,0.8,0.9],\n",
    "              'colsample_bytree': [0.7,0.8,0.9]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "19eaea36",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb = GridSearchCV(xgb, param_grid = parameters3, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "358799b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    in...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [0.03, 0.05, 0.07],\n",
       "                         &#x27;max_depth&#x27;: [5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.7, 0.8, 0.9]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    in...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                         &#x27;learning_rate&#x27;: [0.03, 0.05, 0.07],\n",
       "                         &#x27;max_depth&#x27;: [5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                         &#x27;subsample&#x27;: [0.7, 0.8, 0.9]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    in...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                         'learning_rate': [0.03, 0.05, 0.07],\n",
       "                         'max_depth': [5, 6, 7],\n",
       "                         'n_estimators': [100, 500, 1000],\n",
       "                         'subsample': [0.7, 0.8, 0.9]})"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "000074b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb_score=cross_val_score(grid_xgb,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "12ad1a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76323945,  0.71759528,  0.76805702,  0.84957329, -0.39450955])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "0c6bd3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.9274317283176737\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'colsample_bytree': 0.7, 'learning_rate': 0.03, 'max_depth': 5, 'n_estimators': 1000, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_xgb.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77efb28",
   "metadata": {},
   "source": [
    "# grid search ridge regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "0e9cd980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "ridge_reg = Ridge()\n",
    "params_Ridge = {'alpha': [1,0.1,0.01,0.0001] ,\n",
    "                \"fit_intercept\": [True, False], \n",
    "                \"solver\": ['cholesky', 'lsqr', 'sparse_cg', 'sag']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "72d0cb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS = GridSearchCV(ridge_reg, param_grid=params_Ridge, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f4ab5d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 0.1, 0.01, 0.0001],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;solver&#x27;: [&#x27;cholesky&#x27;, &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1, 0.1, 0.01, 0.0001],\n",
       "                         &#x27;fit_intercept&#x27;: [True, False],\n",
       "                         &#x27;solver&#x27;: [&#x27;cholesky&#x27;, &#x27;lsqr&#x27;, &#x27;sparse_cg&#x27;, &#x27;sag&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Ridge(),\n",
       "             param_grid={'alpha': [1, 0.1, 0.01, 0.0001],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'solver': ['cholesky', 'lsqr', 'sparse_cg', 'sag']})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_GS.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "148d0af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_GS_score=cross_val_score(Ridge_GS,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bbc3ddd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53876254, 0.62773638, 0.66982563, 0.74609971, 0.53624354])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ridge_GS_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "99ec9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.7397215669299697\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'alpha': 1, 'fit_intercept': True, 'solver': 'sag'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",Ridge_GS.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",Ridge_GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add5f3b0",
   "metadata": {},
   "source": [
    "# grid search lasso regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "85ff6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "lasso = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d14c7f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters4 = {'alpha': [1.0,2.0],\n",
    "               'max_iter': [1000,2000],\n",
    "               'tol': [0.0001,0.01],\n",
    "               'selection': ['cyclic','random']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5df9d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lasso = GridSearchCV(lasso, param_grid = parameters4, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d43ecca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-20 {color: black;background-color: white;}#sk-container-id-20 pre{padding: 0;}#sk-container-id-20 div.sk-toggleable {background-color: white;}#sk-container-id-20 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-20 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-20 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-20 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-20 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-20 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-20 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-20 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-20 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-20 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-20 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-20 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-20 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-20 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-20 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-20 div.sk-item {position: relative;z-index: 1;}#sk-container-id-20 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-20 div.sk-item::before, #sk-container-id-20 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-20 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-20 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-20 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-20 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-20 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-20 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-20 div.sk-label-container {text-align: center;}#sk-container-id-20 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-20 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-20\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0, 2.0], &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                         &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                         &#x27;tol&#x27;: [0.0001, 0.01]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Lasso(),\n",
       "             param_grid={&#x27;alpha&#x27;: [1.0, 2.0], &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                         &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                         &#x27;tol&#x27;: [0.0001, 0.01]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-59\" type=\"checkbox\" ><label for=\"sk-estimator-id-59\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-60\" type=\"checkbox\" ><label for=\"sk-estimator-id-60\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=Lasso(),\n",
       "             param_grid={'alpha': [1.0, 2.0], 'max_iter': [1000, 2000],\n",
       "                         'selection': ['cyclic', 'random'],\n",
       "                         'tol': [0.0001, 0.01]})"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "d5858025",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lasso_score=cross_val_score(grid_lasso,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "877f0c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54730031, 0.62049062, 0.66508444, 0.72954657, 0.54902738])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_lasso_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1bd891a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.7411421678166418\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'alpha': 1.0, 'max_iter': 1000, 'selection': 'cyclic', 'tol': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_lasso.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6a91a",
   "metadata": {},
   "source": [
    "# grid search for KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "18a9c6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "fc5d8f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0c80a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters5 = {'n_neighbors': [5,8],\n",
    "               'weights': ['uniform','distance'],\n",
    "               'algorithm': ['auto', 'ball_tree'],\n",
    "               'leaf_size': [30,50],\n",
    "               'p': [2,4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ac7bba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn = GridSearchCV(knn, param_grid = parameters5, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ecca30db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-21 {color: black;background-color: white;}#sk-container-id-21 pre{padding: 0;}#sk-container-id-21 div.sk-toggleable {background-color: white;}#sk-container-id-21 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-21 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-21 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-21 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-21 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-21 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-21 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-21 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-21 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-21 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-21 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-21 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-21 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-21 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-21 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-21 div.sk-item {position: relative;z-index: 1;}#sk-container-id-21 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-21 div.sk-item::before, #sk-container-id-21 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-21 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-21 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-21 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-21 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-21 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-21 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-21 div.sk-label-container {text-align: center;}#sk-container-id-21 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-21 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-21\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;],\n",
       "                         &#x27;leaf_size&#x27;: [30, 50], &#x27;n_neighbors&#x27;: [5, 8],\n",
       "                         &#x27;p&#x27;: [2, 4], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-61\" type=\"checkbox\" ><label for=\"sk-estimator-id-61\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=KNeighborsRegressor(),\n",
       "             param_grid={&#x27;algorithm&#x27;: [&#x27;auto&#x27;, &#x27;ball_tree&#x27;],\n",
       "                         &#x27;leaf_size&#x27;: [30, 50], &#x27;n_neighbors&#x27;: [5, 8],\n",
       "                         &#x27;p&#x27;: [2, 4], &#x27;weights&#x27;: [&#x27;uniform&#x27;, &#x27;distance&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-62\" type=\"checkbox\" ><label for=\"sk-estimator-id-62\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-63\" type=\"checkbox\" ><label for=\"sk-estimator-id-63\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=KNeighborsRegressor(),\n",
       "             param_grid={'algorithm': ['auto', 'ball_tree'],\n",
       "                         'leaf_size': [30, 50], 'n_neighbors': [5, 8],\n",
       "                         'p': [2, 4], 'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "597ea180",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_knn_score=cross_val_score(grid_knn,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "bd40f86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.37285786,  0.10115036,  0.42655009,  0.53005179, -0.11549247])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_knn_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "ed913905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.716899271712853\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'algorithm': 'ball_tree', 'leaf_size': 50, 'n_neighbors': 5, 'p': 2, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_knn.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_knn.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3524f84",
   "metadata": {},
   "source": [
    "# grid search for Adaboost reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "151706d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "60de2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "5f740487",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters6 = {'n_estimators': [50,100],\n",
    "              'learning_rate': [1.0,2.0],\n",
    "              'loss' : ['linear', 'square']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "e8a37f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada = GridSearchCV(Ada, param_grid = parameters6, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "9abdcc0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-22 {color: black;background-color: white;}#sk-container-id-22 pre{padding: 0;}#sk-container-id-22 div.sk-toggleable {background-color: white;}#sk-container-id-22 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-22 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-22 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-22 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-22 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-22 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-22 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-22 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-22 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-22 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-22 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-22 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-22 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-22 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-22 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-22 div.sk-item {position: relative;z-index: 1;}#sk-container-id-22 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-22 div.sk-item::before, #sk-container-id-22 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-22 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-22 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-22 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-22 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-22 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-22 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-22 div.sk-label-container {text-align: center;}#sk-container-id-22 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-22 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-22\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=AdaBoostRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [1.0, 2.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-64\" type=\"checkbox\" ><label for=\"sk-estimator-id-64\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=AdaBoostRegressor(),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [1.0, 2.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-65\" type=\"checkbox\" ><label for=\"sk-estimator-id-65\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-66\" type=\"checkbox\" ><label for=\"sk-estimator-id-66\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=AdaBoostRegressor(),\n",
       "             param_grid={'learning_rate': [1.0, 2.0],\n",
       "                         'loss': ['linear', 'square'],\n",
       "                         'n_estimators': [50, 100]})"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ada.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9b8898b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ada_score=cross_val_score(grid_ada,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bd672c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62682374,  0.67917195,  0.65149571,  0.66537397, -0.3172811 ])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ada_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "437b1158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.7995619680783201\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'learning_rate': 2.0, 'loss': 'linear', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_ada.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_ada.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390e74d",
   "metadata": {},
   "source": [
    "# Random search cv for all regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9100d80e",
   "metadata": {},
   "source": [
    "# Random search RF Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cc7d4d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "93a90446",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a6e0fe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "parameters7 = {\n",
    "    'n_estimators': [150, 200],\n",
    "    'max_depth': [1,2],\n",
    "    'min_samples_split': [2,4],\n",
    "    'min_samples_leaf': [1,2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8c70f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_rfr = RandomizedSearchCV(RFR, param_distributions = parameters7, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6d3f4f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=RandomForestRegressor(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=RandomForestRegressor(),\n",
       "                   param_distributions={&#x27;max_depth&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [150, 200]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=RandomForestRegressor(),\n",
       "                   param_distributions={'max_depth': [1, 2],\n",
       "                                        'min_samples_leaf': [1, 2],\n",
       "                                        'min_samples_split': [2, 4],\n",
       "                                        'n_estimators': [150, 200]})"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rfr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b63d8165",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_rfr_score=cross_val_score(rand_rfr,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5544876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.18496783,  0.41776427,  0.44892178,  0.22169945, -1.75391013])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_rfr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1d7bb91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.5426752000704826\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_rfr.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_rfr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77692d",
   "metadata": {},
   "source": [
    "# Random search GBR Reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec616cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBR1 = GradientBoostingRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4e9bfde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters8 = {'learning_rate': [0.01,0.02],\n",
    "                  'subsample'    : [0.9, 0.5],\n",
    "                  'n_estimators' : [50,100],\n",
    "                  'max_depth'    : [4,6]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "742b5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gbr = RandomizedSearchCV(GBR1, param_distributions = parameters8, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7f3601da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=GradientBoostingRegressor(),\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.02],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100],\n",
       "                                        &#x27;subsample&#x27;: [0.9, 0.5]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=GradientBoostingRegressor(),\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.01, 0.02],\n",
       "                                        &#x27;max_depth&#x27;: [4, 6],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100],\n",
       "                                        &#x27;subsample&#x27;: [0.9, 0.5]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=GradientBoostingRegressor(),\n",
       "                   param_distributions={'learning_rate': [0.01, 0.02],\n",
       "                                        'max_depth': [4, 6],\n",
       "                                        'n_estimators': [50, 100],\n",
       "                                        'subsample': [0.9, 0.5]})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_gbr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8da825b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_gbr_score=cross_val_score(rand_gbr,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "386819d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.68343451,  0.70917561,  0.73710987,  0.7482815 , -0.87657136])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_gbr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "96452d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8104851760692136\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'subsample': 0.5, 'n_estimators': 100, 'max_depth': 4, 'learning_rate': 0.02}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_gbr.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_gbr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc377d1",
   "metadata": {},
   "source": [
    "# random search for DTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8d0379e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTR = tree.DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c549736b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters9 = {'max_depth': [1,2,3],\n",
    "               'criterion': ['squared_error', \"friedman_mse\", \"absolute_error\"],\n",
    "               'min_samples_split': [2,3,4],\n",
    "               'min_samples_leaf': [1,2,3],\n",
    "               'splitter': [\"best\", \"random\"]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3e27f872",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dtr = RandomizedSearchCV(DTR, param_distributions = parameters9, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "134117a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                      &#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                                        &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(),\n",
       "                   param_distributions={&#x27;criterion&#x27;: [&#x27;squared_error&#x27;,\n",
       "                                                      &#x27;friedman_mse&#x27;,\n",
       "                                                      &#x27;absolute_error&#x27;],\n",
       "                                        &#x27;max_depth&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 3],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 3, 4],\n",
       "                                        &#x27;splitter&#x27;: [&#x27;best&#x27;, &#x27;random&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=DecisionTreeRegressor(),\n",
       "                   param_distributions={'criterion': ['squared_error',\n",
       "                                                      'friedman_mse',\n",
       "                                                      'absolute_error'],\n",
       "                                        'max_depth': [1, 2, 3],\n",
       "                                        'min_samples_leaf': [1, 2, 3],\n",
       "                                        'min_samples_split': [2, 3, 4],\n",
       "                                        'splitter': ['best', 'random']})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_dtr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "54e4d8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_dtr_score=cross_val_score(rand_dtr,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "afd059f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16148646,  0.39140556,  0.37025977,  0.46993799, -1.84897516])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_dtr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ed013b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.5824605941940553\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_dtr.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_dtr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afecdce",
   "metadata": {},
   "source": [
    "# Random search for xgboost reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "1505ff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "XGB = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "305db4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters10 = {'n_estimators':[100,500,1000], \n",
    "              'learning_rate': [.03, 0.05, .07],\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'subsample': [0.7,0.8,0.9],\n",
    "              'colsample_bytree': [0.7,0.8,0.9]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dc8ccdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_xgb = RandomizedSearchCV(XGB, param_distributions = parameters10, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "16fd49eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=N...\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.03, 0.05, 0.07],\n",
       "                                        &#x27;max_depth&#x27;: [5, 6, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.7, 0.8, 0.9]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=N...\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.7, 0.8, 0.9],\n",
       "                                        &#x27;learning_rate&#x27;: [0.03, 0.05, 0.07],\n",
       "                                        &#x27;max_depth&#x27;: [5, 6, 7],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 1000],\n",
       "                                        &#x27;subsample&#x27;: [0.7, 0.8, 0.9]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, gpu_id=None,\n",
       "                                          grow_policy=None,\n",
       "                                          importance_type=N...\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          max_leaves=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          predictor=None, random_state=None, ...),\n",
       "                   param_distributions={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                                        'learning_rate': [0.03, 0.05, 0.07],\n",
       "                                        'max_depth': [5, 6, 7],\n",
       "                                        'n_estimators': [100, 500, 1000],\n",
       "                                        'subsample': [0.7, 0.8, 0.9]})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_xgb.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7f3a3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_xgb_score=cross_val_score(rand_xgb,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cfa01b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77595637,  0.73821518,  0.73812132,  0.8487844 , -0.39718148])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_xgb_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ed4ab1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.5824605941940553\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'splitter': 'best', 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 3, 'criterion': 'friedman_mse'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_dtr.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_dtr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27885744",
   "metadata": {},
   "source": [
    "# Random search for Ridge reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "52bc9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "RR = Ridge()\n",
    "parameters11 = {'alpha': [1,0.1,0.01,0.0001] ,\n",
    "                \"fit_intercept\": [True, False], \n",
    "                \"solver\": ['cholesky', 'lsqr', 'sparse_cg', 'sag']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9bab88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ridge = RandomizedSearchCV(RR, param_distributions = parameters11, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "126ce0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Ridge(),\n",
       "                   param_distributions={&#x27;alpha&#x27;: [1, 0.1, 0.01, 0.0001],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                                   &#x27;sparse_cg&#x27;, &#x27;sag&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-31\" type=\"checkbox\" ><label for=\"sk-estimator-id-31\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Ridge(),\n",
       "                   param_distributions={&#x27;alpha&#x27;: [1, 0.1, 0.01, 0.0001],\n",
       "                                        &#x27;fit_intercept&#x27;: [True, False],\n",
       "                                        &#x27;solver&#x27;: [&#x27;cholesky&#x27;, &#x27;lsqr&#x27;,\n",
       "                                                   &#x27;sparse_cg&#x27;, &#x27;sag&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-32\" type=\"checkbox\" ><label for=\"sk-estimator-id-32\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-33\" type=\"checkbox\" ><label for=\"sk-estimator-id-33\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Ridge(),\n",
       "                   param_distributions={'alpha': [1, 0.1, 0.01, 0.0001],\n",
       "                                        'fit_intercept': [True, False],\n",
       "                                        'solver': ['cholesky', 'lsqr',\n",
       "                                                   'sparse_cg', 'sag']})"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ridge.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "669cbc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ridge_score=cross_val_score(rand_ridge,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a8ab37a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52809439, 0.62773638, 0.66982694, 0.74609828, 0.53625575])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ridge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "aedf5883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.7373989525198381\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'solver': 'cholesky', 'fit_intercept': True, 'alpha': 1}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_ridge.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_ridge.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069fcea",
   "metadata": {},
   "source": [
    "# random search for lasso reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "68f8f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso1 = Lasso()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "eae022a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters12 = {'alpha': [1.0,2.0],\n",
    "               'max_iter': [1000,2000],\n",
    "               'tol': [0.0001,0.01],\n",
    "               'selection': ['cyclic','random']\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "18c7f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lasso = RandomizedSearchCV(lasso, param_distributions = parameters12, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f34f1229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Lasso(),\n",
       "                   param_distributions={&#x27;alpha&#x27;: [1.0, 2.0],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.01]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-34\" type=\"checkbox\" ><label for=\"sk-estimator-id-34\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Lasso(),\n",
       "                   param_distributions={&#x27;alpha&#x27;: [1.0, 2.0],\n",
       "                                        &#x27;max_iter&#x27;: [1000, 2000],\n",
       "                                        &#x27;selection&#x27;: [&#x27;cyclic&#x27;, &#x27;random&#x27;],\n",
       "                                        &#x27;tol&#x27;: [0.0001, 0.01]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-35\" type=\"checkbox\" ><label for=\"sk-estimator-id-35\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-36\" type=\"checkbox\" ><label for=\"sk-estimator-id-36\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=Lasso(),\n",
       "                   param_distributions={'alpha': [1.0, 2.0],\n",
       "                                        'max_iter': [1000, 2000],\n",
       "                                        'selection': ['cyclic', 'random'],\n",
       "                                        'tol': [0.0001, 0.01]})"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_lasso.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5bc42447",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_lasso_score=cross_val_score(rand_lasso,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aa7f6f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.54730031, 0.62443637, 0.66534209, 0.73778024, 0.54947091])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_lasso_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "85d844d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.7343265003791973\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'tol': 0.01, 'selection': 'random', 'max_iter': 2000, 'alpha': 2.0}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_lasso.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_lasso.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cea2ae8",
   "metadata": {},
   "source": [
    "# random search for KNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3fa8e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_boost = AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d8b54c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters13 = {'n_estimators': [50,100],\n",
    "              'learning_rate': [1.0,2.0],\n",
    "              'loss' : ['linear', 'square']\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "dc568e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ada = RandomizedSearchCV(Ada_boost, param_distributions = parameters13, cv =kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d7cb61c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=AdaBoostRegressor(),\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [1.0, 2.0],\n",
       "                                        &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-37\" type=\"checkbox\" ><label for=\"sk-estimator-id-37\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=AdaBoostRegressor(),\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [1.0, 2.0],\n",
       "                                        &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" ><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-39\" type=\"checkbox\" ><label for=\"sk-estimator-id-39\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=AdaBoostRegressor(),\n",
       "                   param_distributions={'learning_rate': [1.0, 2.0],\n",
       "                                        'loss': ['linear', 'square'],\n",
       "                                        'n_estimators': [50, 100]})"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ada.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "c2277d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ada_score=cross_val_score(rand_ada,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5ebf6463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66443347,  0.67443348,  0.58345163,  0.65480302, -0.47478321])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ada_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "393ab72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from random Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " 0.8007188427102981\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'n_estimators': 100, 'loss': 'linear', 'learning_rate': 2.0}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from random Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",rand_ada.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",rand_ada.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b3d446",
   "metadata": {},
   "source": [
    "# ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c41b50e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05dfa9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp39-cp39-win_amd64.whl (1.9 kB)\n",
      "Collecting tensorflow-intel==2.12.0\n",
      "  Using cached tensorflow_intel-2.12.0-cp39-cp39-win_amd64.whl (272.8 MB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting packaging\n",
      "  Using cached packaging-23.1-py3-none-any.whl (48 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting six>=1.12.0\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.23.2-cp39-cp39-win_amd64.whl (422 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.54.2-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Collecting jax>=0.3.15\n",
      "  Downloading jax-0.4.11.tar.gz (1.3 MB)\n",
      "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.1/1.3 MB 1.7 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 0.3/1.3 MB 3.8 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 0.6/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.7/1.3 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 0.8/1.3 MB 4.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  1.3/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.3/1.3 MB 3.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.0-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting numpy<1.24,>=1.22\n",
      "  Using cached numpy-1.23.5-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras<2.13,>=2.12.0\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting setuptools\n",
      "  Using cached setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting tensorboard<2.13,>=2.12\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.40.0-py3-none-any.whl (64 kB)\n",
      "Collecting scipy>=1.7\n",
      "  Using cached scipy-1.10.1-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Collecting ml-dtypes>=0.1.0\n",
      "  Using cached ml_dtypes-0.1.0-cp39-cp39-win_amd64.whl (120 kB)\n",
      "Collecting importlib-metadata>=4.6\n",
      "  Using cached importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-any.whl (2.4 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     --------------------------- ------------ 122.9/181.3 kB ? eta -:--:--\n",
      "     ------------------------------ ------- 143.4/181.3 kB 2.9 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 174.1/181.3 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ - 174.1/181.3 kB 1.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ 181.3/181.3 kB 784.7 kB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting urllib3<2.0\n",
      "  Using cached urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.1.0-cp39-cp39-win_amd64.whl (97 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.2-cp39-cp39-win_amd64.whl (16 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: jax\n",
      "  Building wheel for jax (pyproject.toml): started\n",
      "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for jax: filename=jax-0.4.11-py3-none-any.whl size=1487992 sha256=5a9ad5b40682f7aac6d517e08bed6f91ca5c6e45015c15142dcd264d39290878\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\7b\\cf\\91\\0100f587c836f0e6c07b595e15265e5e208bed047417a94ca9\n",
      "Successfully built jax\n",
      "Installing collected packages: libclang, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, pyasn1, protobuf, packaging, oauthlib, numpy, MarkupSafe, keras, idna, grpcio, gast, charset-normalizer, certifi, cachetools, absl-py, werkzeug, scipy, rsa, requests, pyasn1-modules, opt-einsum, ml-dtypes, importlib-metadata, h5py, google-pasta, astunparse, requests-oauthlib, markdown, jax, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\DELL\\\\anaconda3\\\\envs\\\\Loandefault\\\\Lib\\\\site-packages\\\\charset_normalizer\\\\md.cp39-win_amd64.pyd'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install --ignore-installed --upgrade tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c220095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.10.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages\n",
      "Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24a5099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (5.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebb56fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (16.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.54.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (0.31.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (67.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (4.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "     ---------------------------------------- 0.0/895.9 kB ? eta -:--:--\n",
      "     ------ ------------------------------- 143.4/895.9 kB 2.8 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 491.5/895.9 kB 5.1 MB/s eta 0:00:01\n",
      "     -------------------------------------  890.9/895.9 kB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- 895.9/895.9 kB 5.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: tensorboard<2.11,>=2.10 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.24.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.6.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\anaconda3\\envs\\loandefault\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.2)\n",
      "Installing collected packages: keras, tensorflow-estimator, tensorboard-data-server, protobuf\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.12.0\n",
      "    Uninstalling keras-2.12.0:\n",
      "      Successfully uninstalled keras-2.12.0\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.2\n",
      "    Uninstalling protobuf-4.23.2:\n",
      "      Successfully uninstalled protobuf-4.23.2\n",
      "Successfully installed keras-2.12.0 protobuf-3.20.3 tensorboard-data-server-0.6.1 tensorflow-estimator-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c4844f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# print(tensorflow.__version__)\n",
    "# print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0c81ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f1f77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=8, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7c9b8c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=10, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f08d3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b6144714",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'mean_squared_error',metrics=['MeanSquaredLogarithmicError'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "80b279e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.5906 - mean_squared_logarithmic_error: 0.0679\n",
      "Epoch 2/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.3018 - mean_squared_logarithmic_error: 0.0700\n",
      "Epoch 3/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0954 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 4/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0447 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 5/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6129 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 6/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0027 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 7/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1306 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 8/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6992 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 9/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8085 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 10/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6798 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 11/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0439 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 12/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9522 - mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 13/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.1532 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 14/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9145 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 15/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5398 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 16/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6432 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 17/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1001 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 18/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1630 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 19/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.0389 - mean_squared_logarithmic_error: 0.0645\n",
      "Epoch 20/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5545 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 21/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4661 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 22/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0748 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 23/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.6635 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 24/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7221 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 25/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0639 - mean_squared_logarithmic_error: 0.0705\n",
      "Epoch 26/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 51.0155 - mean_squared_logarithmic_error: 0.0716\n",
      "Epoch 27/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0709 - mean_squared_logarithmic_error: 0.0661\n",
      "Epoch 28/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9057 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 29/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2637 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 30/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6682 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 31/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9863 - mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 32/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2681 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 33/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9484 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 34/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2547 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 35/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1379 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 36/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.8967 - mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 37/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.4252 - mean_squared_logarithmic_error: 0.0653\n",
      "Epoch 38/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.8780 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 39/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2821 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 40/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4278 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 41/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 51.4260 - mean_squared_logarithmic_error: 0.0674\n",
      "Epoch 42/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2736 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 43/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.5391 - mean_squared_logarithmic_error: 0.0610\n",
      "Epoch 44/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.7119 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 45/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9618 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 46/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5758 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 47/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 49.2440 - mean_squared_logarithmic_error: 0.0691\n",
      "Epoch 48/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.8464 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 49/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7776 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 50/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8379 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 51/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8868 - mean_squared_logarithmic_error: 0.0612\n",
      "Epoch 52/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5712 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 53/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7774 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 54/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8505 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 55/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.8386 - mean_squared_logarithmic_error: 0.0663\n",
      "Epoch 56/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.2776 - mean_squared_logarithmic_error: 0.0637\n",
      "Epoch 57/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3900 - mean_squared_logarithmic_error: 0.0655\n",
      "Epoch 58/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9423 - mean_squared_logarithmic_error: 0.0606\n",
      "Epoch 59/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.1714 - mean_squared_logarithmic_error: 0.0690\n",
      "Epoch 60/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3422 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 61/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2586 - mean_squared_logarithmic_error: 0.0679\n",
      "Epoch 62/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2983 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 63/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9129 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 64/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7715 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 65/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0888 - mean_squared_logarithmic_error: 0.0617\n",
      "Epoch 66/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4441 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 67/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9898 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 68/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.9622 - mean_squared_logarithmic_error: 0.0696\n",
      "Epoch 69/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2481 - mean_squared_logarithmic_error: 0.0663\n",
      "Epoch 70/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.9048 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 71/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7573 - mean_squared_logarithmic_error: 0.0709\n",
      "Epoch 72/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0760 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 73/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9609 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 74/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2296 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 75/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5387 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 76/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3580 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 77/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.7098 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 78/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1392 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 79/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.5092 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 80/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0366 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 81/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8936 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 82/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4999 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 83/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9011 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 84/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5205 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 85/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6709 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 86/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5872 - mean_squared_logarithmic_error: 0.0615\n",
      "Epoch 87/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2679 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 88/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.3114 - mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 89/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8399 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 90/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6757 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 91/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1641 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 92/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6370 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 93/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3610 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 94/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 52.9844 - mean_squared_logarithmic_error: 0.0779\n",
      "Epoch 95/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8048 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 96/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1990 - mean_squared_logarithmic_error: 0.0731\n",
      "Epoch 97/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2438 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 98/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.9928 - mean_squared_logarithmic_error: 0.0754\n",
      "Epoch 99/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2599 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 100/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1712 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 101/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5487 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 102/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8154 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 103/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9321 - mean_squared_logarithmic_error: 0.0528\n",
      "Epoch 104/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6657 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 105/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3594 - mean_squared_logarithmic_error: 0.0617\n",
      "Epoch 106/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5865 - mean_squared_logarithmic_error: 0.0653\n",
      "Epoch 107/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4706 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 108/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2546 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 109/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2048 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 110/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4141 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 111/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2228 - mean_squared_logarithmic_error: 0.0661\n",
      "Epoch 112/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4265 - mean_squared_logarithmic_error: 0.0614\n",
      "Epoch 113/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0746 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 114/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7795 - mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 115/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6496 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 116/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9080 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 117/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7704 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 118/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.5075 - mean_squared_logarithmic_error: 0.0635\n",
      "Epoch 119/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1414 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 120/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3432 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 121/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0626 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 122/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0658 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 123/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8383 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 124/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8795 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 125/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7563 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 126/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7075 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 127/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7719 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 128/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5732 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 129/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4715 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 130/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4708 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 131/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.1040 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 132/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8285 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 133/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 50.3474 - mean_squared_logarithmic_error: 0.0623\n",
      "Epoch 134/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8904 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 135/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3640 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 136/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8337 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 137/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5746 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 138/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9751 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 139/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2218 - mean_squared_logarithmic_error: 0.0609\n",
      "Epoch 140/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4262 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 141/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4468 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 142/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9329 - mean_squared_logarithmic_error: 0.0659\n",
      "Epoch 143/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2953 - mean_squared_logarithmic_error: 0.0625\n",
      "Epoch 144/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6453 - mean_squared_logarithmic_error: 0.0601\n",
      "Epoch 145/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6426 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 146/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0501 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 147/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1545 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 148/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.6419 - mean_squared_logarithmic_error: 0.0646\n",
      "Epoch 149/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 52.0565 - mean_squared_logarithmic_error: 0.0691\n",
      "Epoch 150/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3666 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 151/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0326 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 152/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5415 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 153/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7097 - mean_squared_logarithmic_error: 0.0648\n",
      "Epoch 154/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6839 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 155/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0176 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 156/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.0561 - mean_squared_logarithmic_error: 0.0740\n",
      "Epoch 157/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9333 - mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 158/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9705 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 159/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4114 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 160/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1165 - mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 161/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0328 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 162/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.0783 - mean_squared_logarithmic_error: 0.0674\n",
      "Epoch 163/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9464 - mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 164/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7835 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 165/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2895 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 166/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2942 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 167/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9088 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 168/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5110 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 169/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.5189 - mean_squared_logarithmic_error: 0.0647\n",
      "Epoch 170/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.2626 - mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 171/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3025 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 172/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9250 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 173/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3306 - mean_squared_logarithmic_error: 0.0527\n",
      "Epoch 174/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2429 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 175/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7201 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 176/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5156 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 177/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0737 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 178/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4009 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 179/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3168 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 180/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2254 - mean_squared_logarithmic_error: 0.0623\n",
      "Epoch 181/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.2333 - mean_squared_logarithmic_error: 0.0646\n",
      "Epoch 182/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1667 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 183/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0346 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 184/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6696 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 185/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1788 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 186/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3697 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 187/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9005 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 188/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3564 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 189/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9338 - mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 190/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4546 - mean_squared_logarithmic_error: 0.0523\n",
      "Epoch 191/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8673 - mean_squared_logarithmic_error: 0.0712\n",
      "Epoch 192/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7332 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 193/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7405 - mean_squared_logarithmic_error: 0.0723\n",
      "Epoch 194/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5689 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 195/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0264 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 196/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4125 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 197/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5395 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 198/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0854 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 199/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4458 - mean_squared_logarithmic_error: 0.0729\n",
      "Epoch 200/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8168 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 201/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7025 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 202/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9685 - mean_squared_logarithmic_error: 0.0667\n",
      "Epoch 203/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6570 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 204/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6430 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 205/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6997 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 206/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2556 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 207/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2324 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 208/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2005 - mean_squared_logarithmic_error: 0.0624\n",
      "Epoch 209/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6133 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 210/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2529 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 211/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9424 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 212/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7651 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 213/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8490 - mean_squared_logarithmic_error: 0.0712\n",
      "Epoch 214/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5989 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 215/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8308 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 216/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8222 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 217/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3415 - mean_squared_logarithmic_error: 0.0609\n",
      "Epoch 218/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5297 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 219/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.8205 - mean_squared_logarithmic_error: 0.0686\n",
      "Epoch 220/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4667 - mean_squared_logarithmic_error: 0.0532\n",
      "Epoch 221/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7052 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 222/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3373 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 223/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9471 - mean_squared_logarithmic_error: 0.0715\n",
      "Epoch 224/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2929 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 225/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0842 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 226/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4759 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 227/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7226 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 228/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5795 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 229/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6544 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 230/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1641 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 231/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5152 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 232/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4319 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 233/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2359 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 234/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 49.6196 - mean_squared_logarithmic_error: 0.0733\n",
      "Epoch 235/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6367 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 236/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.1237 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 237/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.7809 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 238/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1906 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 239/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8492 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 240/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8576 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 241/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1766 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 242/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1733 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 243/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7777 - mean_squared_logarithmic_error: 0.0599\n",
      "Epoch 244/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3403 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 245/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.2311 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 246/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6266 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 247/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.2740 - mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 248/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7527 - mean_squared_logarithmic_error: 0.0624\n",
      "Epoch 249/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4145 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 250/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1868 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 251/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9415 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 252/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8429 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 253/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9956 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 254/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3244 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 255/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0523 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 256/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9676 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 257/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.3800 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 258/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9328 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 259/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.5427 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 260/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6532 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 261/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1217 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 262/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 47.5002 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 263/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7698 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 264/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6325 - mean_squared_logarithmic_error: 0.0528\n",
      "Epoch 265/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9538 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 266/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1201 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 267/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7557 - mean_squared_logarithmic_error: 0.0706\n",
      "Epoch 268/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0560 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 269/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9268 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 270/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9137 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 271/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.7960 - mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 272/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.8303 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 273/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.2810 - mean_squared_logarithmic_error: 0.0685\n",
      "Epoch 274/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1420 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 275/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1439 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 276/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0394 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 277/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2484 - mean_squared_logarithmic_error: 0.0638\n",
      "Epoch 278/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9667 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 279/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5843 - mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 280/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6923 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 281/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5685 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 282/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2904 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 283/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3312 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 284/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1263 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 285/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5759 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 286/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9460 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 287/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7415 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 288/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1536 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 289/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9471 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 290/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5886 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 291/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7658 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 292/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8228 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 293/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0310 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 294/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7402 - mean_squared_logarithmic_error: 0.0655\n",
      "Epoch 295/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.2921 - mean_squared_logarithmic_error: 0.0614\n",
      "Epoch 296/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0587 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 297/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3131 - mean_squared_logarithmic_error: 0.0610\n",
      "Epoch 298/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7245 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 299/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3084 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 300/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1278 - mean_squared_logarithmic_error: 0.0615\n",
      "Epoch 301/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6221 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 302/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4237 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 303/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0555 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 304/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4590 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 305/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7048 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 306/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.8323 - mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 307/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6456 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 308/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8472 - mean_squared_logarithmic_error: 0.0671\n",
      "Epoch 309/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0396 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 310/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7862 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 311/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4114 - mean_squared_logarithmic_error: 0.0662\n",
      "Epoch 312/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7153 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 313/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6758 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 314/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 46.2414 - mean_squared_logarithmic_error: 0.0531\n",
      "Epoch 315/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.2194 - mean_squared_logarithmic_error: 0.0678\n",
      "Epoch 316/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8025 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 317/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.3103 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 318/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9177 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 319/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8511 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 320/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5744 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 321/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0966 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 322/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4814 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 323/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8425 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 324/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6954 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 325/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.8183 - mean_squared_logarithmic_error: 0.0624\n",
      "Epoch 326/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0132 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 327/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 51.0367 - mean_squared_logarithmic_error: 0.0659\n",
      "Epoch 328/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8550 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 329/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 49.3131 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 330/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.1252 - mean_squared_logarithmic_error: 0.0598\n",
      "Epoch 331/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6494 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 332/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.4325 - mean_squared_logarithmic_error: 0.0619\n",
      "Epoch 333/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.5535 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 334/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6645 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 335/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3845 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 336/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5266 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 337/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.7484 - mean_squared_logarithmic_error: 0.0601\n",
      "Epoch 338/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2478 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 339/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3433 - mean_squared_logarithmic_error: 0.0599\n",
      "Epoch 340/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5271 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 341/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 50.0957 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 342/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3928 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 343/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0080 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 344/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4618 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 345/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3680 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 346/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.9145 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 347/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0644 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 348/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.8180 - mean_squared_logarithmic_error: 0.0641\n",
      "Epoch 349/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4217 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 350/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.9630 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 351/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.5486 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 352/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.3495 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 353/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6732 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 354/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.9072 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 355/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6304 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 356/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 50.2246 - mean_squared_logarithmic_error: 0.0690\n",
      "Epoch 357/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.2564 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 358/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3587 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 359/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7901 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 360/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7355 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 361/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.0099 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 362/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6926 - mean_squared_logarithmic_error: 0.0652\n",
      "Epoch 363/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 50.2653 - mean_squared_logarithmic_error: 0.0680\n",
      "Epoch 364/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.0031 - mean_squared_logarithmic_error: 0.0715\n",
      "Epoch 365/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7518 - mean_squared_logarithmic_error: 0.0637\n",
      "Epoch 366/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4371 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 367/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7191 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 368/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7175 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 369/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2766 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 370/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5750 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 371/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1712 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 372/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7948 - mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 373/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9448 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 374/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3977 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 375/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2656 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 376/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4241 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 377/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0682 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 378/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5141 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 379/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3825 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 380/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7990 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 381/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7118 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 382/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0909 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 383/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5498 - mean_squared_logarithmic_error: 0.0641\n",
      "Epoch 384/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2813 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 385/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9096 - mean_squared_logarithmic_error: 0.0625\n",
      "Epoch 386/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2241 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 387/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6820 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 388/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.7008 - mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 389/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 54.9959 - mean_squared_logarithmic_error: 0.0713\n",
      "Epoch 390/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8948 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 391/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7084 - mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 392/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0057 - mean_squared_logarithmic_error: 0.0655\n",
      "Epoch 393/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3468 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 394/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5498 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 395/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8452 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 396/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1725 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 397/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2731 - mean_squared_logarithmic_error: 0.0614\n",
      "Epoch 398/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7431 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 399/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8066 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 400/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8736 - mean_squared_logarithmic_error: 0.0652\n",
      "Epoch 401/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 51.5438 - mean_squared_logarithmic_error: 0.0750\n",
      "Epoch 402/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.8180 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 403/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.5186 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 404/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3937 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 405/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8966 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 406/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6213 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 407/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1235 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 408/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9544 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 409/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1793 - mean_squared_logarithmic_error: 0.0601\n",
      "Epoch 410/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8284 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 411/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.8202 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 412/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3131 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 413/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 51.4169 - mean_squared_logarithmic_error: 0.0795\n",
      "Epoch 414/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6889 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 415/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0853 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 416/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7069 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 417/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5654 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 418/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1509 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 419/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2349 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 420/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9904 - mean_squared_logarithmic_error: 0.0682\n",
      "Epoch 421/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0252 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 422/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9112 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 423/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2421 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 424/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0925 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 425/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5662 - mean_squared_logarithmic_error: 0.0600\n",
      "Epoch 426/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6456 - mean_squared_logarithmic_error: 0.0614\n",
      "Epoch 427/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4423 - mean_squared_logarithmic_error: 0.0620\n",
      "Epoch 428/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5982 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 429/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9804 - mean_squared_logarithmic_error: 0.0628\n",
      "Epoch 430/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.1023 - mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 431/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7861 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 432/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3172 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 433/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8484 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 434/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2257 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 435/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2144 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 436/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.2083 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 437/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.2130 - mean_squared_logarithmic_error: 0.0636\n",
      "Epoch 438/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5472 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 439/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6230 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 440/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.3842 - mean_squared_logarithmic_error: 0.0734\n",
      "Epoch 441/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0052 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 442/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4050 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 443/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0685 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 444/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8476 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 445/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6071 - mean_squared_logarithmic_error: 0.0525\n",
      "Epoch 446/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4438 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 447/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.9931 - mean_squared_logarithmic_error: 0.0745\n",
      "Epoch 448/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4460 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 449/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9700 - mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 450/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2385 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 451/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5484 - mean_squared_logarithmic_error: 0.0635\n",
      "Epoch 452/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7914 - mean_squared_logarithmic_error: 0.0631\n",
      "Epoch 453/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8134 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 454/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9302 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 455/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4097 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 456/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6633 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1334 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 458/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0774 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 459/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7239 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 460/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0681 - mean_squared_logarithmic_error: 0.0682\n",
      "Epoch 461/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7717 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 462/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0462 - mean_squared_logarithmic_error: 0.0646\n",
      "Epoch 463/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5335 - mean_squared_logarithmic_error: 0.0535\n",
      "Epoch 464/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9536 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 465/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3753 - mean_squared_logarithmic_error: 0.0612\n",
      "Epoch 466/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2744 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 467/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3178 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 468/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4921 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 469/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3655 - mean_squared_logarithmic_error: 0.0525\n",
      "Epoch 470/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.8760 - mean_squared_logarithmic_error: 0.0666\n",
      "Epoch 471/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.2397 - mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 472/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.6304 - mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 473/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7027 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 474/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6792 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 475/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.3752 - mean_squared_logarithmic_error: 0.0648\n",
      "Epoch 476/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3046 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 477/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0106 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 478/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2048 - mean_squared_logarithmic_error: 0.0606\n",
      "Epoch 479/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6118 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 480/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8436 - mean_squared_logarithmic_error: 0.0534\n",
      "Epoch 481/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2008 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 482/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8729 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 483/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.8854 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 484/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4077 - mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 485/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9799 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 486/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6647 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 487/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6026 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 488/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5910 - mean_squared_logarithmic_error: 0.0641\n",
      "Epoch 489/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5506 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 490/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1636 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 491/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8413 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 492/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2507 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 493/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5876 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 494/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5694 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 495/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2051 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 496/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1450 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 497/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5385 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 498/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2371 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 499/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0955 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 500/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2421 - mean_squared_logarithmic_error: 0.0642\n",
      "Epoch 501/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.6881 - mean_squared_logarithmic_error: 0.0715\n",
      "Epoch 502/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0602 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 503/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4822 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 504/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9805 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 505/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9599 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 506/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8774 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 507/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1090 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 508/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6954 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 509/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3532 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 510/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4228 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 511/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7726 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 512/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0571 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 513/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7389 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 514/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.1328 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 515/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1877 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 516/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.0990 - mean_squared_logarithmic_error: 0.0689\n",
      "Epoch 517/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5188 - mean_squared_logarithmic_error: 0.0530\n",
      "Epoch 518/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.2035 - mean_squared_logarithmic_error: 0.0723\n",
      "Epoch 519/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6796 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 520/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5651 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 521/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5767 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6652 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 523/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7844 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 524/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6600 - mean_squared_logarithmic_error: 0.0549\n",
      "Epoch 525/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7752 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 526/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7505 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 527/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2907 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 528/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9564 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 529/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5044 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 530/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2080 - mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 531/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9674 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 532/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1543 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 533/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6629 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 534/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9850 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 535/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9903 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 536/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0664 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 537/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3399 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 538/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.4038 - mean_squared_logarithmic_error: 0.0619\n",
      "Epoch 539/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2377 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 540/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6922 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 541/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0153 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 542/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7604 - mean_squared_logarithmic_error: 0.0626\n",
      "Epoch 543/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.4332 - mean_squared_logarithmic_error: 0.0667\n",
      "Epoch 544/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3059 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 545/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1466 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 546/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9037 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 547/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0199 - mean_squared_logarithmic_error: 0.0601\n",
      "Epoch 548/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1142 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 549/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5353 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 550/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0019 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 551/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7122 - mean_squared_logarithmic_error: 0.0609\n",
      "Epoch 552/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2267 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 553/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5912 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 554/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1003 - mean_squared_logarithmic_error: 0.0653\n",
      "Epoch 555/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6490 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 556/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5087 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 557/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7260 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 558/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2705 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 559/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1205 - mean_squared_logarithmic_error: 0.0641\n",
      "Epoch 560/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0879 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 561/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6174 - mean_squared_logarithmic_error: 0.0627\n",
      "Epoch 562/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1199 - mean_squared_logarithmic_error: 0.0625\n",
      "Epoch 563/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4037 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 564/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7330 - mean_squared_logarithmic_error: 0.0658\n",
      "Epoch 565/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9854 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 566/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1998 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 567/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3458 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 568/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6240 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 569/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1473 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 570/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1209 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 571/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6785 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 572/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7021 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 573/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6952 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 574/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9778 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 575/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9634 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 576/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5619 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 577/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.1182 - mean_squared_logarithmic_error: 0.0622\n",
      "Epoch 578/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6927 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 579/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0435 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 580/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0326 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 581/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0659 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 582/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0213 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 583/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0811 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 584/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8318 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 585/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0159 - mean_squared_logarithmic_error: 0.0674\n",
      "Epoch 586/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9483 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 587/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8826 - mean_squared_logarithmic_error: 0.0610\n",
      "Epoch 588/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8346 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 589/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0889 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 590/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5224 - mean_squared_logarithmic_error: 0.0610\n",
      "Epoch 591/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9412 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 592/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7660 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 593/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2423 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 594/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9585 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 595/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7092 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 596/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2298 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 597/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5001 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 598/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.6685 - mean_squared_logarithmic_error: 0.0696\n",
      "Epoch 599/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5747 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 600/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7489 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 601/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.9770 - mean_squared_logarithmic_error: 0.0651\n",
      "Epoch 602/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1955 - mean_squared_logarithmic_error: 0.0631\n",
      "Epoch 603/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1011 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 604/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1145 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 605/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2991 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 606/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6664 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 607/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1532 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 608/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7274 - mean_squared_logarithmic_error: 0.0531\n",
      "Epoch 609/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4630 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 610/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7504 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 611/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3539 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 612/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3359 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 613/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6710 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 614/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9168 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 615/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3880 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 616/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8169 - mean_squared_logarithmic_error: 0.0517\n",
      "Epoch 617/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6045 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 618/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1013 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 619/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7619 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 620/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5498 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 621/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 51.0079 - mean_squared_logarithmic_error: 0.0839\n",
      "Epoch 622/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2490 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 623/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9957 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 624/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0908 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 625/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8129 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 626/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7128 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 627/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3582 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 628/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2022 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 629/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9971 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 630/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0343 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 631/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9078 - mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 632/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9398 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 633/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3500 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 634/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1468 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 635/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0794 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 636/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.8018 - mean_squared_logarithmic_error: 0.0668\n",
      "Epoch 637/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2823 - mean_squared_logarithmic_error: 0.0677\n",
      "Epoch 638/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2746 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 639/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7696 - mean_squared_logarithmic_error: 0.0706\n",
      "Epoch 640/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5275 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 641/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3443 - mean_squared_logarithmic_error: 0.0651\n",
      "Epoch 642/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3867 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 643/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2369 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 644/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7380 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 645/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6313 - mean_squared_logarithmic_error: 0.0531\n",
      "Epoch 646/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3338 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 647/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3315 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 648/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7726 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 649/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2509 - mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 650/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3470 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 651/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4461 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 652/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 47.4364 - mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 653/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9780 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 654/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3374 - mean_squared_logarithmic_error: 0.0684\n",
      "Epoch 655/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8321 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 656/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0281 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 657/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0487 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 658/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4424 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 659/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.3642 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 660/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2538 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 661/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.8254 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 662/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.4001 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 663/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3156 - mean_squared_logarithmic_error: 0.0600\n",
      "Epoch 664/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9681 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 665/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.7039 - mean_squared_logarithmic_error: 0.0640\n",
      "Epoch 666/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.1913 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 667/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4661 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 668/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5821 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 669/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4267 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 670/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0382 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 671/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 49.0232 - mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 672/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5938 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 673/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9819 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 674/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.8493 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 675/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4492 - mean_squared_logarithmic_error: 0.0535\n",
      "Epoch 676/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9113 - mean_squared_logarithmic_error: 0.0510\n",
      "Epoch 677/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5602 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 678/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4964 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 679/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9030 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 680/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.0858 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 681/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9091 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 682/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.4880 - mean_squared_logarithmic_error: 0.0642\n",
      "Epoch 683/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7780 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 684/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7619 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 685/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.7583 - mean_squared_logarithmic_error: 0.0649\n",
      "Epoch 686/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.1202 - mean_squared_logarithmic_error: 0.0620\n",
      "Epoch 687/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7566 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 688/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7767 - mean_squared_logarithmic_error: 0.0562\n",
      "Epoch 689/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9960 - mean_squared_logarithmic_error: 0.0525\n",
      "Epoch 690/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3514 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 691/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2772 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 692/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7069 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 693/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1409 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 694/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1782 - mean_squared_logarithmic_error: 0.0615\n",
      "Epoch 695/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.7084 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 696/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2900 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 697/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6423 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 698/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.3303 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 699/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4000 - mean_squared_logarithmic_error: 0.0636\n",
      "Epoch 700/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7055 - mean_squared_logarithmic_error: 0.0620\n",
      "Epoch 701/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.0916 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 702/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.1949 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 703/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9828 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 704/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.7085 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 705/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5330 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 706/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3281 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 707/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 46.1432 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 708/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6507 - mean_squared_logarithmic_error: 0.0681\n",
      "Epoch 709/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9168 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 710/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2498 - mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 711/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.1203 - mean_squared_logarithmic_error: 0.0527\n",
      "Epoch 712/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9486 - mean_squared_logarithmic_error: 0.0639\n",
      "Epoch 713/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.1193 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 714/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.3753 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 715/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.6492 - mean_squared_logarithmic_error: 0.0655\n",
      "Epoch 716/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2226 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 2ms/step - loss: 45.2789 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 718/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.2060 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 719/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.0420 - mean_squared_logarithmic_error: 0.0730\n",
      "Epoch 720/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.1791 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 721/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.2825 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 722/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.1096 - mean_squared_logarithmic_error: 0.0623\n",
      "Epoch 723/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.0846 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 724/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.8343 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 725/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.5740 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 726/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.3033 - mean_squared_logarithmic_error: 0.0623\n",
      "Epoch 727/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.0595 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 728/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2832 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 729/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.7904 - mean_squared_logarithmic_error: 0.0707\n",
      "Epoch 730/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6286 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 731/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 46.6617 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 732/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9321 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 733/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.0755 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 734/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.2067 - mean_squared_logarithmic_error: 0.0636\n",
      "Epoch 735/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.5800 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 736/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.8916 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 737/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0000 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 738/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 45.4020 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 739/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.3646 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 740/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.8617 - mean_squared_logarithmic_error: 0.0600\n",
      "Epoch 741/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5120 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 742/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.9480 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 743/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.0626 - mean_squared_logarithmic_error: 0.0526\n",
      "Epoch 744/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.0364 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 745/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.5924 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 746/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.5716 - mean_squared_logarithmic_error: 0.0523\n",
      "Epoch 747/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.6690 - mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 748/1000\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 51.7226 - mean_squared_logarithmic_error: 0.0653\n",
      "Epoch 749/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.7047 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 750/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.7844 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 751/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.2409 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 752/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6379 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 753/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4167 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 754/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3052 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 755/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7004 - mean_squared_logarithmic_error: 0.0619\n",
      "Epoch 756/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7305 - mean_squared_logarithmic_error: 0.0620\n",
      "Epoch 757/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3093 - mean_squared_logarithmic_error: 0.0587\n",
      "Epoch 758/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.0936 - mean_squared_logarithmic_error: 0.0568\n",
      "Epoch 759/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.1700 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 760/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9396 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 761/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6830 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 762/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.9685 - mean_squared_logarithmic_error: 0.0563\n",
      "Epoch 763/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8360 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 764/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1735 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 765/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6868 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 766/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1988 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 767/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5596 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 768/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5015 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 769/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8365 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 770/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9231 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 771/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0042 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 772/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9940 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 773/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3629 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 774/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9052 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 775/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9898 - mean_squared_logarithmic_error: 0.0549\n",
      "Epoch 776/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1218 - mean_squared_logarithmic_error: 0.0612\n",
      "Epoch 777/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9189 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 778/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3760 - mean_squared_logarithmic_error: 0.0593\n",
      "Epoch 779/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7113 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 780/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3819 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 781/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6914 - mean_squared_logarithmic_error: 0.0614\n",
      "Epoch 782/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5381 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 783/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.8375 - mean_squared_logarithmic_error: 0.0527\n",
      "Epoch 784/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4826 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 785/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9739 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 786/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1768 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 787/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9434 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 788/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9827 - mean_squared_logarithmic_error: 0.0630\n",
      "Epoch 789/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8107 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 790/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6272 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 791/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8287 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 792/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9175 - mean_squared_logarithmic_error: 0.0544\n",
      "Epoch 793/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2398 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 794/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3307 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 795/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9156 - mean_squared_logarithmic_error: 0.0537\n",
      "Epoch 796/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4662 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 797/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1240 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 798/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3329 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 799/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4877 - mean_squared_logarithmic_error: 0.0601\n",
      "Epoch 800/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9761 - mean_squared_logarithmic_error: 0.0596\n",
      "Epoch 801/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8872 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 802/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3535 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 803/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2833 - mean_squared_logarithmic_error: 0.0602\n",
      "Epoch 804/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.8699 - mean_squared_logarithmic_error: 0.0644\n",
      "Epoch 805/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6917 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 806/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5266 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 807/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1316 - mean_squared_logarithmic_error: 0.0606\n",
      "Epoch 808/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1956 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 809/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5824 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 810/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2260 - mean_squared_logarithmic_error: 0.0535\n",
      "Epoch 811/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.3651 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 812/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5217 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 813/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9700 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 814/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2625 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 815/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4904 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 816/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1997 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 817/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9733 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 818/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1947 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 819/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2614 - mean_squared_logarithmic_error: 0.0581\n",
      "Epoch 820/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6647 - mean_squared_logarithmic_error: 0.0575\n",
      "Epoch 821/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2977 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 822/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.0014 - mean_squared_logarithmic_error: 0.0603\n",
      "Epoch 823/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8664 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 824/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.3130 - mean_squared_logarithmic_error: 0.0661\n",
      "Epoch 825/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3641 - mean_squared_logarithmic_error: 0.0613\n",
      "Epoch 826/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3945 - mean_squared_logarithmic_error: 0.0584\n",
      "Epoch 827/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4385 - mean_squared_logarithmic_error: 0.0513\n",
      "Epoch 828/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2509 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 829/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2126 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 830/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7463 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 831/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7449 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 832/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4941 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 833/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5778 - mean_squared_logarithmic_error: 0.0612\n",
      "Epoch 834/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.0042 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 835/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.3717 - mean_squared_logarithmic_error: 0.0695\n",
      "Epoch 836/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5464 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 837/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7356 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 838/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1131 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 839/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4548 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 840/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0334 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 841/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0496 - mean_squared_logarithmic_error: 0.0560\n",
      "Epoch 842/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.8898 - mean_squared_logarithmic_error: 0.0514\n",
      "Epoch 843/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8880 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 844/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.5602 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 845/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4821 - mean_squared_logarithmic_error: 0.0619\n",
      "Epoch 846/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9355 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 847/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1821 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 848/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8309 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 849/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3286 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 850/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4360 - mean_squared_logarithmic_error: 0.0535\n",
      "Epoch 851/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.1822 - mean_squared_logarithmic_error: 0.0618\n",
      "Epoch 852/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8580 - mean_squared_logarithmic_error: 0.0548\n",
      "Epoch 853/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5982 - mean_squared_logarithmic_error: 0.0549\n",
      "Epoch 854/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1579 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 855/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1501 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 856/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1895 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 857/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.7864 - mean_squared_logarithmic_error: 0.0616\n",
      "Epoch 858/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0696 - mean_squared_logarithmic_error: 0.0524\n",
      "Epoch 859/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0079 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 860/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0685 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 861/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0667 - mean_squared_logarithmic_error: 0.0567\n",
      "Epoch 862/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2970 - mean_squared_logarithmic_error: 0.0532\n",
      "Epoch 863/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4369 - mean_squared_logarithmic_error: 0.0554\n",
      "Epoch 864/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9731 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 865/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9812 - mean_squared_logarithmic_error: 0.0535\n",
      "Epoch 866/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1040 - mean_squared_logarithmic_error: 0.0566\n",
      "Epoch 867/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7467 - mean_squared_logarithmic_error: 0.0632\n",
      "Epoch 868/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9817 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 869/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3987 - mean_squared_logarithmic_error: 0.0591\n",
      "Epoch 870/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7151 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 871/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6230 - mean_squared_logarithmic_error: 0.0549\n",
      "Epoch 872/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2195 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 873/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6911 - mean_squared_logarithmic_error: 0.0517\n",
      "Epoch 874/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9567 - mean_squared_logarithmic_error: 0.0607\n",
      "Epoch 875/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0770 - mean_squared_logarithmic_error: 0.0622\n",
      "Epoch 876/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4178 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 877/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9531 - mean_squared_logarithmic_error: 0.0550\n",
      "Epoch 878/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1053 - mean_squared_logarithmic_error: 0.0545\n",
      "Epoch 879/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6932 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 880/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.9288 - mean_squared_logarithmic_error: 0.0597\n",
      "Epoch 881/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4255 - mean_squared_logarithmic_error: 0.0585\n",
      "Epoch 882/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.0899 - mean_squared_logarithmic_error: 0.0647\n",
      "Epoch 883/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6813 - mean_squared_logarithmic_error: 0.0592\n",
      "Epoch 884/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6677 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 885/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.8683 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 886/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2457 - mean_squared_logarithmic_error: 0.0611\n",
      "Epoch 887/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1508 - mean_squared_logarithmic_error: 0.0538\n",
      "Epoch 888/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5531 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 889/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9674 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 890/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.5001 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 891/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8486 - mean_squared_logarithmic_error: 0.0634\n",
      "Epoch 892/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0687 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 893/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0957 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 894/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0869 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 895/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.5668 - mean_squared_logarithmic_error: 0.0669\n",
      "Epoch 896/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6910 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 897/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2589 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 898/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3981 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 899/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5768 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 900/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9443 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 901/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.9449 - mean_squared_logarithmic_error: 0.0748\n",
      "Epoch 902/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7764 - mean_squared_logarithmic_error: 0.0529\n",
      "Epoch 903/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.0287 - mean_squared_logarithmic_error: 0.0583\n",
      "Epoch 904/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1921 - mean_squared_logarithmic_error: 0.0526\n",
      "Epoch 905/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1289 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 906/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8160 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 907/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5300 - mean_squared_logarithmic_error: 0.0540\n",
      "Epoch 908/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5331 - mean_squared_logarithmic_error: 0.0561\n",
      "Epoch 909/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3815 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 910/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1216 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 911/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 44.9774 - mean_squared_logarithmic_error: 0.0529\n",
      "Epoch 912/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1064 - mean_squared_logarithmic_error: 0.0578\n",
      "Epoch 913/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 48.6745 - mean_squared_logarithmic_error: 0.0678\n",
      "Epoch 914/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3353 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 915/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2582 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 916/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4716 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 917/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0328 - mean_squared_logarithmic_error: 0.0519\n",
      "Epoch 918/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.9213 - mean_squared_logarithmic_error: 0.0658\n",
      "Epoch 919/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5174 - mean_squared_logarithmic_error: 0.0576\n",
      "Epoch 920/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8379 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 921/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 46.4459 - mean_squared_logarithmic_error: 0.0621\n",
      "Epoch 922/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1440 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 923/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6758 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 924/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.0986 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 925/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6960 - mean_squared_logarithmic_error: 0.0599\n",
      "Epoch 926/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5761 - mean_squared_logarithmic_error: 0.0534\n",
      "Epoch 927/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.6067 - mean_squared_logarithmic_error: 0.0588\n",
      "Epoch 928/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2195 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 929/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0904 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 930/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6827 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 931/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7454 - mean_squared_logarithmic_error: 0.0574\n",
      "Epoch 932/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2656 - mean_squared_logarithmic_error: 0.0586\n",
      "Epoch 933/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5534 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 934/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3686 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 935/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8100 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 936/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 49.5405 - mean_squared_logarithmic_error: 0.0595\n",
      "Epoch 937/1000\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 45.7980 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 938/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2237 - mean_squared_logarithmic_error: 0.0589\n",
      "Epoch 939/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.2667 - mean_squared_logarithmic_error: 0.0546\n",
      "Epoch 940/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2876 - mean_squared_logarithmic_error: 0.0565\n",
      "Epoch 941/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8073 - mean_squared_logarithmic_error: 0.0569\n",
      "Epoch 942/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3539 - mean_squared_logarithmic_error: 0.0564\n",
      "Epoch 943/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7542 - mean_squared_logarithmic_error: 0.0582\n",
      "Epoch 944/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.0182 - mean_squared_logarithmic_error: 0.0615\n",
      "Epoch 945/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.8076 - mean_squared_logarithmic_error: 0.0577\n",
      "Epoch 946/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9874 - mean_squared_logarithmic_error: 0.0532\n",
      "Epoch 947/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.6042 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 948/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8568 - mean_squared_logarithmic_error: 0.0527\n",
      "Epoch 949/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.8901 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 950/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9251 - mean_squared_logarithmic_error: 0.0536\n",
      "Epoch 951/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6852 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 952/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.7300 - mean_squared_logarithmic_error: 0.0559\n",
      "Epoch 953/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1151 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 954/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5556 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 955/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4575 - mean_squared_logarithmic_error: 0.0599\n",
      "Epoch 956/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 48.5138 - mean_squared_logarithmic_error: 0.0664\n",
      "Epoch 957/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.1022 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 958/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.7227 - mean_squared_logarithmic_error: 0.0514\n",
      "Epoch 959/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 47.7467 - mean_squared_logarithmic_error: 0.0612\n",
      "Epoch 960/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.1141 - mean_squared_logarithmic_error: 0.0525\n",
      "Epoch 961/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5954 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 962/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4692 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 963/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.1891 - mean_squared_logarithmic_error: 0.0633\n",
      "Epoch 964/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 49.3437 - mean_squared_logarithmic_error: 0.0708\n",
      "Epoch 965/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3196 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 966/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4332 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 967/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9098 - mean_squared_logarithmic_error: 0.0604\n",
      "Epoch 968/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4250 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 969/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1567 - mean_squared_logarithmic_error: 0.0549\n",
      "Epoch 970/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4423 - mean_squared_logarithmic_error: 0.0556\n",
      "Epoch 971/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9678 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 972/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.7416 - mean_squared_logarithmic_error: 0.0542\n",
      "Epoch 973/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.2622 - mean_squared_logarithmic_error: 0.0580\n",
      "Epoch 974/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9819 - mean_squared_logarithmic_error: 0.0541\n",
      "Epoch 975/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.6483 - mean_squared_logarithmic_error: 0.0533\n",
      "Epoch 976/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.2505 - mean_squared_logarithmic_error: 0.0608\n",
      "Epoch 977/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7700 - mean_squared_logarithmic_error: 0.0551\n",
      "Epoch 978/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9793 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 979/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 50.0215 - mean_squared_logarithmic_error: 0.0606\n",
      "Epoch 980/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1403 - mean_squared_logarithmic_error: 0.0579\n",
      "Epoch 981/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 44.9046 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 982/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4344 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 983/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4127 - mean_squared_logarithmic_error: 0.0522\n",
      "Epoch 984/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.4778 - mean_squared_logarithmic_error: 0.0547\n",
      "Epoch 985/1000\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 45.1285 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 986/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9204 - mean_squared_logarithmic_error: 0.0599\n",
      "Epoch 987/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7005 - mean_squared_logarithmic_error: 0.0572\n",
      "Epoch 988/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6027 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 989/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.4674 - mean_squared_logarithmic_error: 0.0571\n",
      "Epoch 990/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5055 - mean_squared_logarithmic_error: 0.0605\n",
      "Epoch 991/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.5748 - mean_squared_logarithmic_error: 0.0553\n",
      "Epoch 992/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.9149 - mean_squared_logarithmic_error: 0.0543\n",
      "Epoch 993/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.5771 - mean_squared_logarithmic_error: 0.0594\n",
      "Epoch 994/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.1825 - mean_squared_logarithmic_error: 0.0557\n",
      "Epoch 995/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.7585 - mean_squared_logarithmic_error: 0.0519\n",
      "Epoch 996/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 47.3706 - mean_squared_logarithmic_error: 0.0552\n",
      "Epoch 997/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 46.3508 - mean_squared_logarithmic_error: 0.0590\n",
      "Epoch 998/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.8006 - mean_squared_logarithmic_error: 0.0646\n",
      "Epoch 999/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.6091 - mean_squared_logarithmic_error: 0.0530\n",
      "Epoch 1000/1000\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 45.3832 - mean_squared_logarithmic_error: 0.0537\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "model = ann.fit(X_train, Y_train, batch_size = 32, epochs = 1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a65d60eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1000us/step\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2d584880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.222786  ],\n",
       "       [ 4.7222195 ],\n",
       "       [26.403765  ],\n",
       "       [30.702362  ],\n",
       "       [ 7.90656   ],\n",
       "       [36.52868   ],\n",
       "       [45.672806  ],\n",
       "       [38.1482    ],\n",
       "       [55.116493  ],\n",
       "       [74.43661   ],\n",
       "       [32.158638  ],\n",
       "       [45.906178  ],\n",
       "       [23.273304  ],\n",
       "       [45.95533   ],\n",
       "       [26.646084  ],\n",
       "       [29.346735  ],\n",
       "       [41.10836   ],\n",
       "       [35.40191   ],\n",
       "       [31.670332  ],\n",
       "       [ 0.73009795],\n",
       "       [28.900154  ],\n",
       "       [33.264614  ],\n",
       "       [34.99066   ],\n",
       "       [31.41488   ],\n",
       "       [ 9.484338  ],\n",
       "       [20.756657  ],\n",
       "       [35.337616  ],\n",
       "       [39.47279   ],\n",
       "       [58.96978   ],\n",
       "       [33.28222   ],\n",
       "       [19.862265  ],\n",
       "       [16.382063  ],\n",
       "       [11.895219  ],\n",
       "       [14.21697   ],\n",
       "       [22.29006   ],\n",
       "       [18.173588  ],\n",
       "       [28.70361   ],\n",
       "       [37.358788  ],\n",
       "       [57.172688  ],\n",
       "       [35.97146   ],\n",
       "       [47.186924  ],\n",
       "       [ 9.928014  ],\n",
       "       [56.652718  ],\n",
       "       [29.935253  ],\n",
       "       [43.5991    ],\n",
       "       [24.896969  ],\n",
       "       [21.867064  ],\n",
       "       [34.222786  ],\n",
       "       [13.574712  ],\n",
       "       [26.862871  ],\n",
       "       [ 2.7208798 ],\n",
       "       [32.839546  ],\n",
       "       [40.325657  ],\n",
       "       [58.20303   ],\n",
       "       [40.42101   ],\n",
       "       [59.78068   ],\n",
       "       [40.039104  ],\n",
       "       [24.693295  ],\n",
       "       [50.726665  ],\n",
       "       [40.49116   ],\n",
       "       [24.343248  ],\n",
       "       [22.685553  ],\n",
       "       [33.490532  ],\n",
       "       [39.151054  ],\n",
       "       [26.741049  ],\n",
       "       [40.625137  ],\n",
       "       [46.309227  ],\n",
       "       [20.990618  ],\n",
       "       [46.147285  ],\n",
       "       [67.009674  ],\n",
       "       [17.186968  ],\n",
       "       [36.509922  ],\n",
       "       [35.83024   ],\n",
       "       [40.881897  ],\n",
       "       [22.351976  ],\n",
       "       [35.758842  ],\n",
       "       [58.029446  ],\n",
       "       [17.003199  ],\n",
       "       [30.891901  ],\n",
       "       [41.918625  ],\n",
       "       [35.986206  ],\n",
       "       [75.31425   ],\n",
       "       [18.47951   ],\n",
       "       [26.697777  ],\n",
       "       [64.72926   ],\n",
       "       [43.70793   ],\n",
       "       [45.275574  ],\n",
       "       [ 1.4875557 ],\n",
       "       [11.1331415 ],\n",
       "       [37.156464  ],\n",
       "       [59.55164   ],\n",
       "       [ 8.161918  ],\n",
       "       [50.07905   ],\n",
       "       [38.46785   ],\n",
       "       [36.46074   ],\n",
       "       [37.2889    ],\n",
       "       [19.400253  ],\n",
       "       [53.76688   ],\n",
       "       [25.244162  ],\n",
       "       [27.661793  ],\n",
       "       [10.123921  ],\n",
       "       [44.342304  ],\n",
       "       [26.587992  ],\n",
       "       [30.398964  ],\n",
       "       [34.45134   ],\n",
       "       [38.288765  ],\n",
       "       [26.922375  ],\n",
       "       [26.89132   ],\n",
       "       [38.504604  ],\n",
       "       [36.22568   ],\n",
       "       [51.908707  ],\n",
       "       [ 8.256793  ],\n",
       "       [15.481856  ],\n",
       "       [10.223037  ],\n",
       "       [39.161995  ],\n",
       "       [18.629784  ],\n",
       "       [10.384833  ],\n",
       "       [ 7.70963   ],\n",
       "       [29.681816  ],\n",
       "       [ 5.739171  ],\n",
       "       [50.900955  ],\n",
       "       [41.451706  ],\n",
       "       [38.498962  ],\n",
       "       [31.441408  ],\n",
       "       [65.72979   ],\n",
       "       [15.971172  ],\n",
       "       [17.29853   ],\n",
       "       [27.091465  ],\n",
       "       [15.786181  ],\n",
       "       [44.270397  ],\n",
       "       [39.850708  ],\n",
       "       [24.515394  ],\n",
       "       [33.414726  ],\n",
       "       [22.322376  ],\n",
       "       [17.825754  ],\n",
       "       [48.418427  ],\n",
       "       [48.351177  ],\n",
       "       [42.437237  ],\n",
       "       [11.293969  ],\n",
       "       [38.17648   ],\n",
       "       [36.883286  ],\n",
       "       [62.318615  ],\n",
       "       [41.448563  ],\n",
       "       [44.003277  ],\n",
       "       [24.06814   ],\n",
       "       [29.86436   ],\n",
       "       [13.376227  ],\n",
       "       [41.47838   ],\n",
       "       [44.27731   ],\n",
       "       [36.509922  ],\n",
       "       [18.004995  ],\n",
       "       [37.406002  ],\n",
       "       [37.519577  ],\n",
       "       [44.72737   ],\n",
       "       [29.81393   ],\n",
       "       [22.824766  ],\n",
       "       [40.029526  ],\n",
       "       [21.968632  ],\n",
       "       [25.22751   ],\n",
       "       [38.818157  ],\n",
       "       [28.71237   ],\n",
       "       [32.807354  ],\n",
       "       [41.33052   ],\n",
       "       [38.41859   ],\n",
       "       [10.647492  ],\n",
       "       [22.770472  ],\n",
       "       [32.854736  ],\n",
       "       [50.376625  ],\n",
       "       [34.909824  ],\n",
       "       [52.219635  ],\n",
       "       [34.622112  ],\n",
       "       [38.106113  ],\n",
       "       [26.695406  ],\n",
       "       [36.57708   ],\n",
       "       [23.552494  ],\n",
       "       [35.41165   ],\n",
       "       [50.39562   ],\n",
       "       [27.736988  ],\n",
       "       [ 2.3546097 ],\n",
       "       [40.019566  ],\n",
       "       [41.911392  ],\n",
       "       [36.883286  ],\n",
       "       [65.98944   ],\n",
       "       [40.5116    ],\n",
       "       [ 8.934716  ],\n",
       "       [32.646416  ],\n",
       "       [22.767538  ],\n",
       "       [20.049473  ],\n",
       "       [42.219055  ],\n",
       "       [28.31101   ],\n",
       "       [41.30148   ],\n",
       "       [13.605527  ],\n",
       "       [31.339308  ],\n",
       "       [42.444782  ],\n",
       "       [31.741388  ],\n",
       "       [44.616203  ],\n",
       "       [24.330061  ],\n",
       "       [43.918518  ],\n",
       "       [16.982618  ],\n",
       "       [40.90978   ],\n",
       "       [22.239325  ]], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "246cfa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_r2score = r2_score(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "c906f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365656470837927"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_r2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71ebe8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "abc = X[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9c642119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement</th>\n",
       "      <th>BlastFurnaceSlag</th>\n",
       "      <th>FlyAsh</th>\n",
       "      <th>Water</th>\n",
       "      <th>Superplasticizer</th>\n",
       "      <th>CoarseAggregate</th>\n",
       "      <th>FineAggregate</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>45.856716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>45.856716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cement  BlastFurnaceSlag  FlyAsh  Water  Superplasticizer  CoarseAggregate   \n",
       "2   332.5             142.5     0.0  228.0               0.0            932.0  \\\n",
       "3   332.5             142.5     0.0  228.0               0.0            932.0   \n",
       "\n",
       "   FineAggregate        Age  \n",
       "2          594.0  45.856716  \n",
       "3          594.0  45.856716  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "9f76cb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[41.845333],\n",
       "       [41.845333]], dtype=float32)"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.predict(abc)\n",
    "xyz =ann.predict(abc)\n",
    "xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c491ff58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    40.269535\n",
       "3    41.052780\n",
       "Name: CC_Strength, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b= data1['CC_Strength'][2:4]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "e47e357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "lr = LinearRegression()\n",
    "lr1 = lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "f20deb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7483439832374135"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "0694b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = lr1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "a18ae7d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44.54582091, 36.40025678, 50.98376853, 44.07065537, 21.36177305,\n",
       "       48.28519984, 40.97640362, 26.69434974, 22.25374315, 22.1763818 ,\n",
       "       59.09258219, 20.77824919, 40.88195871, 28.54763747, 27.66308925,\n",
       "       13.4316615 , 56.60310016, 58.65337316, 44.59637523, 34.46760758,\n",
       "       26.37470873, 35.98960306, 49.39590858, 39.66436745, 40.44873663,\n",
       "       33.03089903, 55.56367474, 21.62268565, 16.26477736, 50.00745214,\n",
       "       30.40090802, 35.35988327, 55.93171623, 48.55243644, 17.85013486,\n",
       "       18.76553025, 48.90679669, 56.87605094, 20.12942048, 30.45516482,\n",
       "       52.3950891 , 31.79768245, 35.10389153, 19.28100751, 21.05780416,\n",
       "       31.17320431, 23.65989935, 33.98850974, 44.53406873, 31.3615508 ,\n",
       "       55.34716407, 46.38347762, 42.21036593, 36.82122099, 54.46707597,\n",
       "       30.20324666, 41.41308198, 23.60522398, 32.20623147, 36.21976438,\n",
       "       29.05778384, 27.72561594, 46.46980713, 31.1379558 , 27.54011833,\n",
       "       58.03202825, 38.46657079, 27.23933293, 28.7654591 , 50.41988049,\n",
       "       54.86997476, 31.35373905, 63.63213067, 49.18635165, 47.39952739,\n",
       "       48.47892302, 30.12217163, 44.35639125, 30.52216586, 35.131054  ,\n",
       "       33.60737541, 41.21900524, 34.18722016, 33.86404771, 62.18154978,\n",
       "       29.89278815, 39.42353485, 49.9065899 , 36.72684216, 24.25534844,\n",
       "       20.27047918, 18.71215842, 42.78922264, 44.3457563 , 36.72684216,\n",
       "       30.57176688, 52.06724011, 27.99684721, 34.84377544, 73.94420236,\n",
       "       26.01031681, 15.26800413, 48.6991476 , 31.32049314, 57.85236734,\n",
       "       15.75299808, 63.63213067, 47.99116233, 26.60494363, 48.41946689,\n",
       "       27.68902379, 71.7084703 , 28.43913925, 27.6534133 , 48.67301055,\n",
       "       48.35936588, 77.38098512, 49.65782145, 47.1319929 , 45.60730479,\n",
       "       36.40600641, 18.6291581 , 33.21909858, 37.6772221 , 40.78699169,\n",
       "       55.95196699, 18.53987348, 26.98323331, 11.68088772, 27.50291276,\n",
       "       39.15909074, 33.84873447, 56.33109932, 41.58518578, 25.8929822 ,\n",
       "       25.42189312, 44.39666772, 34.42835433, 27.89576354, 29.90992543,\n",
       "       39.9366936 , 31.23540702, 31.63772072, 16.67591326, 24.28166587,\n",
       "       35.98066429, 50.7817922 , 29.61490225, 45.33306924, 27.77215141,\n",
       "       48.58097175, 19.51212044, 18.00842634, 60.3831218 , 27.5574986 ,\n",
       "       26.83280902, 27.24787467, 19.27097989, 44.85300983, 57.59155718,\n",
       "       21.82405565, 18.1878505 , 68.56040108, 21.56560216, 42.35764989,\n",
       "       53.30007881, 26.60540919, 13.27786061, 41.13313009, 42.60189273,\n",
       "       51.93187669, 44.53214202, 17.96834832, 77.48184736, 34.5154468 ,\n",
       "       34.8071028 , 45.15804647, 33.197517  , 50.3049293 , 43.70261492,\n",
       "       42.37017353, 45.1615026 , 27.62723411, 59.2665033 , 41.09906985,\n",
       "       33.27341868, 48.00433622, 26.66687209, 27.61602222, 24.25342173,\n",
       "       41.4809181 , 13.38201002, 18.02484818, 54.12218655, 18.46409973,\n",
       "       54.12218655, 10.95167616, 19.47650996, 28.15754849, 64.67538801,\n",
       "       52.0617154 ])"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "9601bd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lr1.predict(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "d141a1f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([39.66436745, 39.66436745])"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "1961666b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.91717833e+02,  2.38373239e+00,  6.53600770e+01,\n",
       "        -3.84530026e+00, -2.95593023e+01],\n",
       "       [ 2.92000613e+02, -1.89072278e+00,  7.75712119e+01,\n",
       "        -9.63268894e+00, -3.36879255e+01],\n",
       "       [ 7.99891422e+01,  1.73926739e+02,  5.41578689e+01,\n",
       "         5.96194526e+01,  5.75112600e+01],\n",
       "       ...,\n",
       "       [-1.52353897e+02,  4.84026489e+01, -5.11454305e+01,\n",
       "         5.44386880e+01,  1.03843456e+01],\n",
       "       [-1.32694183e+02,  8.57691108e+01,  1.83536449e+01,\n",
       "        -7.60006651e+01, -2.62142373e-02],\n",
       "       [-2.91604090e+01,  5.17468439e+01, -8.11015350e+01,\n",
       "         5.99503068e+01,  2.14463154e+01]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dimensionality reduction on train data.\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca2=PCA(n_components=5)\n",
    "x_pca=pca2.fit_transform(X)\n",
    "x_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "b50b771d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(x_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "ede1f49b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>291.717833</td>\n",
       "      <td>2.383732</td>\n",
       "      <td>65.360077</td>\n",
       "      <td>-3.845300</td>\n",
       "      <td>-29.559302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>292.000613</td>\n",
       "      <td>-1.890723</td>\n",
       "      <td>77.571212</td>\n",
       "      <td>-9.632689</td>\n",
       "      <td>-33.687925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.989142</td>\n",
       "      <td>173.926739</td>\n",
       "      <td>54.157869</td>\n",
       "      <td>59.619453</td>\n",
       "      <td>57.511260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.989142</td>\n",
       "      <td>173.926739</td>\n",
       "      <td>54.157869</td>\n",
       "      <td>59.619453</td>\n",
       "      <td>57.511260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-89.622581</td>\n",
       "      <td>33.410107</td>\n",
       "      <td>-15.902141</td>\n",
       "      <td>-81.124320</td>\n",
       "      <td>14.768581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.904089</td>\n",
       "      <td>111.754315</td>\n",
       "      <td>23.207672</td>\n",
       "      <td>24.838846</td>\n",
       "      <td>74.919105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>136.672462</td>\n",
       "      <td>140.180891</td>\n",
       "      <td>47.576703</td>\n",
       "      <td>67.979597</td>\n",
       "      <td>64.232857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>136.755885</td>\n",
       "      <td>140.406004</td>\n",
       "      <td>47.507332</td>\n",
       "      <td>67.803390</td>\n",
       "      <td>63.683834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.193743</td>\n",
       "      <td>112.535925</td>\n",
       "      <td>22.966812</td>\n",
       "      <td>24.227042</td>\n",
       "      <td>73.012854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>250.122524</td>\n",
       "      <td>72.914308</td>\n",
       "      <td>34.345000</td>\n",
       "      <td>84.523679</td>\n",
       "      <td>77.127028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-89.828811</td>\n",
       "      <td>32.853609</td>\n",
       "      <td>-15.730652</td>\n",
       "      <td>-80.688723</td>\n",
       "      <td>16.125810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-89.539158</td>\n",
       "      <td>33.635219</td>\n",
       "      <td>-15.971512</td>\n",
       "      <td>-81.300527</td>\n",
       "      <td>14.219559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>193.355781</td>\n",
       "      <td>106.435043</td>\n",
       "      <td>40.995536</td>\n",
       "      <td>76.339741</td>\n",
       "      <td>70.954454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-79.789222</td>\n",
       "      <td>165.747672</td>\n",
       "      <td>33.737538</td>\n",
       "      <td>11.462615</td>\n",
       "      <td>64.164551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>56.540399</td>\n",
       "      <td>85.539246</td>\n",
       "      <td>17.701879</td>\n",
       "      <td>30.915158</td>\n",
       "      <td>78.390132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>146.944056</td>\n",
       "      <td>30.764279</td>\n",
       "      <td>7.412873</td>\n",
       "      <td>44.903193</td>\n",
       "      <td>91.050938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-159.978025</td>\n",
       "      <td>77.820031</td>\n",
       "      <td>58.272930</td>\n",
       "      <td>-110.839424</td>\n",
       "      <td>-14.738176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.803631</td>\n",
       "      <td>58.317455</td>\n",
       "      <td>12.506316</td>\n",
       "      <td>37.779480</td>\n",
       "      <td>84.316431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>136.466232</td>\n",
       "      <td>139.624394</td>\n",
       "      <td>47.748192</td>\n",
       "      <td>68.415194</td>\n",
       "      <td>65.590086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>250.039101</td>\n",
       "      <td>72.689195</td>\n",
       "      <td>34.414370</td>\n",
       "      <td>84.699886</td>\n",
       "      <td>77.676050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>193.355781</td>\n",
       "      <td>106.435043</td>\n",
       "      <td>40.995536</td>\n",
       "      <td>76.339741</td>\n",
       "      <td>70.954454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-159.688371</td>\n",
       "      <td>78.601641</td>\n",
       "      <td>58.032070</td>\n",
       "      <td>-111.451227</td>\n",
       "      <td>-16.644427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-159.571576</td>\n",
       "      <td>78.916806</td>\n",
       "      <td>57.934949</td>\n",
       "      <td>-111.697922</td>\n",
       "      <td>-17.413077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-159.771795</td>\n",
       "      <td>78.376528</td>\n",
       "      <td>58.101441</td>\n",
       "      <td>-111.275021</td>\n",
       "      <td>-16.095405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>147.150286</td>\n",
       "      <td>31.320777</td>\n",
       "      <td>7.241383</td>\n",
       "      <td>44.467595</td>\n",
       "      <td>89.693709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>147.150286</td>\n",
       "      <td>31.320777</td>\n",
       "      <td>7.241383</td>\n",
       "      <td>44.467595</td>\n",
       "      <td>89.693709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>136.672462</td>\n",
       "      <td>140.180891</td>\n",
       "      <td>47.576703</td>\n",
       "      <td>67.979597</td>\n",
       "      <td>64.232857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>101.803631</td>\n",
       "      <td>58.317455</td>\n",
       "      <td>12.506316</td>\n",
       "      <td>37.779480</td>\n",
       "      <td>84.316431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>193.439205</td>\n",
       "      <td>106.660156</td>\n",
       "      <td>40.926166</td>\n",
       "      <td>76.163535</td>\n",
       "      <td>70.405431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>250.220633</td>\n",
       "      <td>73.179047</td>\n",
       "      <td>34.263418</td>\n",
       "      <td>84.316456</td>\n",
       "      <td>76.481362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>56.456975</td>\n",
       "      <td>85.314134</td>\n",
       "      <td>17.771249</td>\n",
       "      <td>31.091364</td>\n",
       "      <td>78.939154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>11.110319</td>\n",
       "      <td>112.310812</td>\n",
       "      <td>23.036182</td>\n",
       "      <td>24.403249</td>\n",
       "      <td>73.561877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-89.622581</td>\n",
       "      <td>33.410107</td>\n",
       "      <td>-15.902141</td>\n",
       "      <td>-81.124320</td>\n",
       "      <td>14.768581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>250.039101</td>\n",
       "      <td>72.689195</td>\n",
       "      <td>34.414370</td>\n",
       "      <td>84.699886</td>\n",
       "      <td>77.676050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-79.582992</td>\n",
       "      <td>166.304169</td>\n",
       "      <td>33.566049</td>\n",
       "      <td>11.027018</td>\n",
       "      <td>62.807322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-33.377497</td>\n",
       "      <td>241.418435</td>\n",
       "      <td>67.320202</td>\n",
       "      <td>42.899164</td>\n",
       "      <td>44.068067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-33.294073</td>\n",
       "      <td>241.643548</td>\n",
       "      <td>67.250831</td>\n",
       "      <td>42.722957</td>\n",
       "      <td>43.519044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>79.782912</td>\n",
       "      <td>173.370242</td>\n",
       "      <td>54.329359</td>\n",
       "      <td>60.055050</td>\n",
       "      <td>58.868489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>249.832871</td>\n",
       "      <td>72.132698</td>\n",
       "      <td>34.585860</td>\n",
       "      <td>85.135483</td>\n",
       "      <td>79.033279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-33.377497</td>\n",
       "      <td>241.418435</td>\n",
       "      <td>67.320202</td>\n",
       "      <td>42.899164</td>\n",
       "      <td>44.068067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>101.597401</td>\n",
       "      <td>57.760958</td>\n",
       "      <td>12.677806</td>\n",
       "      <td>38.215077</td>\n",
       "      <td>85.673660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>193.355781</td>\n",
       "      <td>106.435043</td>\n",
       "      <td>40.995536</td>\n",
       "      <td>76.339741</td>\n",
       "      <td>70.954454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-33.377497</td>\n",
       "      <td>241.418435</td>\n",
       "      <td>67.320202</td>\n",
       "      <td>42.899164</td>\n",
       "      <td>44.068067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>147.150286</td>\n",
       "      <td>31.320777</td>\n",
       "      <td>7.241383</td>\n",
       "      <td>44.467595</td>\n",
       "      <td>89.693709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>193.149551</td>\n",
       "      <td>105.878546</td>\n",
       "      <td>41.167026</td>\n",
       "      <td>76.775339</td>\n",
       "      <td>72.311682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>193.537313</td>\n",
       "      <td>106.924895</td>\n",
       "      <td>40.844584</td>\n",
       "      <td>75.956311</td>\n",
       "      <td>69.759765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>90.312363</td>\n",
       "      <td>-69.849101</td>\n",
       "      <td>28.922397</td>\n",
       "      <td>-74.842886</td>\n",
       "      <td>12.218552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>136.672462</td>\n",
       "      <td>140.180891</td>\n",
       "      <td>47.576703</td>\n",
       "      <td>67.979597</td>\n",
       "      <td>64.232857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-33.195965</td>\n",
       "      <td>241.908287</td>\n",
       "      <td>67.169249</td>\n",
       "      <td>42.515733</td>\n",
       "      <td>42.873378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>136.853994</td>\n",
       "      <td>140.670743</td>\n",
       "      <td>47.425751</td>\n",
       "      <td>67.596167</td>\n",
       "      <td>63.038169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>79.989142</td>\n",
       "      <td>173.926739</td>\n",
       "      <td>54.157869</td>\n",
       "      <td>59.619453</td>\n",
       "      <td>57.511260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-79.582992</td>\n",
       "      <td>166.304169</td>\n",
       "      <td>33.566049</td>\n",
       "      <td>11.027018</td>\n",
       "      <td>62.807322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-33.583727</td>\n",
       "      <td>240.861938</td>\n",
       "      <td>67.491691</td>\n",
       "      <td>43.334761</td>\n",
       "      <td>45.425295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>56.250745</td>\n",
       "      <td>84.757636</td>\n",
       "      <td>17.942739</td>\n",
       "      <td>31.526961</td>\n",
       "      <td>80.296383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-159.590263</td>\n",
       "      <td>78.866380</td>\n",
       "      <td>57.950489</td>\n",
       "      <td>-111.658451</td>\n",
       "      <td>-17.290093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-89.441049</td>\n",
       "      <td>33.899958</td>\n",
       "      <td>-16.053093</td>\n",
       "      <td>-81.507751</td>\n",
       "      <td>13.573893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>250.039101</td>\n",
       "      <td>72.689195</td>\n",
       "      <td>34.414370</td>\n",
       "      <td>84.699886</td>\n",
       "      <td>77.676050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-89.422362</td>\n",
       "      <td>33.950385</td>\n",
       "      <td>-16.068633</td>\n",
       "      <td>-81.547222</td>\n",
       "      <td>13.450909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>56.456975</td>\n",
       "      <td>85.314134</td>\n",
       "      <td>17.771249</td>\n",
       "      <td>31.091364</td>\n",
       "      <td>78.939154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>80.072566</td>\n",
       "      <td>174.151852</td>\n",
       "      <td>54.088498</td>\n",
       "      <td>59.443246</td>\n",
       "      <td>56.962238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>56.456975</td>\n",
       "      <td>85.314134</td>\n",
       "      <td>17.771249</td>\n",
       "      <td>31.091364</td>\n",
       "      <td>78.939154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>11.110319</td>\n",
       "      <td>112.310812</td>\n",
       "      <td>23.036182</td>\n",
       "      <td>24.403249</td>\n",
       "      <td>73.561877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>43.815268</td>\n",
       "      <td>-71.046434</td>\n",
       "      <td>-51.069868</td>\n",
       "      <td>-68.721741</td>\n",
       "      <td>34.526795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-79.582992</td>\n",
       "      <td>166.304169</td>\n",
       "      <td>33.566049</td>\n",
       "      <td>11.027018</td>\n",
       "      <td>62.807322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>11.110319</td>\n",
       "      <td>112.310812</td>\n",
       "      <td>23.036182</td>\n",
       "      <td>24.403249</td>\n",
       "      <td>73.561877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>101.803631</td>\n",
       "      <td>58.317455</td>\n",
       "      <td>12.506316</td>\n",
       "      <td>37.779480</td>\n",
       "      <td>84.316431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-159.771795</td>\n",
       "      <td>78.376528</td>\n",
       "      <td>58.101441</td>\n",
       "      <td>-111.275021</td>\n",
       "      <td>-16.095405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>80.170674</td>\n",
       "      <td>174.416591</td>\n",
       "      <td>54.006917</td>\n",
       "      <td>59.236022</td>\n",
       "      <td>56.316572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-79.499568</td>\n",
       "      <td>166.529282</td>\n",
       "      <td>33.496678</td>\n",
       "      <td>10.850811</td>\n",
       "      <td>62.258299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>215.458549</td>\n",
       "      <td>-83.166143</td>\n",
       "      <td>70.011302</td>\n",
       "      <td>-101.498763</td>\n",
       "      <td>-74.468317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>66.619812</td>\n",
       "      <td>133.633617</td>\n",
       "      <td>-49.947654</td>\n",
       "      <td>-36.166913</td>\n",
       "      <td>-53.781544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>25.688999</td>\n",
       "      <td>220.296465</td>\n",
       "      <td>137.389439</td>\n",
       "      <td>-18.008902</td>\n",
       "      <td>-57.992566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>105.724568</td>\n",
       "      <td>31.351561</td>\n",
       "      <td>-189.541646</td>\n",
       "      <td>-63.105899</td>\n",
       "      <td>-55.646765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>126.131350</td>\n",
       "      <td>46.446079</td>\n",
       "      <td>-74.808866</td>\n",
       "      <td>-50.896810</td>\n",
       "      <td>-56.260965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>90.311301</td>\n",
       "      <td>74.658703</td>\n",
       "      <td>-117.271006</td>\n",
       "      <td>1.893465</td>\n",
       "      <td>13.214791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>171.331395</td>\n",
       "      <td>95.738693</td>\n",
       "      <td>-138.512940</td>\n",
       "      <td>-8.217333</td>\n",
       "      <td>-36.095912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>153.070058</td>\n",
       "      <td>66.524259</td>\n",
       "      <td>-170.353704</td>\n",
       "      <td>-39.499812</td>\n",
       "      <td>-49.195327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>66.897064</td>\n",
       "      <td>4.326012</td>\n",
       "      <td>-204.928020</td>\n",
       "      <td>-81.882027</td>\n",
       "      <td>-46.736771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>231.047177</td>\n",
       "      <td>-48.117634</td>\n",
       "      <td>-207.939132</td>\n",
       "      <td>-48.692109</td>\n",
       "      <td>-46.919594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-19.462926</td>\n",
       "      <td>110.129019</td>\n",
       "      <td>-171.036587</td>\n",
       "      <td>-78.189171</td>\n",
       "      <td>-67.555099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>97.847379</td>\n",
       "      <td>10.044304</td>\n",
       "      <td>-88.984010</td>\n",
       "      <td>-79.120726</td>\n",
       "      <td>-60.203595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>56.896982</td>\n",
       "      <td>127.512083</td>\n",
       "      <td>-32.559205</td>\n",
       "      <td>-42.940853</td>\n",
       "      <td>-57.062281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>16.293824</td>\n",
       "      <td>244.512400</td>\n",
       "      <td>23.724098</td>\n",
       "      <td>-6.911576</td>\n",
       "      <td>-53.134675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>120.701350</td>\n",
       "      <td>115.345407</td>\n",
       "      <td>203.758213</td>\n",
       "      <td>-29.015230</td>\n",
       "      <td>-59.247547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>-25.264567</td>\n",
       "      <td>90.994917</td>\n",
       "      <td>1.219024</td>\n",
       "      <td>-94.300767</td>\n",
       "      <td>-75.363876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>139.191963</td>\n",
       "      <td>164.003997</td>\n",
       "      <td>-66.246772</td>\n",
       "      <td>8.408296</td>\n",
       "      <td>-38.274835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>81.316286</td>\n",
       "      <td>127.617853</td>\n",
       "      <td>-37.291546</td>\n",
       "      <td>-43.520931</td>\n",
       "      <td>-76.452797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>34.705084</td>\n",
       "      <td>126.822256</td>\n",
       "      <td>-28.463857</td>\n",
       "      <td>-42.494260</td>\n",
       "      <td>-43.517991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>66.601124</td>\n",
       "      <td>133.583191</td>\n",
       "      <td>-49.932115</td>\n",
       "      <td>-36.127442</td>\n",
       "      <td>-53.658560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>25.670312</td>\n",
       "      <td>220.246038</td>\n",
       "      <td>137.404979</td>\n",
       "      <td>-17.969430</td>\n",
       "      <td>-57.869582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>105.705881</td>\n",
       "      <td>31.301134</td>\n",
       "      <td>-189.526107</td>\n",
       "      <td>-63.066428</td>\n",
       "      <td>-55.523781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>126.112662</td>\n",
       "      <td>46.395653</td>\n",
       "      <td>-74.793327</td>\n",
       "      <td>-50.857339</td>\n",
       "      <td>-56.137981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>90.292614</td>\n",
       "      <td>74.608276</td>\n",
       "      <td>-117.255467</td>\n",
       "      <td>1.932937</td>\n",
       "      <td>13.337775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>171.312707</td>\n",
       "      <td>95.688267</td>\n",
       "      <td>-138.497401</td>\n",
       "      <td>-8.177862</td>\n",
       "      <td>-35.972928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>153.051371</td>\n",
       "      <td>66.473833</td>\n",
       "      <td>-170.338165</td>\n",
       "      <td>-39.460341</td>\n",
       "      <td>-49.072343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>66.878376</td>\n",
       "      <td>4.275586</td>\n",
       "      <td>-204.912481</td>\n",
       "      <td>-81.842556</td>\n",
       "      <td>-46.613787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>231.028490</td>\n",
       "      <td>-48.168061</td>\n",
       "      <td>-207.923592</td>\n",
       "      <td>-48.652638</td>\n",
       "      <td>-46.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-19.481613</td>\n",
       "      <td>110.078592</td>\n",
       "      <td>-171.021047</td>\n",
       "      <td>-78.149700</td>\n",
       "      <td>-67.432115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>97.828692</td>\n",
       "      <td>9.993878</td>\n",
       "      <td>-88.968470</td>\n",
       "      <td>-79.081255</td>\n",
       "      <td>-60.080611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>56.878295</td>\n",
       "      <td>127.461657</td>\n",
       "      <td>-32.543666</td>\n",
       "      <td>-42.901382</td>\n",
       "      <td>-56.939297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>16.275137</td>\n",
       "      <td>244.461974</td>\n",
       "      <td>23.739638</td>\n",
       "      <td>-6.872105</td>\n",
       "      <td>-53.011691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>120.682663</td>\n",
       "      <td>115.294981</td>\n",
       "      <td>203.773753</td>\n",
       "      <td>-28.975759</td>\n",
       "      <td>-59.124563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-25.283254</td>\n",
       "      <td>90.944490</td>\n",
       "      <td>1.234563</td>\n",
       "      <td>-94.261296</td>\n",
       "      <td>-75.240892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>139.173276</td>\n",
       "      <td>163.953570</td>\n",
       "      <td>-66.231232</td>\n",
       "      <td>8.447768</td>\n",
       "      <td>-38.151851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>81.297599</td>\n",
       "      <td>127.567426</td>\n",
       "      <td>-37.276007</td>\n",
       "      <td>-43.481460</td>\n",
       "      <td>-76.329813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>56.878295</td>\n",
       "      <td>127.461657</td>\n",
       "      <td>-32.543666</td>\n",
       "      <td>-42.901382</td>\n",
       "      <td>-56.939297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>34.686397</td>\n",
       "      <td>126.771829</td>\n",
       "      <td>-28.448318</td>\n",
       "      <td>-42.454788</td>\n",
       "      <td>-43.395007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>66.503016</td>\n",
       "      <td>133.318452</td>\n",
       "      <td>-49.850533</td>\n",
       "      <td>-35.920218</td>\n",
       "      <td>-53.012894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>25.572203</td>\n",
       "      <td>219.981299</td>\n",
       "      <td>137.486560</td>\n",
       "      <td>-17.762207</td>\n",
       "      <td>-57.223916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>105.607772</td>\n",
       "      <td>31.036395</td>\n",
       "      <td>-189.444525</td>\n",
       "      <td>-62.859204</td>\n",
       "      <td>-54.878115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>126.014554</td>\n",
       "      <td>46.130914</td>\n",
       "      <td>-74.711745</td>\n",
       "      <td>-50.650115</td>\n",
       "      <td>-55.492315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>90.194506</td>\n",
       "      <td>74.343537</td>\n",
       "      <td>-117.173885</td>\n",
       "      <td>2.140160</td>\n",
       "      <td>13.983440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>171.214599</td>\n",
       "      <td>95.423528</td>\n",
       "      <td>-138.415819</td>\n",
       "      <td>-7.970638</td>\n",
       "      <td>-35.327262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>152.953263</td>\n",
       "      <td>66.209094</td>\n",
       "      <td>-170.256583</td>\n",
       "      <td>-39.253117</td>\n",
       "      <td>-48.426677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>66.780268</td>\n",
       "      <td>4.010847</td>\n",
       "      <td>-204.830899</td>\n",
       "      <td>-81.635332</td>\n",
       "      <td>-45.968121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>230.930381</td>\n",
       "      <td>-48.432799</td>\n",
       "      <td>-207.842011</td>\n",
       "      <td>-48.445414</td>\n",
       "      <td>-46.150944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>-19.579722</td>\n",
       "      <td>109.813854</td>\n",
       "      <td>-170.939466</td>\n",
       "      <td>-77.942476</td>\n",
       "      <td>-66.786449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>97.730583</td>\n",
       "      <td>9.729139</td>\n",
       "      <td>-88.886889</td>\n",
       "      <td>-78.874031</td>\n",
       "      <td>-59.434945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>56.780186</td>\n",
       "      <td>127.196918</td>\n",
       "      <td>-32.462084</td>\n",
       "      <td>-42.694158</td>\n",
       "      <td>-56.293632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>16.177028</td>\n",
       "      <td>244.197235</td>\n",
       "      <td>23.821219</td>\n",
       "      <td>-6.664881</td>\n",
       "      <td>-52.366025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>120.584554</td>\n",
       "      <td>115.030242</td>\n",
       "      <td>203.855334</td>\n",
       "      <td>-28.768535</td>\n",
       "      <td>-58.478897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>-25.381362</td>\n",
       "      <td>90.679751</td>\n",
       "      <td>1.316145</td>\n",
       "      <td>-94.054072</td>\n",
       "      <td>-74.595226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>139.075167</td>\n",
       "      <td>163.688831</td>\n",
       "      <td>-66.149651</td>\n",
       "      <td>8.654991</td>\n",
       "      <td>-37.506185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>81.199490</td>\n",
       "      <td>127.302687</td>\n",
       "      <td>-37.194425</td>\n",
       "      <td>-43.274236</td>\n",
       "      <td>-75.684147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>34.588288</td>\n",
       "      <td>126.507090</td>\n",
       "      <td>-28.366736</td>\n",
       "      <td>-42.247564</td>\n",
       "      <td>-42.749341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>66.372204</td>\n",
       "      <td>132.965467</td>\n",
       "      <td>-49.741758</td>\n",
       "      <td>-35.643920</td>\n",
       "      <td>-52.152006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>25.441392</td>\n",
       "      <td>219.628314</td>\n",
       "      <td>137.595336</td>\n",
       "      <td>-17.485908</td>\n",
       "      <td>-56.363028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>105.476961</td>\n",
       "      <td>30.683410</td>\n",
       "      <td>-189.335749</td>\n",
       "      <td>-62.582905</td>\n",
       "      <td>-54.017227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>125.883742</td>\n",
       "      <td>45.777928</td>\n",
       "      <td>-74.602970</td>\n",
       "      <td>-50.373817</td>\n",
       "      <td>-54.631427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>90.063694</td>\n",
       "      <td>73.990552</td>\n",
       "      <td>-117.065109</td>\n",
       "      <td>2.416459</td>\n",
       "      <td>14.844328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>171.083788</td>\n",
       "      <td>95.070543</td>\n",
       "      <td>-138.307043</td>\n",
       "      <td>-7.694340</td>\n",
       "      <td>-34.466375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>152.822451</td>\n",
       "      <td>65.856109</td>\n",
       "      <td>-170.147808</td>\n",
       "      <td>-38.976819</td>\n",
       "      <td>-47.565790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>66.649457</td>\n",
       "      <td>3.657861</td>\n",
       "      <td>-204.722124</td>\n",
       "      <td>-81.359033</td>\n",
       "      <td>-45.107234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>230.799570</td>\n",
       "      <td>-48.785785</td>\n",
       "      <td>-207.733235</td>\n",
       "      <td>-48.169116</td>\n",
       "      <td>-45.290057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>-19.710533</td>\n",
       "      <td>109.460868</td>\n",
       "      <td>-170.830690</td>\n",
       "      <td>-77.666178</td>\n",
       "      <td>-65.925562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>97.599772</td>\n",
       "      <td>9.376153</td>\n",
       "      <td>-88.778113</td>\n",
       "      <td>-78.597732</td>\n",
       "      <td>-58.574057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>56.649375</td>\n",
       "      <td>126.843933</td>\n",
       "      <td>-32.353309</td>\n",
       "      <td>-42.417860</td>\n",
       "      <td>-55.432744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>16.046217</td>\n",
       "      <td>243.844250</td>\n",
       "      <td>23.929995</td>\n",
       "      <td>-6.388583</td>\n",
       "      <td>-51.505138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>120.453743</td>\n",
       "      <td>114.677256</td>\n",
       "      <td>203.964110</td>\n",
       "      <td>-28.492237</td>\n",
       "      <td>-57.618010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>-25.512174</td>\n",
       "      <td>90.326766</td>\n",
       "      <td>1.424920</td>\n",
       "      <td>-93.777773</td>\n",
       "      <td>-73.734339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>138.944356</td>\n",
       "      <td>163.335846</td>\n",
       "      <td>-66.040875</td>\n",
       "      <td>8.931290</td>\n",
       "      <td>-36.645297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>81.068679</td>\n",
       "      <td>126.949702</td>\n",
       "      <td>-37.085650</td>\n",
       "      <td>-42.997938</td>\n",
       "      <td>-74.823260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>34.457477</td>\n",
       "      <td>126.154105</td>\n",
       "      <td>-28.257961</td>\n",
       "      <td>-41.971266</td>\n",
       "      <td>-41.888453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>66.208690</td>\n",
       "      <td>132.524235</td>\n",
       "      <td>-49.605788</td>\n",
       "      <td>-35.298547</td>\n",
       "      <td>-51.075897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>25.277878</td>\n",
       "      <td>219.187083</td>\n",
       "      <td>137.731305</td>\n",
       "      <td>-17.140535</td>\n",
       "      <td>-55.286919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>105.313447</td>\n",
       "      <td>30.242178</td>\n",
       "      <td>-189.199780</td>\n",
       "      <td>-62.237532</td>\n",
       "      <td>-52.941118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>125.720228</td>\n",
       "      <td>45.336697</td>\n",
       "      <td>-74.467000</td>\n",
       "      <td>-50.028444</td>\n",
       "      <td>-53.555318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>89.900180</td>\n",
       "      <td>73.549320</td>\n",
       "      <td>-116.929140</td>\n",
       "      <td>2.761832</td>\n",
       "      <td>15.920437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>170.920273</td>\n",
       "      <td>94.629311</td>\n",
       "      <td>-138.171074</td>\n",
       "      <td>-7.348967</td>\n",
       "      <td>-33.390265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>152.658937</td>\n",
       "      <td>65.414877</td>\n",
       "      <td>-170.011838</td>\n",
       "      <td>-38.631446</td>\n",
       "      <td>-46.489680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>66.485942</td>\n",
       "      <td>3.216630</td>\n",
       "      <td>-204.586154</td>\n",
       "      <td>-81.013660</td>\n",
       "      <td>-44.031124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>230.636056</td>\n",
       "      <td>-49.227016</td>\n",
       "      <td>-207.597266</td>\n",
       "      <td>-47.823743</td>\n",
       "      <td>-44.213947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-19.874047</td>\n",
       "      <td>109.019637</td>\n",
       "      <td>-170.694721</td>\n",
       "      <td>-77.320805</td>\n",
       "      <td>-64.849452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>97.436258</td>\n",
       "      <td>8.934922</td>\n",
       "      <td>-88.642144</td>\n",
       "      <td>-78.252359</td>\n",
       "      <td>-57.497948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>56.485861</td>\n",
       "      <td>126.402701</td>\n",
       "      <td>-32.217339</td>\n",
       "      <td>-42.072487</td>\n",
       "      <td>-54.356635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>120.290229</td>\n",
       "      <td>114.236025</td>\n",
       "      <td>204.100079</td>\n",
       "      <td>-28.146864</td>\n",
       "      <td>-56.541900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>-25.675688</td>\n",
       "      <td>89.885534</td>\n",
       "      <td>1.560890</td>\n",
       "      <td>-93.432400</td>\n",
       "      <td>-72.658229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>138.780842</td>\n",
       "      <td>162.894615</td>\n",
       "      <td>-65.904906</td>\n",
       "      <td>9.276663</td>\n",
       "      <td>-35.569188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>80.905165</td>\n",
       "      <td>126.508471</td>\n",
       "      <td>-36.949680</td>\n",
       "      <td>-42.652564</td>\n",
       "      <td>-73.747150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>34.293963</td>\n",
       "      <td>125.712873</td>\n",
       "      <td>-28.121991</td>\n",
       "      <td>-41.625893</td>\n",
       "      <td>-40.812344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-61.384644</td>\n",
       "      <td>-114.506709</td>\n",
       "      <td>-49.828923</td>\n",
       "      <td>-6.974338</td>\n",
       "      <td>10.887453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>-61.436034</td>\n",
       "      <td>-114.645382</td>\n",
       "      <td>-49.786190</td>\n",
       "      <td>-6.865792</td>\n",
       "      <td>11.225658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>-61.501440</td>\n",
       "      <td>-114.821875</td>\n",
       "      <td>-49.731802</td>\n",
       "      <td>-6.727643</td>\n",
       "      <td>11.656102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-61.632251</td>\n",
       "      <td>-115.174860</td>\n",
       "      <td>-49.623027</td>\n",
       "      <td>-6.451345</td>\n",
       "      <td>12.516990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>-61.837812</td>\n",
       "      <td>-115.729551</td>\n",
       "      <td>-49.452094</td>\n",
       "      <td>-6.017161</td>\n",
       "      <td>13.869813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>-46.792321</td>\n",
       "      <td>-98.272890</td>\n",
       "      <td>-57.784843</td>\n",
       "      <td>9.244535</td>\n",
       "      <td>22.520065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-46.843711</td>\n",
       "      <td>-98.411563</td>\n",
       "      <td>-57.742110</td>\n",
       "      <td>9.353081</td>\n",
       "      <td>22.858271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-46.909117</td>\n",
       "      <td>-98.588055</td>\n",
       "      <td>-57.687722</td>\n",
       "      <td>9.491230</td>\n",
       "      <td>23.288715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-47.039928</td>\n",
       "      <td>-98.941040</td>\n",
       "      <td>-57.578946</td>\n",
       "      <td>9.767529</td>\n",
       "      <td>24.149603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-47.245489</td>\n",
       "      <td>-99.495731</td>\n",
       "      <td>-57.408014</td>\n",
       "      <td>10.201712</td>\n",
       "      <td>25.502426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-94.725208</td>\n",
       "      <td>-147.110499</td>\n",
       "      <td>-33.485191</td>\n",
       "      <td>-39.108344</td>\n",
       "      <td>-13.394956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-94.776598</td>\n",
       "      <td>-147.249171</td>\n",
       "      <td>-33.442458</td>\n",
       "      <td>-38.999798</td>\n",
       "      <td>-13.056751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>-94.842004</td>\n",
       "      <td>-147.425664</td>\n",
       "      <td>-33.388070</td>\n",
       "      <td>-38.861649</td>\n",
       "      <td>-12.626307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>-94.972815</td>\n",
       "      <td>-147.778649</td>\n",
       "      <td>-33.279294</td>\n",
       "      <td>-38.585351</td>\n",
       "      <td>-11.765419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-95.178376</td>\n",
       "      <td>-148.333340</td>\n",
       "      <td>-33.108361</td>\n",
       "      <td>-38.151167</td>\n",
       "      <td>-10.412596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-79.301391</td>\n",
       "      <td>-131.263863</td>\n",
       "      <td>92.345676</td>\n",
       "      <td>1.129861</td>\n",
       "      <td>-20.206079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>-79.352781</td>\n",
       "      <td>-131.402536</td>\n",
       "      <td>92.388410</td>\n",
       "      <td>1.238407</td>\n",
       "      <td>-19.867873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-79.418186</td>\n",
       "      <td>-131.579029</td>\n",
       "      <td>92.442797</td>\n",
       "      <td>1.376556</td>\n",
       "      <td>-19.437430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-79.548998</td>\n",
       "      <td>-131.932014</td>\n",
       "      <td>92.551573</td>\n",
       "      <td>1.652854</td>\n",
       "      <td>-18.576542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-79.754558</td>\n",
       "      <td>-132.486705</td>\n",
       "      <td>92.722506</td>\n",
       "      <td>2.087038</td>\n",
       "      <td>-17.223719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-54.032101</td>\n",
       "      <td>-106.574416</td>\n",
       "      <td>76.494615</td>\n",
       "      <td>24.655566</td>\n",
       "      <td>-1.358398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-54.083491</td>\n",
       "      <td>-106.713089</td>\n",
       "      <td>76.537348</td>\n",
       "      <td>24.764112</td>\n",
       "      <td>-1.020192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>-54.148897</td>\n",
       "      <td>-106.889581</td>\n",
       "      <td>76.591736</td>\n",
       "      <td>24.902261</td>\n",
       "      <td>-0.589748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>-54.279708</td>\n",
       "      <td>-107.242566</td>\n",
       "      <td>76.700511</td>\n",
       "      <td>25.178560</td>\n",
       "      <td>0.271139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>-54.485269</td>\n",
       "      <td>-107.797257</td>\n",
       "      <td>76.871444</td>\n",
       "      <td>25.612743</td>\n",
       "      <td>1.623963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>-32.862165</td>\n",
       "      <td>-85.533347</td>\n",
       "      <td>62.371227</td>\n",
       "      <td>44.709343</td>\n",
       "      <td>14.722223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-32.913555</td>\n",
       "      <td>-85.672020</td>\n",
       "      <td>62.413960</td>\n",
       "      <td>44.817888</td>\n",
       "      <td>15.060429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>-32.978961</td>\n",
       "      <td>-85.848513</td>\n",
       "      <td>62.468348</td>\n",
       "      <td>44.956038</td>\n",
       "      <td>15.490873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>-33.109772</td>\n",
       "      <td>-86.201498</td>\n",
       "      <td>62.577123</td>\n",
       "      <td>45.232336</td>\n",
       "      <td>16.351760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>-33.315333</td>\n",
       "      <td>-86.756189</td>\n",
       "      <td>62.748056</td>\n",
       "      <td>45.666519</td>\n",
       "      <td>17.704584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-79.287854</td>\n",
       "      <td>-130.041250</td>\n",
       "      <td>91.608480</td>\n",
       "      <td>2.512332</td>\n",
       "      <td>-19.379062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>-79.339245</td>\n",
       "      <td>-130.179922</td>\n",
       "      <td>91.651213</td>\n",
       "      <td>2.620878</td>\n",
       "      <td>-19.040856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-79.404650</td>\n",
       "      <td>-130.356415</td>\n",
       "      <td>91.705601</td>\n",
       "      <td>2.759027</td>\n",
       "      <td>-18.610412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-79.535462</td>\n",
       "      <td>-130.709400</td>\n",
       "      <td>91.814377</td>\n",
       "      <td>3.035326</td>\n",
       "      <td>-17.749524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-79.741022</td>\n",
       "      <td>-131.264091</td>\n",
       "      <td>91.985309</td>\n",
       "      <td>3.469509</td>\n",
       "      <td>-16.396701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-104.980807</td>\n",
       "      <td>-123.117439</td>\n",
       "      <td>84.851219</td>\n",
       "      <td>54.193666</td>\n",
       "      <td>-8.141046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-105.032197</td>\n",
       "      <td>-123.256111</td>\n",
       "      <td>84.893953</td>\n",
       "      <td>54.302212</td>\n",
       "      <td>-7.802840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-105.097603</td>\n",
       "      <td>-123.432604</td>\n",
       "      <td>84.948340</td>\n",
       "      <td>54.440361</td>\n",
       "      <td>-7.372396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-105.228414</td>\n",
       "      <td>-123.785589</td>\n",
       "      <td>85.057116</td>\n",
       "      <td>54.716660</td>\n",
       "      <td>-6.511508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-105.433975</td>\n",
       "      <td>-124.340280</td>\n",
       "      <td>85.228049</td>\n",
       "      <td>55.150843</td>\n",
       "      <td>-5.158685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-115.643019</td>\n",
       "      <td>-90.383851</td>\n",
       "      <td>83.784081</td>\n",
       "      <td>47.213587</td>\n",
       "      <td>-27.450676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-115.694409</td>\n",
       "      <td>-90.522523</td>\n",
       "      <td>83.826814</td>\n",
       "      <td>47.322133</td>\n",
       "      <td>-27.112470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-115.759815</td>\n",
       "      <td>-90.699016</td>\n",
       "      <td>83.881202</td>\n",
       "      <td>47.460282</td>\n",
       "      <td>-26.682026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-115.890626</td>\n",
       "      <td>-91.052001</td>\n",
       "      <td>83.989978</td>\n",
       "      <td>47.736581</td>\n",
       "      <td>-25.821139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-116.096187</td>\n",
       "      <td>-91.606692</td>\n",
       "      <td>84.160911</td>\n",
       "      <td>48.170764</td>\n",
       "      <td>-24.468315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-60.648751</td>\n",
       "      <td>-6.060534</td>\n",
       "      <td>75.924565</td>\n",
       "      <td>-70.052295</td>\n",
       "      <td>-5.246060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-60.700141</td>\n",
       "      <td>-6.199207</td>\n",
       "      <td>75.967298</td>\n",
       "      <td>-69.943749</td>\n",
       "      <td>-4.907854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-60.765547</td>\n",
       "      <td>-6.375699</td>\n",
       "      <td>76.021686</td>\n",
       "      <td>-69.805600</td>\n",
       "      <td>-4.477410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-60.896358</td>\n",
       "      <td>-6.728685</td>\n",
       "      <td>76.130461</td>\n",
       "      <td>-69.529302</td>\n",
       "      <td>-3.616523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-61.101919</td>\n",
       "      <td>-7.283376</td>\n",
       "      <td>76.301394</td>\n",
       "      <td>-69.095118</td>\n",
       "      <td>-2.263699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-60.644284</td>\n",
       "      <td>-6.172869</td>\n",
       "      <td>76.006178</td>\n",
       "      <td>-70.203829</td>\n",
       "      <td>-5.331634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-60.695674</td>\n",
       "      <td>-6.311542</td>\n",
       "      <td>76.048912</td>\n",
       "      <td>-70.095283</td>\n",
       "      <td>-4.993428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-60.761080</td>\n",
       "      <td>-6.488034</td>\n",
       "      <td>76.103299</td>\n",
       "      <td>-69.957134</td>\n",
       "      <td>-4.562984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-60.891891</td>\n",
       "      <td>-6.841019</td>\n",
       "      <td>76.212075</td>\n",
       "      <td>-69.680835</td>\n",
       "      <td>-3.702096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-61.097452</td>\n",
       "      <td>-7.395711</td>\n",
       "      <td>76.383008</td>\n",
       "      <td>-69.246652</td>\n",
       "      <td>-2.349273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-32.908041</td>\n",
       "      <td>-84.709356</td>\n",
       "      <td>61.868282</td>\n",
       "      <td>45.649633</td>\n",
       "      <td>15.280375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>-32.959431</td>\n",
       "      <td>-84.848029</td>\n",
       "      <td>61.911015</td>\n",
       "      <td>45.758179</td>\n",
       "      <td>15.618581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-33.024837</td>\n",
       "      <td>-85.024521</td>\n",
       "      <td>61.965403</td>\n",
       "      <td>45.896328</td>\n",
       "      <td>16.049025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-33.155648</td>\n",
       "      <td>-85.377507</td>\n",
       "      <td>62.074178</td>\n",
       "      <td>46.172626</td>\n",
       "      <td>16.909913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-33.361209</td>\n",
       "      <td>-85.932198</td>\n",
       "      <td>62.245111</td>\n",
       "      <td>46.606810</td>\n",
       "      <td>18.262736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-41.747870</td>\n",
       "      <td>-97.154170</td>\n",
       "      <td>-53.428604</td>\n",
       "      <td>10.152295</td>\n",
       "      <td>16.510239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-41.799260</td>\n",
       "      <td>-97.292843</td>\n",
       "      <td>-53.385871</td>\n",
       "      <td>10.260841</td>\n",
       "      <td>16.848444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>-41.864666</td>\n",
       "      <td>-97.469335</td>\n",
       "      <td>-53.331483</td>\n",
       "      <td>10.398990</td>\n",
       "      <td>17.278888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>-41.995477</td>\n",
       "      <td>-97.822320</td>\n",
       "      <td>-53.222708</td>\n",
       "      <td>10.675289</td>\n",
       "      <td>18.139776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-42.201038</td>\n",
       "      <td>-98.377012</td>\n",
       "      <td>-53.051775</td>\n",
       "      <td>11.109472</td>\n",
       "      <td>19.492599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>-34.374772</td>\n",
       "      <td>-105.494636</td>\n",
       "      <td>-57.519781</td>\n",
       "      <td>0.984433</td>\n",
       "      <td>6.056737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>-34.426162</td>\n",
       "      <td>-105.633309</td>\n",
       "      <td>-57.477047</td>\n",
       "      <td>1.092978</td>\n",
       "      <td>6.394943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>-34.491568</td>\n",
       "      <td>-105.809801</td>\n",
       "      <td>-57.422660</td>\n",
       "      <td>1.231128</td>\n",
       "      <td>6.825387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>-34.622379</td>\n",
       "      <td>-106.162787</td>\n",
       "      <td>-57.313884</td>\n",
       "      <td>1.507426</td>\n",
       "      <td>7.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>-34.827940</td>\n",
       "      <td>-106.717478</td>\n",
       "      <td>-57.142951</td>\n",
       "      <td>1.941609</td>\n",
       "      <td>9.039098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>-78.105667</td>\n",
       "      <td>-145.806971</td>\n",
       "      <td>-34.003392</td>\n",
       "      <td>-38.816216</td>\n",
       "      <td>-22.379766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>-78.157058</td>\n",
       "      <td>-145.945644</td>\n",
       "      <td>-33.960659</td>\n",
       "      <td>-38.707670</td>\n",
       "      <td>-22.041560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>-78.222463</td>\n",
       "      <td>-146.122136</td>\n",
       "      <td>-33.906271</td>\n",
       "      <td>-38.569521</td>\n",
       "      <td>-21.611116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-78.353275</td>\n",
       "      <td>-146.475122</td>\n",
       "      <td>-33.797496</td>\n",
       "      <td>-38.293223</td>\n",
       "      <td>-20.750229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>-78.558835</td>\n",
       "      <td>-147.029813</td>\n",
       "      <td>-33.626563</td>\n",
       "      <td>-37.859039</td>\n",
       "      <td>-19.397405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-78.194539</td>\n",
       "      <td>-144.770660</td>\n",
       "      <td>-37.401688</td>\n",
       "      <td>-37.316958</td>\n",
       "      <td>-21.502513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-78.245929</td>\n",
       "      <td>-144.909333</td>\n",
       "      <td>-37.358954</td>\n",
       "      <td>-37.208412</td>\n",
       "      <td>-21.164307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>-78.311335</td>\n",
       "      <td>-145.085825</td>\n",
       "      <td>-37.304567</td>\n",
       "      <td>-37.070263</td>\n",
       "      <td>-20.733864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>-78.442146</td>\n",
       "      <td>-145.438810</td>\n",
       "      <td>-37.195791</td>\n",
       "      <td>-36.793964</td>\n",
       "      <td>-19.872976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-78.647707</td>\n",
       "      <td>-145.993502</td>\n",
       "      <td>-37.024858</td>\n",
       "      <td>-36.359781</td>\n",
       "      <td>-18.520152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>-59.030383</td>\n",
       "      <td>-126.632822</td>\n",
       "      <td>87.636486</td>\n",
       "      <td>4.627766</td>\n",
       "      <td>-26.352869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>-59.081773</td>\n",
       "      <td>-126.771495</td>\n",
       "      <td>87.679219</td>\n",
       "      <td>4.736312</td>\n",
       "      <td>-26.014663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>-59.147179</td>\n",
       "      <td>-126.947987</td>\n",
       "      <td>87.733607</td>\n",
       "      <td>4.874461</td>\n",
       "      <td>-25.584219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-59.277990</td>\n",
       "      <td>-127.300973</td>\n",
       "      <td>87.842382</td>\n",
       "      <td>5.150760</td>\n",
       "      <td>-24.723331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>-59.483551</td>\n",
       "      <td>-127.855664</td>\n",
       "      <td>88.013315</td>\n",
       "      <td>5.584943</td>\n",
       "      <td>-23.370508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>-36.159821</td>\n",
       "      <td>-105.145758</td>\n",
       "      <td>72.767560</td>\n",
       "      <td>25.274196</td>\n",
       "      <td>-10.765681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>-36.211211</td>\n",
       "      <td>-105.284431</td>\n",
       "      <td>72.810293</td>\n",
       "      <td>25.382742</td>\n",
       "      <td>-10.427475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-36.276617</td>\n",
       "      <td>-105.460924</td>\n",
       "      <td>72.864681</td>\n",
       "      <td>25.520891</td>\n",
       "      <td>-9.997031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-36.407428</td>\n",
       "      <td>-105.813909</td>\n",
       "      <td>72.973456</td>\n",
       "      <td>25.797189</td>\n",
       "      <td>-9.136144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-36.612989</td>\n",
       "      <td>-106.368600</td>\n",
       "      <td>73.144389</td>\n",
       "      <td>26.231372</td>\n",
       "      <td>-7.783320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-13.433588</td>\n",
       "      <td>-84.103659</td>\n",
       "      <td>58.516702</td>\n",
       "      <td>45.184684</td>\n",
       "      <td>4.351306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-13.484978</td>\n",
       "      <td>-84.242331</td>\n",
       "      <td>58.559435</td>\n",
       "      <td>45.293230</td>\n",
       "      <td>4.689512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-13.550384</td>\n",
       "      <td>-84.418824</td>\n",
       "      <td>58.613823</td>\n",
       "      <td>45.431379</td>\n",
       "      <td>5.119956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>-13.681195</td>\n",
       "      <td>-84.771809</td>\n",
       "      <td>58.722598</td>\n",
       "      <td>45.707678</td>\n",
       "      <td>5.980844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>-13.886756</td>\n",
       "      <td>-85.326500</td>\n",
       "      <td>58.893531</td>\n",
       "      <td>46.141861</td>\n",
       "      <td>7.333667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>-13.436893</td>\n",
       "      <td>-84.106811</td>\n",
       "      <td>58.508322</td>\n",
       "      <td>45.201809</td>\n",
       "      <td>4.295932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>-13.488283</td>\n",
       "      <td>-84.245484</td>\n",
       "      <td>58.551055</td>\n",
       "      <td>45.310355</td>\n",
       "      <td>4.634138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>-13.553688</td>\n",
       "      <td>-84.421976</td>\n",
       "      <td>58.605443</td>\n",
       "      <td>45.448504</td>\n",
       "      <td>5.064581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>-13.684500</td>\n",
       "      <td>-84.774962</td>\n",
       "      <td>58.714218</td>\n",
       "      <td>45.724802</td>\n",
       "      <td>5.925469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>-13.890060</td>\n",
       "      <td>-85.329653</td>\n",
       "      <td>58.885151</td>\n",
       "      <td>46.158986</td>\n",
       "      <td>7.278292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>-91.631373</td>\n",
       "      <td>-121.976582</td>\n",
       "      <td>81.175858</td>\n",
       "      <td>59.045731</td>\n",
       "      <td>-17.401602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>-91.682763</td>\n",
       "      <td>-122.115254</td>\n",
       "      <td>81.218591</td>\n",
       "      <td>59.154277</td>\n",
       "      <td>-17.063397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>-91.748169</td>\n",
       "      <td>-122.291747</td>\n",
       "      <td>81.272979</td>\n",
       "      <td>59.292426</td>\n",
       "      <td>-16.632953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>-91.878980</td>\n",
       "      <td>-122.644732</td>\n",
       "      <td>81.381754</td>\n",
       "      <td>59.568725</td>\n",
       "      <td>-15.772065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>-92.084541</td>\n",
       "      <td>-123.199423</td>\n",
       "      <td>81.552687</td>\n",
       "      <td>60.002908</td>\n",
       "      <td>-14.419242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>-94.727417</td>\n",
       "      <td>-75.589257</td>\n",
       "      <td>80.907875</td>\n",
       "      <td>15.149793</td>\n",
       "      <td>-19.067814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-94.778807</td>\n",
       "      <td>-75.727930</td>\n",
       "      <td>80.950608</td>\n",
       "      <td>15.258339</td>\n",
       "      <td>-18.729608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-94.844212</td>\n",
       "      <td>-75.904423</td>\n",
       "      <td>81.004996</td>\n",
       "      <td>15.396488</td>\n",
       "      <td>-18.299164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>-94.975024</td>\n",
       "      <td>-76.257408</td>\n",
       "      <td>81.113771</td>\n",
       "      <td>15.672786</td>\n",
       "      <td>-17.438276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>-95.180584</td>\n",
       "      <td>-76.812099</td>\n",
       "      <td>81.284704</td>\n",
       "      <td>16.106970</td>\n",
       "      <td>-16.085453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>-109.448945</td>\n",
       "      <td>-93.692364</td>\n",
       "      <td>91.716906</td>\n",
       "      <td>0.461408</td>\n",
       "      <td>-30.102445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>-109.500335</td>\n",
       "      <td>-93.831036</td>\n",
       "      <td>91.759640</td>\n",
       "      <td>0.569954</td>\n",
       "      <td>-29.764239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-109.565741</td>\n",
       "      <td>-94.007529</td>\n",
       "      <td>91.814027</td>\n",
       "      <td>0.708103</td>\n",
       "      <td>-29.333795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>-109.696552</td>\n",
       "      <td>-94.360514</td>\n",
       "      <td>91.922803</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>-28.472907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>-109.902113</td>\n",
       "      <td>-94.915205</td>\n",
       "      <td>92.093736</td>\n",
       "      <td>1.418585</td>\n",
       "      <td>-27.120084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.957657</td>\n",
       "      <td>-107.783720</td>\n",
       "      <td>-62.861744</td>\n",
       "      <td>-3.210510</td>\n",
       "      <td>-20.020074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.906267</td>\n",
       "      <td>-107.922393</td>\n",
       "      <td>-62.819011</td>\n",
       "      <td>-3.101964</td>\n",
       "      <td>-19.681868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>0.840861</td>\n",
       "      <td>-108.098885</td>\n",
       "      <td>-62.764623</td>\n",
       "      <td>-2.963815</td>\n",
       "      <td>-19.251424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>0.710050</td>\n",
       "      <td>-108.451871</td>\n",
       "      <td>-62.655847</td>\n",
       "      <td>-2.687517</td>\n",
       "      <td>-18.390536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.504489</td>\n",
       "      <td>-109.006562</td>\n",
       "      <td>-62.484914</td>\n",
       "      <td>-2.253333</td>\n",
       "      <td>-17.037713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>-13.543625</td>\n",
       "      <td>-118.150417</td>\n",
       "      <td>-56.396737</td>\n",
       "      <td>-13.083092</td>\n",
       "      <td>-26.118435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-13.595016</td>\n",
       "      <td>-118.289090</td>\n",
       "      <td>-56.354004</td>\n",
       "      <td>-12.974546</td>\n",
       "      <td>-25.780229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>-13.660421</td>\n",
       "      <td>-118.465583</td>\n",
       "      <td>-56.299616</td>\n",
       "      <td>-12.836397</td>\n",
       "      <td>-25.349785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-13.791233</td>\n",
       "      <td>-118.818568</td>\n",
       "      <td>-56.190841</td>\n",
       "      <td>-12.560098</td>\n",
       "      <td>-24.488898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>-13.996793</td>\n",
       "      <td>-119.373259</td>\n",
       "      <td>-56.019908</td>\n",
       "      <td>-12.125915</td>\n",
       "      <td>-23.136074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>7.141966</td>\n",
       "      <td>-102.581239</td>\n",
       "      <td>-65.363224</td>\n",
       "      <td>1.927945</td>\n",
       "      <td>-16.686756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>7.090576</td>\n",
       "      <td>-102.719912</td>\n",
       "      <td>-65.320490</td>\n",
       "      <td>2.036491</td>\n",
       "      <td>-16.348551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>7.025170</td>\n",
       "      <td>-102.896405</td>\n",
       "      <td>-65.266103</td>\n",
       "      <td>2.174640</td>\n",
       "      <td>-15.918107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>6.894359</td>\n",
       "      <td>-103.249390</td>\n",
       "      <td>-65.157327</td>\n",
       "      <td>2.450938</td>\n",
       "      <td>-15.057219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>6.688798</td>\n",
       "      <td>-103.804081</td>\n",
       "      <td>-64.986394</td>\n",
       "      <td>2.885122</td>\n",
       "      <td>-13.704396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>-41.857179</td>\n",
       "      <td>-142.055667</td>\n",
       "      <td>-39.827324</td>\n",
       "      <td>-36.979497</td>\n",
       "      <td>-40.894612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>-41.908569</td>\n",
       "      <td>-142.194340</td>\n",
       "      <td>-39.784591</td>\n",
       "      <td>-36.870951</td>\n",
       "      <td>-40.556406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>-41.973975</td>\n",
       "      <td>-142.370833</td>\n",
       "      <td>-39.730203</td>\n",
       "      <td>-36.732802</td>\n",
       "      <td>-40.125962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>-42.104786</td>\n",
       "      <td>-142.723818</td>\n",
       "      <td>-39.621428</td>\n",
       "      <td>-36.456503</td>\n",
       "      <td>-39.265075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>-42.310347</td>\n",
       "      <td>-143.278509</td>\n",
       "      <td>-39.450495</td>\n",
       "      <td>-36.022320</td>\n",
       "      <td>-37.912251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>-41.856439</td>\n",
       "      <td>-130.679683</td>\n",
       "      <td>-48.135589</td>\n",
       "      <td>-24.556947</td>\n",
       "      <td>-25.779641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-41.907829</td>\n",
       "      <td>-130.818356</td>\n",
       "      <td>-48.092856</td>\n",
       "      <td>-24.448401</td>\n",
       "      <td>-25.441435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-41.973235</td>\n",
       "      <td>-130.994848</td>\n",
       "      <td>-48.038468</td>\n",
       "      <td>-24.310252</td>\n",
       "      <td>-25.010991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-42.104046</td>\n",
       "      <td>-131.347834</td>\n",
       "      <td>-47.929693</td>\n",
       "      <td>-24.033954</td>\n",
       "      <td>-24.150104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-42.309607</td>\n",
       "      <td>-131.902525</td>\n",
       "      <td>-47.758760</td>\n",
       "      <td>-23.599771</td>\n",
       "      <td>-22.797280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>-39.063587</td>\n",
       "      <td>-131.411977</td>\n",
       "      <td>-48.806807</td>\n",
       "      <td>-25.004976</td>\n",
       "      <td>-32.524276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>-39.114977</td>\n",
       "      <td>-131.550649</td>\n",
       "      <td>-48.764074</td>\n",
       "      <td>-24.896430</td>\n",
       "      <td>-32.186070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>-39.180383</td>\n",
       "      <td>-131.727142</td>\n",
       "      <td>-48.709686</td>\n",
       "      <td>-24.758281</td>\n",
       "      <td>-31.755626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-39.311194</td>\n",
       "      <td>-132.080127</td>\n",
       "      <td>-48.600910</td>\n",
       "      <td>-24.481982</td>\n",
       "      <td>-30.894739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-39.516755</td>\n",
       "      <td>-132.634818</td>\n",
       "      <td>-48.429978</td>\n",
       "      <td>-24.047799</td>\n",
       "      <td>-29.541915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>-28.102231</td>\n",
       "      <td>-126.915631</td>\n",
       "      <td>82.218136</td>\n",
       "      <td>2.924417</td>\n",
       "      <td>-47.219297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>-28.153621</td>\n",
       "      <td>-127.054303</td>\n",
       "      <td>82.260869</td>\n",
       "      <td>3.032962</td>\n",
       "      <td>-46.881091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>-28.219027</td>\n",
       "      <td>-127.230796</td>\n",
       "      <td>82.315257</td>\n",
       "      <td>3.171112</td>\n",
       "      <td>-46.450647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>-28.349838</td>\n",
       "      <td>-127.583781</td>\n",
       "      <td>82.424032</td>\n",
       "      <td>3.447410</td>\n",
       "      <td>-45.589760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-28.555399</td>\n",
       "      <td>-128.138472</td>\n",
       "      <td>82.594965</td>\n",
       "      <td>3.881593</td>\n",
       "      <td>-44.236936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3.010960</td>\n",
       "      <td>-102.369356</td>\n",
       "      <td>63.873687</td>\n",
       "      <td>25.990411</td>\n",
       "      <td>-31.884359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>2.959570</td>\n",
       "      <td>-102.508029</td>\n",
       "      <td>63.916420</td>\n",
       "      <td>26.098957</td>\n",
       "      <td>-31.546153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>2.894164</td>\n",
       "      <td>-102.684522</td>\n",
       "      <td>63.970808</td>\n",
       "      <td>26.237107</td>\n",
       "      <td>-31.115709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>2.763353</td>\n",
       "      <td>-103.037507</td>\n",
       "      <td>64.079583</td>\n",
       "      <td>26.513405</td>\n",
       "      <td>-30.254821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2.557792</td>\n",
       "      <td>-103.592198</td>\n",
       "      <td>64.250516</td>\n",
       "      <td>26.947588</td>\n",
       "      <td>-28.901998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>28.771611</td>\n",
       "      <td>-78.614653</td>\n",
       "      <td>48.798923</td>\n",
       "      <td>48.466443</td>\n",
       "      <td>-15.365526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>28.720220</td>\n",
       "      <td>-78.753326</td>\n",
       "      <td>48.841656</td>\n",
       "      <td>48.574988</td>\n",
       "      <td>-15.027320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>28.654815</td>\n",
       "      <td>-78.929819</td>\n",
       "      <td>48.896044</td>\n",
       "      <td>48.713138</td>\n",
       "      <td>-14.596876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>28.524003</td>\n",
       "      <td>-79.282804</td>\n",
       "      <td>49.004819</td>\n",
       "      <td>48.989436</td>\n",
       "      <td>-13.735989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>28.318443</td>\n",
       "      <td>-79.837495</td>\n",
       "      <td>49.175752</td>\n",
       "      <td>49.423619</td>\n",
       "      <td>-12.383165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-64.005447</td>\n",
       "      <td>-122.310835</td>\n",
       "      <td>75.011768</td>\n",
       "      <td>65.602099</td>\n",
       "      <td>-38.801037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>-64.056837</td>\n",
       "      <td>-122.449507</td>\n",
       "      <td>75.054501</td>\n",
       "      <td>65.710645</td>\n",
       "      <td>-38.462832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>-64.122243</td>\n",
       "      <td>-122.626000</td>\n",
       "      <td>75.108889</td>\n",
       "      <td>65.848795</td>\n",
       "      <td>-38.032388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>-64.253054</td>\n",
       "      <td>-122.978985</td>\n",
       "      <td>75.217665</td>\n",
       "      <td>66.125093</td>\n",
       "      <td>-37.171500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-64.458615</td>\n",
       "      <td>-123.533676</td>\n",
       "      <td>75.388598</td>\n",
       "      <td>66.559276</td>\n",
       "      <td>-35.818677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-63.946154</td>\n",
       "      <td>-121.441914</td>\n",
       "      <td>74.527321</td>\n",
       "      <td>66.203032</td>\n",
       "      <td>-38.110515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>-63.997544</td>\n",
       "      <td>-121.580587</td>\n",
       "      <td>74.570055</td>\n",
       "      <td>66.311578</td>\n",
       "      <td>-37.772309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>-64.062950</td>\n",
       "      <td>-121.757080</td>\n",
       "      <td>74.624442</td>\n",
       "      <td>66.449727</td>\n",
       "      <td>-37.341865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>-64.193761</td>\n",
       "      <td>-122.110065</td>\n",
       "      <td>74.733218</td>\n",
       "      <td>66.726025</td>\n",
       "      <td>-36.480978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>-64.399322</td>\n",
       "      <td>-122.664756</td>\n",
       "      <td>74.904151</td>\n",
       "      <td>67.160209</td>\n",
       "      <td>-35.128154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>-2.919078</td>\n",
       "      <td>-1.541825</td>\n",
       "      <td>63.764758</td>\n",
       "      <td>-67.894718</td>\n",
       "      <td>-35.689412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>-2.970468</td>\n",
       "      <td>-1.680498</td>\n",
       "      <td>63.807491</td>\n",
       "      <td>-67.786173</td>\n",
       "      <td>-35.351206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-3.035874</td>\n",
       "      <td>-1.856990</td>\n",
       "      <td>63.861879</td>\n",
       "      <td>-67.648023</td>\n",
       "      <td>-34.920762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>-3.166685</td>\n",
       "      <td>-2.209975</td>\n",
       "      <td>63.970655</td>\n",
       "      <td>-67.371725</td>\n",
       "      <td>-34.059875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>-3.372246</td>\n",
       "      <td>-2.764666</td>\n",
       "      <td>64.141588</td>\n",
       "      <td>-66.937542</td>\n",
       "      <td>-32.707051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>-67.894210</td>\n",
       "      <td>-79.314425</td>\n",
       "      <td>81.121858</td>\n",
       "      <td>0.822571</td>\n",
       "      <td>-59.286132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>-67.945600</td>\n",
       "      <td>-79.453098</td>\n",
       "      <td>81.164591</td>\n",
       "      <td>0.931117</td>\n",
       "      <td>-58.947926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>-68.011005</td>\n",
       "      <td>-79.629591</td>\n",
       "      <td>81.218979</td>\n",
       "      <td>1.069266</td>\n",
       "      <td>-58.517482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>-68.141817</td>\n",
       "      <td>-79.982576</td>\n",
       "      <td>81.327754</td>\n",
       "      <td>1.345564</td>\n",
       "      <td>-57.656594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>-68.347377</td>\n",
       "      <td>-80.537267</td>\n",
       "      <td>81.498687</td>\n",
       "      <td>1.779748</td>\n",
       "      <td>-56.303771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>-68.524311</td>\n",
       "      <td>-55.238321</td>\n",
       "      <td>38.603594</td>\n",
       "      <td>30.296193</td>\n",
       "      <td>-29.327118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>-68.575701</td>\n",
       "      <td>-55.376994</td>\n",
       "      <td>38.646328</td>\n",
       "      <td>30.404739</td>\n",
       "      <td>-28.988912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-68.641106</td>\n",
       "      <td>-55.553487</td>\n",
       "      <td>38.700715</td>\n",
       "      <td>30.542888</td>\n",
       "      <td>-28.558468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-68.771918</td>\n",
       "      <td>-55.906472</td>\n",
       "      <td>38.809491</td>\n",
       "      <td>30.819186</td>\n",
       "      <td>-27.697581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>-68.977478</td>\n",
       "      <td>-56.461163</td>\n",
       "      <td>38.980424</td>\n",
       "      <td>31.253370</td>\n",
       "      <td>-26.344757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-51.808430</td>\n",
       "      <td>-121.996993</td>\n",
       "      <td>83.602873</td>\n",
       "      <td>9.265195</td>\n",
       "      <td>-25.848567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-51.859820</td>\n",
       "      <td>-122.135666</td>\n",
       "      <td>83.645607</td>\n",
       "      <td>9.373740</td>\n",
       "      <td>-25.510361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-51.925226</td>\n",
       "      <td>-122.312158</td>\n",
       "      <td>83.699994</td>\n",
       "      <td>9.511890</td>\n",
       "      <td>-25.079917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-52.056037</td>\n",
       "      <td>-122.665143</td>\n",
       "      <td>83.808770</td>\n",
       "      <td>9.788188</td>\n",
       "      <td>-24.219029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-52.261598</td>\n",
       "      <td>-123.219835</td>\n",
       "      <td>83.979703</td>\n",
       "      <td>10.222371</td>\n",
       "      <td>-22.866206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>124.102491</td>\n",
       "      <td>-33.173327</td>\n",
       "      <td>14.283977</td>\n",
       "      <td>-33.454705</td>\n",
       "      <td>37.729705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>124.051101</td>\n",
       "      <td>-33.312000</td>\n",
       "      <td>14.326710</td>\n",
       "      <td>-33.346159</td>\n",
       "      <td>38.067911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>123.985695</td>\n",
       "      <td>-33.488492</td>\n",
       "      <td>14.381098</td>\n",
       "      <td>-33.208010</td>\n",
       "      <td>38.498355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>123.854884</td>\n",
       "      <td>-33.841477</td>\n",
       "      <td>14.489873</td>\n",
       "      <td>-32.931712</td>\n",
       "      <td>39.359243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>123.649323</td>\n",
       "      <td>-34.396169</td>\n",
       "      <td>14.660806</td>\n",
       "      <td>-32.497528</td>\n",
       "      <td>40.712066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>214.036481</td>\n",
       "      <td>-63.767710</td>\n",
       "      <td>-87.421912</td>\n",
       "      <td>-70.617403</td>\n",
       "      <td>-55.549363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>228.768370</td>\n",
       "      <td>-21.343547</td>\n",
       "      <td>143.170256</td>\n",
       "      <td>34.918472</td>\n",
       "      <td>-51.384950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>34.781032</td>\n",
       "      <td>35.072810</td>\n",
       "      <td>132.971363</td>\n",
       "      <td>-99.782277</td>\n",
       "      <td>-70.363161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>257.253696</td>\n",
       "      <td>8.788452</td>\n",
       "      <td>89.810837</td>\n",
       "      <td>69.695177</td>\n",
       "      <td>-15.967173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>195.612072</td>\n",
       "      <td>-32.302990</td>\n",
       "      <td>32.901685</td>\n",
       "      <td>-36.132330</td>\n",
       "      <td>-14.344885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>237.044391</td>\n",
       "      <td>9.840916</td>\n",
       "      <td>-195.676891</td>\n",
       "      <td>21.247391</td>\n",
       "      <td>8.456216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>229.770886</td>\n",
       "      <td>-29.570621</td>\n",
       "      <td>-181.762030</td>\n",
       "      <td>-27.716391</td>\n",
       "      <td>-18.869109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>268.844013</td>\n",
       "      <td>16.949526</td>\n",
       "      <td>-54.726919</td>\n",
       "      <td>20.016148</td>\n",
       "      <td>5.468404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>241.397101</td>\n",
       "      <td>-9.971648</td>\n",
       "      <td>-141.623186</td>\n",
       "      <td>-6.563465</td>\n",
       "      <td>-6.510996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>98.046473</td>\n",
       "      <td>-53.438910</td>\n",
       "      <td>-70.839038</td>\n",
       "      <td>99.839590</td>\n",
       "      <td>-34.764378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>271.811922</td>\n",
       "      <td>8.386094</td>\n",
       "      <td>175.888747</td>\n",
       "      <td>-1.118459</td>\n",
       "      <td>-3.364481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>212.145270</td>\n",
       "      <td>43.908039</td>\n",
       "      <td>182.816290</td>\n",
       "      <td>-9.918611</td>\n",
       "      <td>-10.439846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>130.753057</td>\n",
       "      <td>-0.402251</td>\n",
       "      <td>54.660270</td>\n",
       "      <td>160.591561</td>\n",
       "      <td>-33.791214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>68.078225</td>\n",
       "      <td>-22.707579</td>\n",
       "      <td>78.022206</td>\n",
       "      <td>143.023229</td>\n",
       "      <td>-26.934099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>74.006304</td>\n",
       "      <td>-2.123908</td>\n",
       "      <td>65.058315</td>\n",
       "      <td>161.514527</td>\n",
       "      <td>-1.050926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>167.253716</td>\n",
       "      <td>-36.375349</td>\n",
       "      <td>141.666136</td>\n",
       "      <td>-43.837601</td>\n",
       "      <td>-3.027926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>-67.419410</td>\n",
       "      <td>115.890212</td>\n",
       "      <td>210.211641</td>\n",
       "      <td>-69.345073</td>\n",
       "      <td>-19.585577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>237.044060</td>\n",
       "      <td>9.840601</td>\n",
       "      <td>-195.677729</td>\n",
       "      <td>21.249103</td>\n",
       "      <td>8.450678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>-174.811614</td>\n",
       "      <td>-3.755620</td>\n",
       "      <td>-154.115532</td>\n",
       "      <td>35.323929</td>\n",
       "      <td>2.003436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>-165.404946</td>\n",
       "      <td>8.330354</td>\n",
       "      <td>-163.525298</td>\n",
       "      <td>39.225881</td>\n",
       "      <td>-8.965242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>-49.672905</td>\n",
       "      <td>83.686281</td>\n",
       "      <td>16.374014</td>\n",
       "      <td>-51.636546</td>\n",
       "      <td>5.961591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>-74.991947</td>\n",
       "      <td>87.140485</td>\n",
       "      <td>-106.415566</td>\n",
       "      <td>37.328128</td>\n",
       "      <td>-51.395820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>236.277190</td>\n",
       "      <td>3.905226</td>\n",
       "      <td>86.713855</td>\n",
       "      <td>2.581738</td>\n",
       "      <td>-4.373073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4.117931</td>\n",
       "      <td>131.876397</td>\n",
       "      <td>89.673972</td>\n",
       "      <td>-38.158224</td>\n",
       "      <td>-33.563932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>95.707816</td>\n",
       "      <td>85.799668</td>\n",
       "      <td>119.810755</td>\n",
       "      <td>-22.340783</td>\n",
       "      <td>-25.355507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>-50.645372</td>\n",
       "      <td>106.128939</td>\n",
       "      <td>-114.914197</td>\n",
       "      <td>85.859236</td>\n",
       "      <td>-53.268087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>260.121068</td>\n",
       "      <td>10.972106</td>\n",
       "      <td>77.541999</td>\n",
       "      <td>10.007540</td>\n",
       "      <td>-13.233683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-129.964695</td>\n",
       "      <td>-159.683911</td>\n",
       "      <td>-25.850796</td>\n",
       "      <td>-4.943051</td>\n",
       "      <td>-22.993472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-129.881950</td>\n",
       "      <td>16.051939</td>\n",
       "      <td>57.416669</td>\n",
       "      <td>46.658218</td>\n",
       "      <td>-32.675687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-115.447659</td>\n",
       "      <td>21.878833</td>\n",
       "      <td>56.325195</td>\n",
       "      <td>35.918578</td>\n",
       "      <td>-28.956482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>-127.379248</td>\n",
       "      <td>18.234894</td>\n",
       "      <td>57.372656</td>\n",
       "      <td>43.676632</td>\n",
       "      <td>-32.381280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>-123.691133</td>\n",
       "      <td>-137.534111</td>\n",
       "      <td>-1.638692</td>\n",
       "      <td>36.907759</td>\n",
       "      <td>-37.971516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>-119.243278</td>\n",
       "      <td>-79.578561</td>\n",
       "      <td>32.456123</td>\n",
       "      <td>65.239590</td>\n",
       "      <td>-35.644971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>-125.771436</td>\n",
       "      <td>-47.816445</td>\n",
       "      <td>46.768859</td>\n",
       "      <td>68.043695</td>\n",
       "      <td>-36.750629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>-117.908766</td>\n",
       "      <td>-19.678769</td>\n",
       "      <td>58.275271</td>\n",
       "      <td>72.594074</td>\n",
       "      <td>-34.127285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>-78.586855</td>\n",
       "      <td>-125.346855</td>\n",
       "      <td>86.312876</td>\n",
       "      <td>8.186720</td>\n",
       "      <td>-13.627226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>-33.590624</td>\n",
       "      <td>-101.018799</td>\n",
       "      <td>-61.732459</td>\n",
       "      <td>6.349455</td>\n",
       "      <td>11.435417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>-63.263771</td>\n",
       "      <td>-116.925542</td>\n",
       "      <td>69.494162</td>\n",
       "      <td>71.657876</td>\n",
       "      <td>-32.573945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>-93.920020</td>\n",
       "      <td>-142.439215</td>\n",
       "      <td>-37.984874</td>\n",
       "      <td>-33.493138</td>\n",
       "      <td>-7.816662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>-12.335439</td>\n",
       "      <td>-86.476881</td>\n",
       "      <td>72.855055</td>\n",
       "      <td>41.333678</td>\n",
       "      <td>3.216215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>-130.016085</td>\n",
       "      <td>-159.822584</td>\n",
       "      <td>-25.808063</td>\n",
       "      <td>-4.834506</td>\n",
       "      <td>-22.655267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>-129.933340</td>\n",
       "      <td>15.913266</td>\n",
       "      <td>57.459402</td>\n",
       "      <td>46.766764</td>\n",
       "      <td>-32.337482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>-115.499049</td>\n",
       "      <td>21.740160</td>\n",
       "      <td>56.367928</td>\n",
       "      <td>36.027124</td>\n",
       "      <td>-28.618276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>-127.430638</td>\n",
       "      <td>18.096221</td>\n",
       "      <td>57.415389</td>\n",
       "      <td>43.785178</td>\n",
       "      <td>-32.043075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>-123.742523</td>\n",
       "      <td>-137.672783</td>\n",
       "      <td>-1.595959</td>\n",
       "      <td>37.016304</td>\n",
       "      <td>-37.633310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>-119.294669</td>\n",
       "      <td>-79.717234</td>\n",
       "      <td>32.498856</td>\n",
       "      <td>65.348136</td>\n",
       "      <td>-35.306765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>-125.822826</td>\n",
       "      <td>-47.955117</td>\n",
       "      <td>46.811592</td>\n",
       "      <td>68.152241</td>\n",
       "      <td>-36.412423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>-117.960156</td>\n",
       "      <td>-19.817442</td>\n",
       "      <td>58.318005</td>\n",
       "      <td>72.702620</td>\n",
       "      <td>-33.789079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>-78.638245</td>\n",
       "      <td>-125.485528</td>\n",
       "      <td>86.355609</td>\n",
       "      <td>8.295265</td>\n",
       "      <td>-13.289020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>-33.642014</td>\n",
       "      <td>-101.157472</td>\n",
       "      <td>-61.689726</td>\n",
       "      <td>6.458001</td>\n",
       "      <td>11.773623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>-63.315161</td>\n",
       "      <td>-117.064215</td>\n",
       "      <td>69.536895</td>\n",
       "      <td>71.766422</td>\n",
       "      <td>-32.235739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>-93.971410</td>\n",
       "      <td>-142.577888</td>\n",
       "      <td>-37.942140</td>\n",
       "      <td>-33.384592</td>\n",
       "      <td>-7.478456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>-12.386829</td>\n",
       "      <td>-86.615554</td>\n",
       "      <td>72.897788</td>\n",
       "      <td>41.442224</td>\n",
       "      <td>3.554421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>-130.081491</td>\n",
       "      <td>-159.999076</td>\n",
       "      <td>-25.753675</td>\n",
       "      <td>-4.696356</td>\n",
       "      <td>-22.224823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>-129.998746</td>\n",
       "      <td>15.736774</td>\n",
       "      <td>57.513790</td>\n",
       "      <td>46.904913</td>\n",
       "      <td>-31.907038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>-115.564455</td>\n",
       "      <td>21.563667</td>\n",
       "      <td>56.422316</td>\n",
       "      <td>36.165273</td>\n",
       "      <td>-28.187832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>-127.496044</td>\n",
       "      <td>17.919728</td>\n",
       "      <td>57.469777</td>\n",
       "      <td>43.923328</td>\n",
       "      <td>-31.612631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>-123.807928</td>\n",
       "      <td>-137.849276</td>\n",
       "      <td>-1.541571</td>\n",
       "      <td>37.154454</td>\n",
       "      <td>-37.202867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>-119.360074</td>\n",
       "      <td>-79.893726</td>\n",
       "      <td>32.553244</td>\n",
       "      <td>65.486285</td>\n",
       "      <td>-34.876321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>-125.888231</td>\n",
       "      <td>-48.131610</td>\n",
       "      <td>46.865980</td>\n",
       "      <td>68.290390</td>\n",
       "      <td>-35.981980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-118.025562</td>\n",
       "      <td>-19.993934</td>\n",
       "      <td>58.372392</td>\n",
       "      <td>72.840769</td>\n",
       "      <td>-33.358635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>-78.703651</td>\n",
       "      <td>-125.662020</td>\n",
       "      <td>86.409997</td>\n",
       "      <td>8.433415</td>\n",
       "      <td>-12.858576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>-33.707420</td>\n",
       "      <td>-101.333965</td>\n",
       "      <td>-61.635338</td>\n",
       "      <td>6.596150</td>\n",
       "      <td>12.204066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>-63.380567</td>\n",
       "      <td>-117.240708</td>\n",
       "      <td>69.591283</td>\n",
       "      <td>71.904571</td>\n",
       "      <td>-31.805295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>-94.036816</td>\n",
       "      <td>-142.754381</td>\n",
       "      <td>-37.887753</td>\n",
       "      <td>-33.246443</td>\n",
       "      <td>-7.048013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>-12.452235</td>\n",
       "      <td>-86.792047</td>\n",
       "      <td>72.952176</td>\n",
       "      <td>41.580373</td>\n",
       "      <td>3.984864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>-130.212302</td>\n",
       "      <td>-160.352062</td>\n",
       "      <td>-25.644900</td>\n",
       "      <td>-4.420058</td>\n",
       "      <td>-21.363935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>-130.129557</td>\n",
       "      <td>15.383788</td>\n",
       "      <td>57.622565</td>\n",
       "      <td>47.181212</td>\n",
       "      <td>-31.046150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>-115.695266</td>\n",
       "      <td>21.210682</td>\n",
       "      <td>56.531091</td>\n",
       "      <td>36.441572</td>\n",
       "      <td>-27.326945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>-127.626855</td>\n",
       "      <td>17.566743</td>\n",
       "      <td>57.578553</td>\n",
       "      <td>44.199626</td>\n",
       "      <td>-30.751743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-123.938740</td>\n",
       "      <td>-138.202261</td>\n",
       "      <td>-1.432795</td>\n",
       "      <td>37.430752</td>\n",
       "      <td>-36.341979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>-119.490886</td>\n",
       "      <td>-80.246711</td>\n",
       "      <td>32.662019</td>\n",
       "      <td>65.762583</td>\n",
       "      <td>-34.015434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-126.019043</td>\n",
       "      <td>-48.484595</td>\n",
       "      <td>46.974755</td>\n",
       "      <td>68.566689</td>\n",
       "      <td>-35.121092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>-118.156373</td>\n",
       "      <td>-20.346920</td>\n",
       "      <td>58.481168</td>\n",
       "      <td>73.117068</td>\n",
       "      <td>-32.497748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-78.834462</td>\n",
       "      <td>-126.015006</td>\n",
       "      <td>86.518773</td>\n",
       "      <td>8.709713</td>\n",
       "      <td>-11.997689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>-33.838231</td>\n",
       "      <td>-101.686950</td>\n",
       "      <td>-61.526562</td>\n",
       "      <td>6.872449</td>\n",
       "      <td>13.064954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>-63.511378</td>\n",
       "      <td>-117.593693</td>\n",
       "      <td>69.700059</td>\n",
       "      <td>72.180870</td>\n",
       "      <td>-30.944408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>-94.167627</td>\n",
       "      <td>-143.107366</td>\n",
       "      <td>-37.778977</td>\n",
       "      <td>-32.970144</td>\n",
       "      <td>-6.187125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>-12.583046</td>\n",
       "      <td>-87.145032</td>\n",
       "      <td>73.060951</td>\n",
       "      <td>41.856672</td>\n",
       "      <td>4.845752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>-130.417863</td>\n",
       "      <td>-160.906753</td>\n",
       "      <td>-25.473967</td>\n",
       "      <td>-3.985875</td>\n",
       "      <td>-20.011112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>-130.335118</td>\n",
       "      <td>14.829097</td>\n",
       "      <td>57.793498</td>\n",
       "      <td>47.615395</td>\n",
       "      <td>-29.693327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>-115.900827</td>\n",
       "      <td>20.655991</td>\n",
       "      <td>56.702024</td>\n",
       "      <td>36.875755</td>\n",
       "      <td>-25.974121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>-127.832416</td>\n",
       "      <td>17.012052</td>\n",
       "      <td>57.749486</td>\n",
       "      <td>44.633809</td>\n",
       "      <td>-29.398920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>-124.144300</td>\n",
       "      <td>-138.756952</td>\n",
       "      <td>-1.261862</td>\n",
       "      <td>37.864935</td>\n",
       "      <td>-34.989156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-119.696446</td>\n",
       "      <td>-80.801403</td>\n",
       "      <td>32.832952</td>\n",
       "      <td>66.196767</td>\n",
       "      <td>-32.662610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-126.224604</td>\n",
       "      <td>-49.039286</td>\n",
       "      <td>47.145688</td>\n",
       "      <td>69.000872</td>\n",
       "      <td>-33.768268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-118.361934</td>\n",
       "      <td>-20.901611</td>\n",
       "      <td>58.652101</td>\n",
       "      <td>73.551251</td>\n",
       "      <td>-31.144924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>-79.040023</td>\n",
       "      <td>-126.569697</td>\n",
       "      <td>86.689706</td>\n",
       "      <td>9.143896</td>\n",
       "      <td>-10.644865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>-34.043792</td>\n",
       "      <td>-102.241641</td>\n",
       "      <td>-61.355629</td>\n",
       "      <td>7.306632</td>\n",
       "      <td>14.417777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>-63.716939</td>\n",
       "      <td>-118.148384</td>\n",
       "      <td>69.870992</td>\n",
       "      <td>72.615053</td>\n",
       "      <td>-29.591584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>-94.373188</td>\n",
       "      <td>-143.662057</td>\n",
       "      <td>-37.608044</td>\n",
       "      <td>-32.535961</td>\n",
       "      <td>-4.834302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>-12.788607</td>\n",
       "      <td>-87.699723</td>\n",
       "      <td>73.231884</td>\n",
       "      <td>42.290855</td>\n",
       "      <td>6.198575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>172.745944</td>\n",
       "      <td>-5.293999</td>\n",
       "      <td>1.486961</td>\n",
       "      <td>58.923408</td>\n",
       "      <td>-38.752986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>172.745779</td>\n",
       "      <td>-5.294156</td>\n",
       "      <td>1.486542</td>\n",
       "      <td>58.924265</td>\n",
       "      <td>-38.755755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>172.745779</td>\n",
       "      <td>-5.294156</td>\n",
       "      <td>1.486542</td>\n",
       "      <td>58.924265</td>\n",
       "      <td>-38.755755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>172.753160</td>\n",
       "      <td>-5.287116</td>\n",
       "      <td>1.505257</td>\n",
       "      <td>58.886020</td>\n",
       "      <td>-38.632085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>172.862740</td>\n",
       "      <td>-4.978833</td>\n",
       "      <td>1.389840</td>\n",
       "      <td>58.676713</td>\n",
       "      <td>-39.521635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>172.862575</td>\n",
       "      <td>-4.978991</td>\n",
       "      <td>1.389421</td>\n",
       "      <td>58.677570</td>\n",
       "      <td>-39.524404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>172.862575</td>\n",
       "      <td>-4.978991</td>\n",
       "      <td>1.389421</td>\n",
       "      <td>58.677570</td>\n",
       "      <td>-39.524404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>172.844053</td>\n",
       "      <td>-5.029260</td>\n",
       "      <td>1.405379</td>\n",
       "      <td>58.716185</td>\n",
       "      <td>-39.398652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>172.843887</td>\n",
       "      <td>-5.029417</td>\n",
       "      <td>1.404960</td>\n",
       "      <td>58.717041</td>\n",
       "      <td>-39.401420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>172.843887</td>\n",
       "      <td>-5.029417</td>\n",
       "      <td>1.404960</td>\n",
       "      <td>58.717041</td>\n",
       "      <td>-39.401420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>172.615133</td>\n",
       "      <td>-5.646984</td>\n",
       "      <td>1.595736</td>\n",
       "      <td>59.199707</td>\n",
       "      <td>-37.892098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>172.614968</td>\n",
       "      <td>-5.647141</td>\n",
       "      <td>1.595317</td>\n",
       "      <td>59.200563</td>\n",
       "      <td>-37.894867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>172.614968</td>\n",
       "      <td>-5.647141</td>\n",
       "      <td>1.595317</td>\n",
       "      <td>59.200563</td>\n",
       "      <td>-37.894867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>172.622348</td>\n",
       "      <td>-5.640101</td>\n",
       "      <td>1.614033</td>\n",
       "      <td>59.162318</td>\n",
       "      <td>-37.771197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>86.668622</td>\n",
       "      <td>-71.138855</td>\n",
       "      <td>-86.597940</td>\n",
       "      <td>10.758772</td>\n",
       "      <td>-55.728227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>86.670770</td>\n",
       "      <td>-71.136806</td>\n",
       "      <td>-86.592493</td>\n",
       "      <td>10.747641</td>\n",
       "      <td>-55.692234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>86.683548</td>\n",
       "      <td>-71.124617</td>\n",
       "      <td>-86.560090</td>\n",
       "      <td>10.681425</td>\n",
       "      <td>-55.478119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>86.785417</td>\n",
       "      <td>-70.823689</td>\n",
       "      <td>-86.695061</td>\n",
       "      <td>10.512077</td>\n",
       "      <td>-56.496877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>86.787566</td>\n",
       "      <td>-70.821640</td>\n",
       "      <td>-86.689614</td>\n",
       "      <td>10.500946</td>\n",
       "      <td>-56.460883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>86.800344</td>\n",
       "      <td>-70.809451</td>\n",
       "      <td>-86.657211</td>\n",
       "      <td>10.434730</td>\n",
       "      <td>-56.246768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>86.766730</td>\n",
       "      <td>-70.874116</td>\n",
       "      <td>-86.679522</td>\n",
       "      <td>10.551548</td>\n",
       "      <td>-56.373893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>86.768878</td>\n",
       "      <td>-70.872067</td>\n",
       "      <td>-86.674075</td>\n",
       "      <td>10.540417</td>\n",
       "      <td>-56.337899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>86.781657</td>\n",
       "      <td>-70.859878</td>\n",
       "      <td>-86.641671</td>\n",
       "      <td>10.474202</td>\n",
       "      <td>-56.123784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>86.537810</td>\n",
       "      <td>-71.491840</td>\n",
       "      <td>-86.489165</td>\n",
       "      <td>11.035070</td>\n",
       "      <td>-54.867340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>86.539958</td>\n",
       "      <td>-71.489791</td>\n",
       "      <td>-86.483717</td>\n",
       "      <td>11.023939</td>\n",
       "      <td>-54.831346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>86.552737</td>\n",
       "      <td>-71.477602</td>\n",
       "      <td>-86.451314</td>\n",
       "      <td>10.957724</td>\n",
       "      <td>-54.617231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>51.999670</td>\n",
       "      <td>-96.143029</td>\n",
       "      <td>-72.421538</td>\n",
       "      <td>-12.344223</td>\n",
       "      <td>-66.222619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>52.004518</td>\n",
       "      <td>-96.138406</td>\n",
       "      <td>-72.409247</td>\n",
       "      <td>-12.369339</td>\n",
       "      <td>-66.141403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>204.717655</td>\n",
       "      <td>19.422387</td>\n",
       "      <td>-66.345558</td>\n",
       "      <td>131.844468</td>\n",
       "      <td>-27.697239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>203.513965</td>\n",
       "      <td>35.824627</td>\n",
       "      <td>-115.295489</td>\n",
       "      <td>154.634973</td>\n",
       "      <td>-15.344383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>204.834451</td>\n",
       "      <td>19.737553</td>\n",
       "      <td>-66.442679</td>\n",
       "      <td>131.597773</td>\n",
       "      <td>-28.465889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>204.815763</td>\n",
       "      <td>19.687126</td>\n",
       "      <td>-66.427139</td>\n",
       "      <td>131.637244</td>\n",
       "      <td>-28.342905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>204.586843</td>\n",
       "      <td>19.069402</td>\n",
       "      <td>-66.236782</td>\n",
       "      <td>132.120766</td>\n",
       "      <td>-26.836352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>203.630761</td>\n",
       "      <td>36.139793</td>\n",
       "      <td>-115.392610</td>\n",
       "      <td>154.388277</td>\n",
       "      <td>-16.113033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>203.612073</td>\n",
       "      <td>36.089366</td>\n",
       "      <td>-115.377071</td>\n",
       "      <td>154.427749</td>\n",
       "      <td>-15.990049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>203.383154</td>\n",
       "      <td>35.471642</td>\n",
       "      <td>-115.186714</td>\n",
       "      <td>154.911271</td>\n",
       "      <td>-14.483496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>130.485433</td>\n",
       "      <td>0.209172</td>\n",
       "      <td>-133.117752</td>\n",
       "      <td>134.137323</td>\n",
       "      <td>-19.716160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>131.733347</td>\n",
       "      <td>-16.573483</td>\n",
       "      <td>-84.370334</td>\n",
       "      <td>110.741073</td>\n",
       "      <td>-36.999302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>130.402375</td>\n",
       "      <td>-0.566007</td>\n",
       "      <td>-133.241001</td>\n",
       "      <td>133.750936</td>\n",
       "      <td>-24.380809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>130.583541</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>-133.199334</td>\n",
       "      <td>133.930099</td>\n",
       "      <td>-20.361825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>130.354622</td>\n",
       "      <td>-0.143813</td>\n",
       "      <td>-133.008977</td>\n",
       "      <td>134.413621</td>\n",
       "      <td>-18.855272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>130.519171</td>\n",
       "      <td>-0.250842</td>\n",
       "      <td>-133.338122</td>\n",
       "      <td>133.504241</td>\n",
       "      <td>-25.149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>130.500483</td>\n",
       "      <td>-0.301268</td>\n",
       "      <td>-133.322582</td>\n",
       "      <td>133.543713</td>\n",
       "      <td>-25.026474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>130.271563</td>\n",
       "      <td>-0.918992</td>\n",
       "      <td>-133.132225</td>\n",
       "      <td>134.027235</td>\n",
       "      <td>-23.519921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>-77.608821</td>\n",
       "      <td>-80.239701</td>\n",
       "      <td>-27.565840</td>\n",
       "      <td>70.990023</td>\n",
       "      <td>25.734183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>-77.492025</td>\n",
       "      <td>-79.924535</td>\n",
       "      <td>-27.662961</td>\n",
       "      <td>70.743328</td>\n",
       "      <td>24.965533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>-77.510712</td>\n",
       "      <td>-79.974962</td>\n",
       "      <td>-27.647422</td>\n",
       "      <td>70.782799</td>\n",
       "      <td>25.088517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-77.739632</td>\n",
       "      <td>-80.592686</td>\n",
       "      <td>-27.457065</td>\n",
       "      <td>71.266321</td>\n",
       "      <td>26.595070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-6.917301</td>\n",
       "      <td>-45.876768</td>\n",
       "      <td>-122.536873</td>\n",
       "      <td>107.523607</td>\n",
       "      <td>9.478677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-6.800506</td>\n",
       "      <td>-45.561603</td>\n",
       "      <td>-122.633994</td>\n",
       "      <td>107.276912</td>\n",
       "      <td>8.710027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-6.819193</td>\n",
       "      <td>-45.612029</td>\n",
       "      <td>-122.618454</td>\n",
       "      <td>107.316383</td>\n",
       "      <td>8.833011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-7.048113</td>\n",
       "      <td>-46.229754</td>\n",
       "      <td>-122.428097</td>\n",
       "      <td>107.799905</td>\n",
       "      <td>10.339565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>61.235990</td>\n",
       "      <td>-68.778638</td>\n",
       "      <td>-53.574111</td>\n",
       "      <td>67.051092</td>\n",
       "      <td>-58.585067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>61.235990</td>\n",
       "      <td>-68.778638</td>\n",
       "      <td>-53.574111</td>\n",
       "      <td>67.051092</td>\n",
       "      <td>-58.585067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>61.352786</td>\n",
       "      <td>-68.463473</td>\n",
       "      <td>-53.671232</td>\n",
       "      <td>66.804397</td>\n",
       "      <td>-59.353717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>61.352786</td>\n",
       "      <td>-68.463473</td>\n",
       "      <td>-53.671232</td>\n",
       "      <td>66.804397</td>\n",
       "      <td>-59.353717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>61.334098</td>\n",
       "      <td>-68.513899</td>\n",
       "      <td>-53.655693</td>\n",
       "      <td>66.843868</td>\n",
       "      <td>-59.230733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>61.334098</td>\n",
       "      <td>-68.513899</td>\n",
       "      <td>-53.655693</td>\n",
       "      <td>66.843868</td>\n",
       "      <td>-59.230733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>61.105178</td>\n",
       "      <td>-69.131623</td>\n",
       "      <td>-53.465336</td>\n",
       "      <td>67.327391</td>\n",
       "      <td>-57.724180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>61.105178</td>\n",
       "      <td>-69.131623</td>\n",
       "      <td>-53.465336</td>\n",
       "      <td>67.327391</td>\n",
       "      <td>-57.724180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>184.675886</td>\n",
       "      <td>37.440797</td>\n",
       "      <td>-105.797518</td>\n",
       "      <td>53.181435</td>\n",
       "      <td>76.408948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>13.268191</td>\n",
       "      <td>-77.922649</td>\n",
       "      <td>-119.343110</td>\n",
       "      <td>-69.377348</td>\n",
       "      <td>47.857701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>13.674640</td>\n",
       "      <td>-76.825874</td>\n",
       "      <td>-119.681091</td>\n",
       "      <td>-70.235847</td>\n",
       "      <td>45.182800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>132.818013</td>\n",
       "      <td>-26.898240</td>\n",
       "      <td>-52.857495</td>\n",
       "      <td>-22.591060</td>\n",
       "      <td>31.997608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>132.411563</td>\n",
       "      <td>-27.995016</td>\n",
       "      <td>-52.519514</td>\n",
       "      <td>-21.732561</td>\n",
       "      <td>34.672508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>132.701217</td>\n",
       "      <td>-27.213405</td>\n",
       "      <td>-52.760374</td>\n",
       "      <td>-22.344365</td>\n",
       "      <td>32.766257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>227.701799</td>\n",
       "      <td>13.710208</td>\n",
       "      <td>-29.339516</td>\n",
       "      <td>18.229881</td>\n",
       "      <td>24.048953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>227.799907</td>\n",
       "      <td>13.974947</td>\n",
       "      <td>-29.421097</td>\n",
       "      <td>18.022658</td>\n",
       "      <td>23.403288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>227.412145</td>\n",
       "      <td>12.928598</td>\n",
       "      <td>-29.098656</td>\n",
       "      <td>18.841685</td>\n",
       "      <td>25.955204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>227.818594</td>\n",
       "      <td>14.025374</td>\n",
       "      <td>-29.436637</td>\n",
       "      <td>17.983186</td>\n",
       "      <td>23.280304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>65.623834</td>\n",
       "      <td>-54.574663</td>\n",
       "      <td>-82.688141</td>\n",
       "      <td>-49.187515</td>\n",
       "      <td>39.623529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>-29.082714</td>\n",
       "      <td>-96.629186</td>\n",
       "      <td>-160.658670</td>\n",
       "      <td>-86.781325</td>\n",
       "      <td>52.220788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>-28.694951</td>\n",
       "      <td>-95.582837</td>\n",
       "      <td>-160.981112</td>\n",
       "      <td>-87.600353</td>\n",
       "      <td>49.668871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>13.655953</td>\n",
       "      <td>-76.876300</td>\n",
       "      <td>-119.665552</td>\n",
       "      <td>-70.196375</td>\n",
       "      <td>45.305784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>-28.793060</td>\n",
       "      <td>-95.847576</td>\n",
       "      <td>-160.899530</td>\n",
       "      <td>-87.393129</td>\n",
       "      <td>50.314537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>65.507038</td>\n",
       "      <td>-54.889828</td>\n",
       "      <td>-82.591020</td>\n",
       "      <td>-48.940820</td>\n",
       "      <td>40.392179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>65.605147</td>\n",
       "      <td>-54.625089</td>\n",
       "      <td>-82.672602</td>\n",
       "      <td>-49.148044</td>\n",
       "      <td>39.746513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>13.557845</td>\n",
       "      <td>-77.141039</td>\n",
       "      <td>-119.583970</td>\n",
       "      <td>-69.989152</td>\n",
       "      <td>45.951450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>65.217384</td>\n",
       "      <td>-55.671438</td>\n",
       "      <td>-82.350160</td>\n",
       "      <td>-48.329017</td>\n",
       "      <td>42.298430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>132.799326</td>\n",
       "      <td>-26.948667</td>\n",
       "      <td>-52.841956</td>\n",
       "      <td>-22.551589</td>\n",
       "      <td>32.120592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>-28.676264</td>\n",
       "      <td>-95.532410</td>\n",
       "      <td>-160.996651</td>\n",
       "      <td>-87.639824</td>\n",
       "      <td>49.545887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>-134.412447</td>\n",
       "      <td>137.630923</td>\n",
       "      <td>89.448907</td>\n",
       "      <td>-75.890758</td>\n",
       "      <td>-18.893678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.817917</td>\n",
       "      <td>75.586989</td>\n",
       "      <td>38.497495</td>\n",
       "      <td>29.359087</td>\n",
       "      <td>81.868581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>-39.661803</td>\n",
       "      <td>81.222074</td>\n",
       "      <td>78.447968</td>\n",
       "      <td>-61.916117</td>\n",
       "      <td>-7.657998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>-119.753879</td>\n",
       "      <td>182.820821</td>\n",
       "      <td>73.290287</td>\n",
       "      <td>-60.447934</td>\n",
       "      <td>-30.097711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>-112.361431</td>\n",
       "      <td>205.656630</td>\n",
       "      <td>65.078652</td>\n",
       "      <td>-52.809806</td>\n",
       "      <td>-36.062181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>-25.405358</td>\n",
       "      <td>99.797367</td>\n",
       "      <td>69.613673</td>\n",
       "      <td>-53.315864</td>\n",
       "      <td>-12.771964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>-11.181797</td>\n",
       "      <td>118.506664</td>\n",
       "      <td>60.614431</td>\n",
       "      <td>-44.656482</td>\n",
       "      <td>-17.880363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.719808</td>\n",
       "      <td>75.322250</td>\n",
       "      <td>38.579077</td>\n",
       "      <td>29.566311</td>\n",
       "      <td>82.514247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>-54.069922</td>\n",
       "      <td>62.185079</td>\n",
       "      <td>87.707595</td>\n",
       "      <td>-70.445004</td>\n",
       "      <td>-1.923653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>149.741375</td>\n",
       "      <td>-31.860363</td>\n",
       "      <td>56.527672</td>\n",
       "      <td>-33.759610</td>\n",
       "      <td>15.459027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>135.763147</td>\n",
       "      <td>-36.861207</td>\n",
       "      <td>61.838708</td>\n",
       "      <td>-39.355707</td>\n",
       "      <td>16.536958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>-101.294974</td>\n",
       "      <td>239.980632</td>\n",
       "      <td>52.797265</td>\n",
       "      <td>-41.561476</td>\n",
       "      <td>-45.512456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>-134.510556</td>\n",
       "      <td>137.366184</td>\n",
       "      <td>89.530489</td>\n",
       "      <td>-75.683534</td>\n",
       "      <td>-18.248012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>51.583327</td>\n",
       "      <td>-68.550786</td>\n",
       "      <td>94.472082</td>\n",
       "      <td>-71.844585</td>\n",
       "      <td>26.662458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>-25.503466</td>\n",
       "      <td>99.532628</td>\n",
       "      <td>69.695255</td>\n",
       "      <td>-53.108640</td>\n",
       "      <td>-12.126299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-69.222836</td>\n",
       "      <td>39.474087</td>\n",
       "      <td>99.534738</td>\n",
       "      <td>-84.704512</td>\n",
       "      <td>-0.854563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>149.839484</td>\n",
       "      <td>-31.595624</td>\n",
       "      <td>56.446090</td>\n",
       "      <td>-33.966834</td>\n",
       "      <td>14.813361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>125.570616</td>\n",
       "      <td>-74.515809</td>\n",
       "      <td>83.253408</td>\n",
       "      <td>-85.125362</td>\n",
       "      <td>-10.819713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>51.485218</td>\n",
       "      <td>-68.815525</td>\n",
       "      <td>94.553663</td>\n",
       "      <td>-71.637361</td>\n",
       "      <td>27.308124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>-90.363630</td>\n",
       "      <td>273.858133</td>\n",
       "      <td>40.660921</td>\n",
       "      <td>-29.917170</td>\n",
       "      <td>-53.756210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>-53.971813</td>\n",
       "      <td>62.449818</td>\n",
       "      <td>87.626014</td>\n",
       "      <td>-70.652228</td>\n",
       "      <td>-2.569319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>24.384220</td>\n",
       "      <td>164.835632</td>\n",
       "      <td>38.275585</td>\n",
       "      <td>-22.803532</td>\n",
       "      <td>-29.951921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>-150.130816</td>\n",
       "      <td>87.641845</td>\n",
       "      <td>108.928487</td>\n",
       "      <td>-96.637518</td>\n",
       "      <td>-10.448758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>-4.575863</td>\n",
       "      <td>-89.461005</td>\n",
       "      <td>114.936465</td>\n",
       "      <td>-92.654005</td>\n",
       "      <td>34.481863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>93.710806</td>\n",
       "      <td>-52.589028</td>\n",
       "      <td>77.821771</td>\n",
       "      <td>-55.446033</td>\n",
       "      <td>21.692140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>-150.228925</td>\n",
       "      <td>87.377106</td>\n",
       "      <td>109.010068</td>\n",
       "      <td>-96.430294</td>\n",
       "      <td>-9.803092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-112.263322</td>\n",
       "      <td>205.921369</td>\n",
       "      <td>64.997070</td>\n",
       "      <td>-53.017029</td>\n",
       "      <td>-36.707847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>-69.320945</td>\n",
       "      <td>39.209348</td>\n",
       "      <td>99.616319</td>\n",
       "      <td>-84.497288</td>\n",
       "      <td>-0.208897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>3.131983</td>\n",
       "      <td>137.221927</td>\n",
       "      <td>51.599201</td>\n",
       "      <td>-35.997535</td>\n",
       "      <td>-23.024091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>-119.655771</td>\n",
       "      <td>183.085560</td>\n",
       "      <td>73.208705</td>\n",
       "      <td>-60.655158</td>\n",
       "      <td>-30.743376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>-98.061164</td>\n",
       "      <td>83.051620</td>\n",
       "      <td>83.632210</td>\n",
       "      <td>-50.068227</td>\n",
       "      <td>25.297721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>-101.393083</td>\n",
       "      <td>239.715893</td>\n",
       "      <td>52.878846</td>\n",
       "      <td>-41.354252</td>\n",
       "      <td>-44.866790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>-90.265521</td>\n",
       "      <td>274.122872</td>\n",
       "      <td>40.579340</td>\n",
       "      <td>-30.124394</td>\n",
       "      <td>-54.401876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>3.033874</td>\n",
       "      <td>136.957188</td>\n",
       "      <td>51.680782</td>\n",
       "      <td>-35.790312</td>\n",
       "      <td>-22.378425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>125.668724</td>\n",
       "      <td>-74.251070</td>\n",
       "      <td>83.171826</td>\n",
       "      <td>-85.332585</td>\n",
       "      <td>-11.465378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-39.759912</td>\n",
       "      <td>80.957335</td>\n",
       "      <td>78.529550</td>\n",
       "      <td>-61.708893</td>\n",
       "      <td>-7.012333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>-82.448049</td>\n",
       "      <td>25.108235</td>\n",
       "      <td>105.622366</td>\n",
       "      <td>-87.989028</td>\n",
       "      <td>7.597998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>93.612697</td>\n",
       "      <td>-52.853766</td>\n",
       "      <td>77.903352</td>\n",
       "      <td>-55.238809</td>\n",
       "      <td>22.337806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>-4.477755</td>\n",
       "      <td>-89.196266</td>\n",
       "      <td>114.854884</td>\n",
       "      <td>-92.861229</td>\n",
       "      <td>33.836197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>9.410254</td>\n",
       "      <td>-84.201389</td>\n",
       "      <td>109.559835</td>\n",
       "      <td>-87.264696</td>\n",
       "      <td>32.793595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>135.665039</td>\n",
       "      <td>-37.125945</td>\n",
       "      <td>61.920290</td>\n",
       "      <td>-39.148483</td>\n",
       "      <td>17.182624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>9.508363</td>\n",
       "      <td>-83.936650</td>\n",
       "      <td>109.478253</td>\n",
       "      <td>-87.471920</td>\n",
       "      <td>32.147929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>24.482328</td>\n",
       "      <td>165.100371</td>\n",
       "      <td>38.194003</td>\n",
       "      <td>-23.010755</td>\n",
       "      <td>-30.597587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>-82.546158</td>\n",
       "      <td>24.843497</td>\n",
       "      <td>105.703948</td>\n",
       "      <td>-87.781804</td>\n",
       "      <td>8.243663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>-97.963055</td>\n",
       "      <td>83.316359</td>\n",
       "      <td>83.550628</td>\n",
       "      <td>-50.275451</td>\n",
       "      <td>24.652055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>-11.279906</td>\n",
       "      <td>118.241925</td>\n",
       "      <td>60.696013</td>\n",
       "      <td>-44.449258</td>\n",
       "      <td>-17.234697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>85.696487</td>\n",
       "      <td>-35.380924</td>\n",
       "      <td>-19.296054</td>\n",
       "      <td>-30.267853</td>\n",
       "      <td>47.150128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>85.677800</td>\n",
       "      <td>-35.431351</td>\n",
       "      <td>-19.280515</td>\n",
       "      <td>-30.228382</td>\n",
       "      <td>47.273112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>85.645097</td>\n",
       "      <td>-35.519597</td>\n",
       "      <td>-19.253321</td>\n",
       "      <td>-30.159308</td>\n",
       "      <td>47.488334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>85.579691</td>\n",
       "      <td>-35.696090</td>\n",
       "      <td>-19.198933</td>\n",
       "      <td>-30.021158</td>\n",
       "      <td>47.918778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>85.290037</td>\n",
       "      <td>-36.477700</td>\n",
       "      <td>-18.958073</td>\n",
       "      <td>-29.409355</td>\n",
       "      <td>49.825029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>85.496268</td>\n",
       "      <td>-35.921203</td>\n",
       "      <td>-19.129563</td>\n",
       "      <td>-29.844952</td>\n",
       "      <td>48.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>85.496268</td>\n",
       "      <td>-35.921203</td>\n",
       "      <td>-19.129563</td>\n",
       "      <td>-29.844952</td>\n",
       "      <td>48.467800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>-30.763786</td>\n",
       "      <td>-90.611241</td>\n",
       "      <td>-60.831899</td>\n",
       "      <td>-85.559853</td>\n",
       "      <td>52.669110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>-30.815176</td>\n",
       "      <td>-90.749914</td>\n",
       "      <td>-60.789166</td>\n",
       "      <td>-85.451308</td>\n",
       "      <td>53.007316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>-30.880582</td>\n",
       "      <td>-90.926406</td>\n",
       "      <td>-60.734778</td>\n",
       "      <td>-85.313158</td>\n",
       "      <td>53.437760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>-31.170236</td>\n",
       "      <td>-91.708016</td>\n",
       "      <td>-60.493918</td>\n",
       "      <td>-84.701355</td>\n",
       "      <td>55.344011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>-30.972069</td>\n",
       "      <td>-91.228806</td>\n",
       "      <td>-60.677118</td>\n",
       "      <td>-85.176846</td>\n",
       "      <td>53.524378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>-30.972069</td>\n",
       "      <td>-91.228806</td>\n",
       "      <td>-60.677118</td>\n",
       "      <td>-85.176846</td>\n",
       "      <td>53.524378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>12.706243</td>\n",
       "      <td>-74.913047</td>\n",
       "      <td>-51.215064</td>\n",
       "      <td>-70.239885</td>\n",
       "      <td>45.356257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>12.640837</td>\n",
       "      <td>-75.089540</td>\n",
       "      <td>-51.160676</td>\n",
       "      <td>-70.101736</td>\n",
       "      <td>45.786701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>12.757633</td>\n",
       "      <td>-74.774374</td>\n",
       "      <td>-51.257797</td>\n",
       "      <td>-70.348431</td>\n",
       "      <td>45.018051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>12.351183</td>\n",
       "      <td>-75.871150</td>\n",
       "      <td>-50.919816</td>\n",
       "      <td>-69.489932</td>\n",
       "      <td>47.692952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>12.557413</td>\n",
       "      <td>-75.314652</td>\n",
       "      <td>-51.091305</td>\n",
       "      <td>-69.925530</td>\n",
       "      <td>46.335723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>12.557413</td>\n",
       "      <td>-75.314652</td>\n",
       "      <td>-51.091305</td>\n",
       "      <td>-69.925530</td>\n",
       "      <td>46.335723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>-9.518736</td>\n",
       "      <td>-78.893844</td>\n",
       "      <td>-51.400380</td>\n",
       "      <td>-73.712707</td>\n",
       "      <td>54.396253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-9.925185</td>\n",
       "      <td>-79.990620</td>\n",
       "      <td>-51.062399</td>\n",
       "      <td>-72.854208</td>\n",
       "      <td>57.071154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-9.718955</td>\n",
       "      <td>-79.434122</td>\n",
       "      <td>-51.233889</td>\n",
       "      <td>-73.289806</td>\n",
       "      <td>55.713925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>-9.718955</td>\n",
       "      <td>-79.434122</td>\n",
       "      <td>-51.233889</td>\n",
       "      <td>-73.289806</td>\n",
       "      <td>55.713925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>49.585992</td>\n",
       "      <td>-52.701570</td>\n",
       "      <td>-31.339279</td>\n",
       "      <td>-46.444470</td>\n",
       "      <td>49.135368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>49.585992</td>\n",
       "      <td>-52.701570</td>\n",
       "      <td>-31.339279</td>\n",
       "      <td>-46.444470</td>\n",
       "      <td>49.135368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>49.786212</td>\n",
       "      <td>-52.161292</td>\n",
       "      <td>-31.505770</td>\n",
       "      <td>-46.867372</td>\n",
       "      <td>47.817696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>49.669416</td>\n",
       "      <td>-52.476457</td>\n",
       "      <td>-31.408649</td>\n",
       "      <td>-46.620677</td>\n",
       "      <td>48.586345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>49.379762</td>\n",
       "      <td>-53.258067</td>\n",
       "      <td>-31.167789</td>\n",
       "      <td>-46.008873</td>\n",
       "      <td>50.492596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>-30.790537</td>\n",
       "      <td>-90.738954</td>\n",
       "      <td>-60.828070</td>\n",
       "      <td>-85.560277</td>\n",
       "      <td>52.329690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>-51.371957</td>\n",
       "      <td>-119.841328</td>\n",
       "      <td>94.880403</td>\n",
       "      <td>-125.104095</td>\n",
       "      <td>27.163983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>-51.470065</td>\n",
       "      <td>-120.106067</td>\n",
       "      <td>94.961985</td>\n",
       "      <td>-124.896871</td>\n",
       "      <td>27.809649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>-26.322612</td>\n",
       "      <td>-109.215971</td>\n",
       "      <td>87.814927</td>\n",
       "      <td>-114.125379</td>\n",
       "      <td>25.498790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>-26.420720</td>\n",
       "      <td>-109.480710</td>\n",
       "      <td>87.896508</td>\n",
       "      <td>-113.918155</td>\n",
       "      <td>26.144455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>74.281124</td>\n",
       "      <td>-65.282420</td>\n",
       "      <td>59.027924</td>\n",
       "      <td>-68.409126</td>\n",
       "      <td>19.493083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>74.183016</td>\n",
       "      <td>-65.547159</td>\n",
       "      <td>59.109506</td>\n",
       "      <td>-68.201902</td>\n",
       "      <td>20.138749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>23.983288</td>\n",
       "      <td>-87.210552</td>\n",
       "      <td>73.427280</td>\n",
       "      <td>-91.247305</td>\n",
       "      <td>22.727138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>23.885179</td>\n",
       "      <td>-87.475291</td>\n",
       "      <td>73.508862</td>\n",
       "      <td>-91.040081</td>\n",
       "      <td>23.372804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>49.239843</td>\n",
       "      <td>-75.830491</td>\n",
       "      <td>66.105111</td>\n",
       "      <td>-79.347947</td>\n",
       "      <td>21.620681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>49.141734</td>\n",
       "      <td>-76.095230</td>\n",
       "      <td>66.186693</td>\n",
       "      <td>-79.140723</td>\n",
       "      <td>22.266346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>124.587024</td>\n",
       "      <td>-43.277001</td>\n",
       "      <td>44.640278</td>\n",
       "      <td>-45.531052</td>\n",
       "      <td>16.721432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>124.488915</td>\n",
       "      <td>-43.541740</td>\n",
       "      <td>44.721860</td>\n",
       "      <td>-45.323828</td>\n",
       "      <td>17.367097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>149.745470</td>\n",
       "      <td>-32.161678</td>\n",
       "      <td>37.399690</td>\n",
       "      <td>-33.424470</td>\n",
       "      <td>16.260640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>149.843579</td>\n",
       "      <td>-31.896940</td>\n",
       "      <td>37.318109</td>\n",
       "      <td>-33.631694</td>\n",
       "      <td>15.614974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>-1.066057</td>\n",
       "      <td>-97.835910</td>\n",
       "      <td>80.492757</td>\n",
       "      <td>-102.226021</td>\n",
       "      <td>24.392332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>-1.164165</td>\n",
       "      <td>-98.100648</td>\n",
       "      <td>80.574339</td>\n",
       "      <td>-102.018797</td>\n",
       "      <td>25.037998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>99.545743</td>\n",
       "      <td>-53.825072</td>\n",
       "      <td>51.717465</td>\n",
       "      <td>-56.469873</td>\n",
       "      <td>18.849029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>99.447634</td>\n",
       "      <td>-54.089811</td>\n",
       "      <td>51.799047</td>\n",
       "      <td>-56.262649</td>\n",
       "      <td>19.494695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>-91.353762</td>\n",
       "      <td>264.340705</td>\n",
       "      <td>76.368501</td>\n",
       "      <td>-1.910249</td>\n",
       "      <td>-8.839539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>-23.508863</td>\n",
       "      <td>125.264498</td>\n",
       "      <td>48.009794</td>\n",
       "      <td>-16.075436</td>\n",
       "      <td>23.663399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>-148.318391</td>\n",
       "      <td>143.217233</td>\n",
       "      <td>-21.602216</td>\n",
       "      <td>-58.909790</td>\n",
       "      <td>3.955417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>-147.034516</td>\n",
       "      <td>130.456218</td>\n",
       "      <td>29.172194</td>\n",
       "      <td>-51.221366</td>\n",
       "      <td>24.040355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>-122.325000</td>\n",
       "      <td>186.886416</td>\n",
       "      <td>58.434879</td>\n",
       "      <td>-30.038711</td>\n",
       "      <td>10.162514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>-167.935221</td>\n",
       "      <td>86.555874</td>\n",
       "      <td>-6.830471</td>\n",
       "      <td>-67.809348</td>\n",
       "      <td>35.572245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>-94.335997</td>\n",
       "      <td>43.864755</td>\n",
       "      <td>-14.791806</td>\n",
       "      <td>-58.211205</td>\n",
       "      <td>41.324849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>-210.630818</td>\n",
       "      <td>15.371860</td>\n",
       "      <td>-140.405631</td>\n",
       "      <td>-111.883526</td>\n",
       "      <td>29.516430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>-211.037268</td>\n",
       "      <td>14.275085</td>\n",
       "      <td>-140.067650</td>\n",
       "      <td>-111.025028</td>\n",
       "      <td>32.191330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>-167.645567</td>\n",
       "      <td>87.337485</td>\n",
       "      <td>-7.071331</td>\n",
       "      <td>-68.421152</td>\n",
       "      <td>33.665994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>-122.441795</td>\n",
       "      <td>186.571250</td>\n",
       "      <td>58.532000</td>\n",
       "      <td>-29.792016</td>\n",
       "      <td>10.931164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>-84.216053</td>\n",
       "      <td>47.266486</td>\n",
       "      <td>-16.130741</td>\n",
       "      <td>-66.323833</td>\n",
       "      <td>21.708991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>-185.718807</td>\n",
       "      <td>52.656030</td>\n",
       "      <td>-47.864196</td>\n",
       "      <td>-82.917178</td>\n",
       "      <td>40.998397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>29.939184</td>\n",
       "      <td>190.978357</td>\n",
       "      <td>63.334791</td>\n",
       "      <td>14.700392</td>\n",
       "      <td>4.731927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>-186.008461</td>\n",
       "      <td>51.874420</td>\n",
       "      <td>-47.623336</td>\n",
       "      <td>-82.305375</td>\n",
       "      <td>42.904648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>-192.473910</td>\n",
       "      <td>47.549273</td>\n",
       "      <td>-96.246564</td>\n",
       "      <td>-96.695689</td>\n",
       "      <td>25.276640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>-146.936408</td>\n",
       "      <td>130.720957</td>\n",
       "      <td>29.090613</td>\n",
       "      <td>-51.428590</td>\n",
       "      <td>23.394689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>-148.028737</td>\n",
       "      <td>143.998843</td>\n",
       "      <td>-21.843076</td>\n",
       "      <td>-59.521594</td>\n",
       "      <td>2.049165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>-172.462596</td>\n",
       "      <td>89.877931</td>\n",
       "      <td>-56.079231</td>\n",
       "      <td>-80.856913</td>\n",
       "      <td>14.100518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>-23.121101</td>\n",
       "      <td>126.310847</td>\n",
       "      <td>47.687353</td>\n",
       "      <td>-16.894464</td>\n",
       "      <td>21.111482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>-115.433853</td>\n",
       "      <td>14.044819</td>\n",
       "      <td>-54.781458</td>\n",
       "      <td>-82.986030</td>\n",
       "      <td>30.557352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>-116.863618</td>\n",
       "      <td>218.623561</td>\n",
       "      <td>3.082135</td>\n",
       "      <td>-32.322189</td>\n",
       "      <td>-16.817881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-116.980413</td>\n",
       "      <td>218.308395</td>\n",
       "      <td>3.179256</td>\n",
       "      <td>-32.075494</td>\n",
       "      <td>-16.049231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>-150.000650</td>\n",
       "      <td>-21.662202</td>\n",
       "      <td>-147.270771</td>\n",
       "      <td>-103.881496</td>\n",
       "      <td>36.146217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>-2.646477</td>\n",
       "      <td>148.995948</td>\n",
       "      <td>-9.375333</td>\n",
       "      <td>-17.183903</td>\n",
       "      <td>-4.320652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>29.841075</td>\n",
       "      <td>190.713618</td>\n",
       "      <td>63.416373</td>\n",
       "      <td>14.907616</td>\n",
       "      <td>5.377593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>-45.699423</td>\n",
       "      <td>92.616910</td>\n",
       "      <td>15.305437</td>\n",
       "      <td>-43.009680</td>\n",
       "      <td>11.443758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>-115.415165</td>\n",
       "      <td>14.095245</td>\n",
       "      <td>-54.796997</td>\n",
       "      <td>-83.025502</td>\n",
       "      <td>30.434369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>-62.876692</td>\n",
       "      <td>79.332374</td>\n",
       "      <td>19.761512</td>\n",
       "      <td>-40.404722</td>\n",
       "      <td>32.533627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>-45.680735</td>\n",
       "      <td>92.667336</td>\n",
       "      <td>15.289897</td>\n",
       "      <td>-43.049152</td>\n",
       "      <td>11.320774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>-94.742447</td>\n",
       "      <td>42.767980</td>\n",
       "      <td>-14.453825</td>\n",
       "      <td>-57.352706</td>\n",
       "      <td>43.999750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>-122.343687</td>\n",
       "      <td>186.835989</td>\n",
       "      <td>58.450419</td>\n",
       "      <td>-29.999240</td>\n",
       "      <td>10.285498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>-210.649505</td>\n",
       "      <td>15.321434</td>\n",
       "      <td>-140.390091</td>\n",
       "      <td>-111.844055</td>\n",
       "      <td>29.639413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>-2.763273</td>\n",
       "      <td>148.680782</td>\n",
       "      <td>-9.278212</td>\n",
       "      <td>-16.937208</td>\n",
       "      <td>-3.552002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>-62.974801</td>\n",
       "      <td>79.067635</td>\n",
       "      <td>19.843094</td>\n",
       "      <td>-40.197498</td>\n",
       "      <td>33.179293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>-210.747614</td>\n",
       "      <td>15.056695</td>\n",
       "      <td>-140.308510</td>\n",
       "      <td>-111.636831</td>\n",
       "      <td>30.285079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>-115.531961</td>\n",
       "      <td>13.780080</td>\n",
       "      <td>-54.699876</td>\n",
       "      <td>-82.778807</td>\n",
       "      <td>31.203018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>-94.452793</td>\n",
       "      <td>43.549590</td>\n",
       "      <td>-14.694685</td>\n",
       "      <td>-57.964510</td>\n",
       "      <td>42.093499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-172.752250</td>\n",
       "      <td>89.096321</td>\n",
       "      <td>-55.838371</td>\n",
       "      <td>-80.245109</td>\n",
       "      <td>16.006769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>-117.270067</td>\n",
       "      <td>217.526785</td>\n",
       "      <td>3.420116</td>\n",
       "      <td>-31.463691</td>\n",
       "      <td>-14.142980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>-172.364487</td>\n",
       "      <td>90.142670</td>\n",
       "      <td>-56.160812</td>\n",
       "      <td>-81.064137</td>\n",
       "      <td>13.454852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>29.957871</td>\n",
       "      <td>191.028784</td>\n",
       "      <td>63.319252</td>\n",
       "      <td>14.660921</td>\n",
       "      <td>4.608943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>-46.087185</td>\n",
       "      <td>91.570561</td>\n",
       "      <td>15.627878</td>\n",
       "      <td>-42.190653</td>\n",
       "      <td>13.995675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>-185.602011</td>\n",
       "      <td>52.971195</td>\n",
       "      <td>-47.961317</td>\n",
       "      <td>-83.163874</td>\n",
       "      <td>40.229747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>-147.930628</td>\n",
       "      <td>144.263582</td>\n",
       "      <td>-21.924658</td>\n",
       "      <td>-59.728817</td>\n",
       "      <td>1.403500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>-2.665165</td>\n",
       "      <td>148.945521</td>\n",
       "      <td>-9.359794</td>\n",
       "      <td>-17.144432</td>\n",
       "      <td>-4.197668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>-62.858005</td>\n",
       "      <td>79.382801</td>\n",
       "      <td>19.745973</td>\n",
       "      <td>-40.444193</td>\n",
       "      <td>32.410643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>-63.264454</td>\n",
       "      <td>78.286025</td>\n",
       "      <td>20.083954</td>\n",
       "      <td>-39.585695</td>\n",
       "      <td>35.085544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>-150.117445</td>\n",
       "      <td>-21.977367</td>\n",
       "      <td>-147.173650</td>\n",
       "      <td>-103.634801</td>\n",
       "      <td>36.914866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>-45.797531</td>\n",
       "      <td>92.352171</td>\n",
       "      <td>15.387018</td>\n",
       "      <td>-42.802457</td>\n",
       "      <td>12.089424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>-192.184257</td>\n",
       "      <td>48.330884</td>\n",
       "      <td>-96.487424</td>\n",
       "      <td>-97.307492</td>\n",
       "      <td>23.370389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>-94.354685</td>\n",
       "      <td>43.814329</td>\n",
       "      <td>-14.776267</td>\n",
       "      <td>-58.171734</td>\n",
       "      <td>41.447833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>-185.620698</td>\n",
       "      <td>52.920769</td>\n",
       "      <td>-47.945777</td>\n",
       "      <td>-83.124402</td>\n",
       "      <td>40.352731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>-91.451870</td>\n",
       "      <td>264.075966</td>\n",
       "      <td>76.450083</td>\n",
       "      <td>-1.703025</td>\n",
       "      <td>-8.193873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>-91.335074</td>\n",
       "      <td>264.391132</td>\n",
       "      <td>76.352962</td>\n",
       "      <td>-1.949720</td>\n",
       "      <td>-8.962523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>-172.345800</td>\n",
       "      <td>90.193096</td>\n",
       "      <td>-56.176352</td>\n",
       "      <td>-81.103608</td>\n",
       "      <td>13.331868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>-3.052927</td>\n",
       "      <td>147.899172</td>\n",
       "      <td>-9.037352</td>\n",
       "      <td>-16.325404</td>\n",
       "      <td>-1.645751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>-84.234741</td>\n",
       "      <td>47.216060</td>\n",
       "      <td>-16.115202</td>\n",
       "      <td>-66.284362</td>\n",
       "      <td>21.831975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-84.332849</td>\n",
       "      <td>46.951321</td>\n",
       "      <td>-16.033620</td>\n",
       "      <td>-66.077138</td>\n",
       "      <td>22.477640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>-23.102413</td>\n",
       "      <td>126.361274</td>\n",
       "      <td>47.671813</td>\n",
       "      <td>-16.933935</td>\n",
       "      <td>20.988498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>-167.528771</td>\n",
       "      <td>87.652650</td>\n",
       "      <td>-7.168452</td>\n",
       "      <td>-68.667847</td>\n",
       "      <td>32.897344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>-150.407099</td>\n",
       "      <td>-22.758977</td>\n",
       "      <td>-146.932790</td>\n",
       "      <td>-103.022997</td>\n",
       "      <td>38.821117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>-84.622503</td>\n",
       "      <td>46.169710</td>\n",
       "      <td>-15.792760</td>\n",
       "      <td>-65.465334</td>\n",
       "      <td>24.383891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>-192.067461</td>\n",
       "      <td>48.646049</td>\n",
       "      <td>-96.584545</td>\n",
       "      <td>-97.554187</td>\n",
       "      <td>22.601739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>-115.821615</td>\n",
       "      <td>12.998470</td>\n",
       "      <td>-54.459016</td>\n",
       "      <td>-82.167003</td>\n",
       "      <td>33.109269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>-23.219209</td>\n",
       "      <td>126.046108</td>\n",
       "      <td>47.768934</td>\n",
       "      <td>-16.687240</td>\n",
       "      <td>21.757148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>29.551422</td>\n",
       "      <td>189.932008</td>\n",
       "      <td>63.657233</td>\n",
       "      <td>15.519420</td>\n",
       "      <td>7.283844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>-116.882305</td>\n",
       "      <td>218.573134</td>\n",
       "      <td>3.097674</td>\n",
       "      <td>-32.282718</td>\n",
       "      <td>-16.694897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>-147.911941</td>\n",
       "      <td>144.314008</td>\n",
       "      <td>-21.940197</td>\n",
       "      <td>-59.768289</td>\n",
       "      <td>1.280516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>-150.019337</td>\n",
       "      <td>-21.712628</td>\n",
       "      <td>-147.255231</td>\n",
       "      <td>-103.842025</td>\n",
       "      <td>36.269201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>-147.324170</td>\n",
       "      <td>129.674608</td>\n",
       "      <td>29.413054</td>\n",
       "      <td>-50.609563</td>\n",
       "      <td>25.946606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>-192.086148</td>\n",
       "      <td>48.595623</td>\n",
       "      <td>-96.569006</td>\n",
       "      <td>-97.514716</td>\n",
       "      <td>22.724723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>-146.917721</td>\n",
       "      <td>130.771383</td>\n",
       "      <td>29.075073</td>\n",
       "      <td>-51.468062</td>\n",
       "      <td>23.271705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>-167.547458</td>\n",
       "      <td>87.602224</td>\n",
       "      <td>-7.152912</td>\n",
       "      <td>-68.628376</td>\n",
       "      <td>33.020328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>-122.731449</td>\n",
       "      <td>185.789640</td>\n",
       "      <td>58.772860</td>\n",
       "      <td>-29.180213</td>\n",
       "      <td>12.837415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>-91.741524</td>\n",
       "      <td>263.294356</td>\n",
       "      <td>76.690943</td>\n",
       "      <td>-1.091221</td>\n",
       "      <td>-6.287622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>49.245083</td>\n",
       "      <td>-73.053303</td>\n",
       "      <td>-6.210673</td>\n",
       "      <td>-73.523376</td>\n",
       "      <td>29.081875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>49.226396</td>\n",
       "      <td>-73.103730</td>\n",
       "      <td>-6.195134</td>\n",
       "      <td>-73.483905</td>\n",
       "      <td>29.204859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>49.128288</td>\n",
       "      <td>-73.368468</td>\n",
       "      <td>-6.113552</td>\n",
       "      <td>-73.276681</td>\n",
       "      <td>29.850524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>48.838634</td>\n",
       "      <td>-74.150079</td>\n",
       "      <td>-5.872692</td>\n",
       "      <td>-72.664878</td>\n",
       "      <td>31.756775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>49.044864</td>\n",
       "      <td>-73.593581</td>\n",
       "      <td>-6.044182</td>\n",
       "      <td>-73.100475</td>\n",
       "      <td>30.399547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>70.470716</td>\n",
       "      <td>-71.277204</td>\n",
       "      <td>6.031382</td>\n",
       "      <td>-73.817231</td>\n",
       "      <td>20.635944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>70.452029</td>\n",
       "      <td>-71.327631</td>\n",
       "      <td>6.046921</td>\n",
       "      <td>-73.777760</td>\n",
       "      <td>20.758928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>70.353920</td>\n",
       "      <td>-71.592370</td>\n",
       "      <td>6.128503</td>\n",
       "      <td>-73.570536</td>\n",
       "      <td>21.404594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>70.064266</td>\n",
       "      <td>-72.373980</td>\n",
       "      <td>6.369363</td>\n",
       "      <td>-72.958732</td>\n",
       "      <td>23.310845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>70.270496</td>\n",
       "      <td>-71.817482</td>\n",
       "      <td>6.197873</td>\n",
       "      <td>-73.394329</td>\n",
       "      <td>21.953616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>90.007300</td>\n",
       "      <td>-73.400227</td>\n",
       "      <td>35.078574</td>\n",
       "      <td>-79.438434</td>\n",
       "      <td>9.146040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>89.988613</td>\n",
       "      <td>-73.450654</td>\n",
       "      <td>35.094113</td>\n",
       "      <td>-79.398963</td>\n",
       "      <td>9.269024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>89.890504</td>\n",
       "      <td>-73.715393</td>\n",
       "      <td>35.175695</td>\n",
       "      <td>-79.191739</td>\n",
       "      <td>9.914689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>89.600851</td>\n",
       "      <td>-74.497003</td>\n",
       "      <td>35.416555</td>\n",
       "      <td>-78.579935</td>\n",
       "      <td>11.820940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>89.807081</td>\n",
       "      <td>-73.940506</td>\n",
       "      <td>35.245065</td>\n",
       "      <td>-79.015533</td>\n",
       "      <td>10.463712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>-4.493965</td>\n",
       "      <td>-89.095117</td>\n",
       "      <td>115.204414</td>\n",
       "      <td>-92.765545</td>\n",
       "      <td>34.040248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>-4.592074</td>\n",
       "      <td>-89.359856</td>\n",
       "      <td>115.285996</td>\n",
       "      <td>-92.558321</td>\n",
       "      <td>34.685914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>51.807610</td>\n",
       "      <td>-67.975796</td>\n",
       "      <td>93.471129</td>\n",
       "      <td>-71.132886</td>\n",
       "      <td>27.200906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>51.709501</td>\n",
       "      <td>-68.240535</td>\n",
       "      <td>93.552710</td>\n",
       "      <td>-70.925662</td>\n",
       "      <td>27.846572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>59.679384</td>\n",
       "      <td>-37.227051</td>\n",
       "      <td>72.115881</td>\n",
       "      <td>-33.127357</td>\n",
       "      <td>50.531987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>225.708680</td>\n",
       "      <td>9.633490</td>\n",
       "      <td>-34.407303</td>\n",
       "      <td>13.600658</td>\n",
       "      <td>21.609252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>225.419026</td>\n",
       "      <td>8.851880</td>\n",
       "      <td>-34.166443</td>\n",
       "      <td>14.212462</td>\n",
       "      <td>23.515503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>149.800302</td>\n",
       "      <td>-31.525277</td>\n",
       "      <td>56.209955</td>\n",
       "      <td>-33.355701</td>\n",
       "      <td>15.847941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>37.408372</td>\n",
       "      <td>-75.208964</td>\n",
       "      <td>104.479398</td>\n",
       "      <td>-79.143198</td>\n",
       "      <td>27.229510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>37.302200</td>\n",
       "      <td>-75.550989</td>\n",
       "      <td>104.549270</td>\n",
       "      <td>-78.975869</td>\n",
       "      <td>27.412771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>271.920891</td>\n",
       "      <td>8.659238</td>\n",
       "      <td>176.441666</td>\n",
       "      <td>-1.594609</td>\n",
       "      <td>-3.990866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>271.911547</td>\n",
       "      <td>8.634024</td>\n",
       "      <td>176.449436</td>\n",
       "      <td>-1.574873</td>\n",
       "      <td>-3.929374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>271.892860</td>\n",
       "      <td>8.583598</td>\n",
       "      <td>176.464975</td>\n",
       "      <td>-1.535402</td>\n",
       "      <td>-3.806390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>271.860157</td>\n",
       "      <td>8.495352</td>\n",
       "      <td>176.492169</td>\n",
       "      <td>-1.466327</td>\n",
       "      <td>-3.591168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>271.794751</td>\n",
       "      <td>8.318859</td>\n",
       "      <td>176.546557</td>\n",
       "      <td>-1.328178</td>\n",
       "      <td>-3.160725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>307.762757</td>\n",
       "      <td>8.883460</td>\n",
       "      <td>169.753795</td>\n",
       "      <td>-2.786779</td>\n",
       "      <td>-30.423185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>307.730054</td>\n",
       "      <td>8.795214</td>\n",
       "      <td>169.780989</td>\n",
       "      <td>-2.717705</td>\n",
       "      <td>-30.207963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>307.664648</td>\n",
       "      <td>8.618722</td>\n",
       "      <td>169.835376</td>\n",
       "      <td>-2.579555</td>\n",
       "      <td>-29.777520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>307.374995</td>\n",
       "      <td>7.837111</td>\n",
       "      <td>170.076236</td>\n",
       "      <td>-1.967752</td>\n",
       "      <td>-27.871268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>307.581225</td>\n",
       "      <td>8.393609</td>\n",
       "      <td>169.904747</td>\n",
       "      <td>-2.403349</td>\n",
       "      <td>-29.228497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>307.581225</td>\n",
       "      <td>8.393609</td>\n",
       "      <td>169.904747</td>\n",
       "      <td>-2.403349</td>\n",
       "      <td>-29.228497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>97.119759</td>\n",
       "      <td>-33.202657</td>\n",
       "      <td>-12.740126</td>\n",
       "      <td>-29.142982</td>\n",
       "      <td>46.210785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>97.087057</td>\n",
       "      <td>-33.290903</td>\n",
       "      <td>-12.712932</td>\n",
       "      <td>-29.073908</td>\n",
       "      <td>46.426007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>97.021651</td>\n",
       "      <td>-33.467396</td>\n",
       "      <td>-12.658544</td>\n",
       "      <td>-28.935759</td>\n",
       "      <td>46.856450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>96.890839</td>\n",
       "      <td>-33.820381</td>\n",
       "      <td>-12.549769</td>\n",
       "      <td>-28.659460</td>\n",
       "      <td>47.717338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>96.731997</td>\n",
       "      <td>-34.249006</td>\n",
       "      <td>-12.417684</td>\n",
       "      <td>-28.323955</td>\n",
       "      <td>48.762702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>96.938227</td>\n",
       "      <td>-33.692508</td>\n",
       "      <td>-12.589174</td>\n",
       "      <td>-28.759552</td>\n",
       "      <td>47.405473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>131.149303</td>\n",
       "      <td>-24.436024</td>\n",
       "      <td>-18.382145</td>\n",
       "      <td>-20.528434</td>\n",
       "      <td>31.403904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>131.139960</td>\n",
       "      <td>-24.461238</td>\n",
       "      <td>-18.374375</td>\n",
       "      <td>-20.508699</td>\n",
       "      <td>31.465396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>131.121272</td>\n",
       "      <td>-24.511664</td>\n",
       "      <td>-18.358836</td>\n",
       "      <td>-20.469227</td>\n",
       "      <td>31.588380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>131.088569</td>\n",
       "      <td>-24.599910</td>\n",
       "      <td>-18.331642</td>\n",
       "      <td>-20.400153</td>\n",
       "      <td>31.803602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>131.023164</td>\n",
       "      <td>-24.776403</td>\n",
       "      <td>-18.277254</td>\n",
       "      <td>-20.262004</td>\n",
       "      <td>32.234046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>68.480204</td>\n",
       "      <td>-60.303149</td>\n",
       "      <td>-34.293215</td>\n",
       "      <td>-57.399779</td>\n",
       "      <td>33.755991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>68.480204</td>\n",
       "      <td>-60.303149</td>\n",
       "      <td>-34.293215</td>\n",
       "      <td>-57.399779</td>\n",
       "      <td>33.755991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>90.515820</td>\n",
       "      <td>-69.426335</td>\n",
       "      <td>29.424042</td>\n",
       "      <td>-74.361551</td>\n",
       "      <td>12.473696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>68.680424</td>\n",
       "      <td>-59.762871</td>\n",
       "      <td>-34.459707</td>\n",
       "      <td>-57.822680</td>\n",
       "      <td>32.438319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>135.367208</td>\n",
       "      <td>-36.498960</td>\n",
       "      <td>61.438113</td>\n",
       "      <td>-38.872455</td>\n",
       "      <td>17.157570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>135.269100</td>\n",
       "      <td>-36.763699</td>\n",
       "      <td>61.519695</td>\n",
       "      <td>-38.665231</td>\n",
       "      <td>17.803236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>126.400929</td>\n",
       "      <td>-75.874930</td>\n",
       "      <td>88.456713</td>\n",
       "      <td>-87.632071</td>\n",
       "      <td>-13.215133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>37.310263</td>\n",
       "      <td>-75.473703</td>\n",
       "      <td>104.560980</td>\n",
       "      <td>-78.935974</td>\n",
       "      <td>27.875175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>93.588772</td>\n",
       "      <td>-52.457147</td>\n",
       "      <td>77.849948</td>\n",
       "      <td>-55.235478</td>\n",
       "      <td>21.579213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>93.490663</td>\n",
       "      <td>-52.721886</td>\n",
       "      <td>77.931530</td>\n",
       "      <td>-55.028254</td>\n",
       "      <td>22.224879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>50.501464</td>\n",
       "      <td>-62.128510</td>\n",
       "      <td>76.523705</td>\n",
       "      <td>-63.066081</td>\n",
       "      <td>32.871872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>50.403356</td>\n",
       "      <td>-62.393249</td>\n",
       "      <td>76.605286</td>\n",
       "      <td>-62.858857</td>\n",
       "      <td>33.517537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>-4.618989</td>\n",
       "      <td>-89.152179</td>\n",
       "      <td>114.460210</td>\n",
       "      <td>-92.212390</td>\n",
       "      <td>34.498751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>52.665980</td>\n",
       "      <td>-64.208297</td>\n",
       "      <td>91.700545</td>\n",
       "      <td>-66.825123</td>\n",
       "      <td>32.485516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>52.567872</td>\n",
       "      <td>-64.473036</td>\n",
       "      <td>91.782126</td>\n",
       "      <td>-66.617899</td>\n",
       "      <td>33.131181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>52.278218</td>\n",
       "      <td>-65.254646</td>\n",
       "      <td>92.022986</td>\n",
       "      <td>-66.006095</td>\n",
       "      <td>35.037432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>66.814078</td>\n",
       "      <td>-31.551467</td>\n",
       "      <td>-115.053197</td>\n",
       "      <td>-19.625915</td>\n",
       "      <td>59.687232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>68.661736</td>\n",
       "      <td>-59.813297</td>\n",
       "      <td>-34.444167</td>\n",
       "      <td>-57.783209</td>\n",
       "      <td>32.561303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>68.563628</td>\n",
       "      <td>-60.078036</td>\n",
       "      <td>-34.362586</td>\n",
       "      <td>-57.575985</td>\n",
       "      <td>33.206969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>68.273974</td>\n",
       "      <td>-60.859646</td>\n",
       "      <td>-34.121726</td>\n",
       "      <td>-56.964182</td>\n",
       "      <td>35.113220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>90.497132</td>\n",
       "      <td>-69.476761</td>\n",
       "      <td>29.439581</td>\n",
       "      <td>-74.322079</td>\n",
       "      <td>12.596680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>90.399024</td>\n",
       "      <td>-69.741500</td>\n",
       "      <td>29.521163</td>\n",
       "      <td>-74.114855</td>\n",
       "      <td>13.242346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>90.109370</td>\n",
       "      <td>-70.523110</td>\n",
       "      <td>29.762023</td>\n",
       "      <td>-73.503052</td>\n",
       "      <td>15.148597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>90.315600</td>\n",
       "      <td>-69.966613</td>\n",
       "      <td>29.590534</td>\n",
       "      <td>-73.938649</td>\n",
       "      <td>13.791368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>90.315600</td>\n",
       "      <td>-69.966613</td>\n",
       "      <td>29.590534</td>\n",
       "      <td>-73.938649</td>\n",
       "      <td>13.791368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>44.287305</td>\n",
       "      <td>-55.883904</td>\n",
       "      <td>-28.449021</td>\n",
       "      <td>-51.327143</td>\n",
       "      <td>51.477507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>44.138475</td>\n",
       "      <td>-56.285510</td>\n",
       "      <td>-28.325262</td>\n",
       "      <td>-51.012787</td>\n",
       "      <td>52.456973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>294.177386</td>\n",
       "      <td>8.735220</td>\n",
       "      <td>172.490237</td>\n",
       "      <td>-1.699703</td>\n",
       "      <td>-16.530575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>271.505097</td>\n",
       "      <td>7.537249</td>\n",
       "      <td>176.787417</td>\n",
       "      <td>-0.716374</td>\n",
       "      <td>-1.254473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>271.711327</td>\n",
       "      <td>8.093746</td>\n",
       "      <td>176.615927</td>\n",
       "      <td>-1.151972</td>\n",
       "      <td>-2.611702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>271.711327</td>\n",
       "      <td>8.093746</td>\n",
       "      <td>176.615927</td>\n",
       "      <td>-1.151972</td>\n",
       "      <td>-2.611702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>307.781444</td>\n",
       "      <td>8.933887</td>\n",
       "      <td>169.738255</td>\n",
       "      <td>-2.826251</td>\n",
       "      <td>-30.546169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>9.108131</td>\n",
       "      <td>-83.708684</td>\n",
       "      <td>109.228763</td>\n",
       "      <td>-87.105728</td>\n",
       "      <td>32.251088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>9.010022</td>\n",
       "      <td>-83.973423</td>\n",
       "      <td>109.310345</td>\n",
       "      <td>-86.898504</td>\n",
       "      <td>32.896754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>93.320995</td>\n",
       "      <td>-50.157212</td>\n",
       "      <td>70.604849</td>\n",
       "      <td>-51.555821</td>\n",
       "      <td>24.702053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>139.046023</td>\n",
       "      <td>-13.762441</td>\n",
       "      <td>-37.962166</td>\n",
       "      <td>-7.598619</td>\n",
       "      <td>39.987195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>138.929227</td>\n",
       "      <td>-14.077606</td>\n",
       "      <td>-37.865045</td>\n",
       "      <td>-7.351924</td>\n",
       "      <td>40.755845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>138.639573</td>\n",
       "      <td>-14.859217</td>\n",
       "      <td>-37.624185</td>\n",
       "      <td>-6.740121</td>\n",
       "      <td>42.662096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>135.359145</td>\n",
       "      <td>-36.576247</td>\n",
       "      <td>61.426403</td>\n",
       "      <td>-38.912350</td>\n",
       "      <td>16.695166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>135.261036</td>\n",
       "      <td>-36.840986</td>\n",
       "      <td>61.507984</td>\n",
       "      <td>-38.705126</td>\n",
       "      <td>17.340831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>9.116194</td>\n",
       "      <td>-83.631397</td>\n",
       "      <td>109.240474</td>\n",
       "      <td>-87.065833</td>\n",
       "      <td>32.713492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>43.913366</td>\n",
       "      <td>-70.530053</td>\n",
       "      <td>-51.533975</td>\n",
       "      <td>-67.975554</td>\n",
       "      <td>35.095117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>43.815257</td>\n",
       "      <td>-70.794792</td>\n",
       "      <td>-51.452393</td>\n",
       "      <td>-67.768330</td>\n",
       "      <td>35.740783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>43.525604</td>\n",
       "      <td>-71.576402</td>\n",
       "      <td>-51.211533</td>\n",
       "      <td>-67.156526</td>\n",
       "      <td>37.647034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>43.731834</td>\n",
       "      <td>-71.019904</td>\n",
       "      <td>-51.383022</td>\n",
       "      <td>-67.592123</td>\n",
       "      <td>36.289805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>43.731834</td>\n",
       "      <td>-71.019904</td>\n",
       "      <td>-51.383022</td>\n",
       "      <td>-67.592123</td>\n",
       "      <td>36.289805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>294.377605</td>\n",
       "      <td>9.275498</td>\n",
       "      <td>172.323746</td>\n",
       "      <td>-2.122604</td>\n",
       "      <td>-17.848247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>294.358918</td>\n",
       "      <td>9.225072</td>\n",
       "      <td>172.339285</td>\n",
       "      <td>-2.083133</td>\n",
       "      <td>-17.725263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>294.326215</td>\n",
       "      <td>9.136825</td>\n",
       "      <td>172.366479</td>\n",
       "      <td>-2.014058</td>\n",
       "      <td>-17.510041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>294.260810</td>\n",
       "      <td>8.960333</td>\n",
       "      <td>172.420867</td>\n",
       "      <td>-1.875909</td>\n",
       "      <td>-17.079597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>293.971156</td>\n",
       "      <td>8.178723</td>\n",
       "      <td>172.661727</td>\n",
       "      <td>-1.264105</td>\n",
       "      <td>-15.173346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>294.177386</td>\n",
       "      <td>8.735220</td>\n",
       "      <td>172.490237</td>\n",
       "      <td>-1.699703</td>\n",
       "      <td>-16.530575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>66.174170</td>\n",
       "      <td>-46.705024</td>\n",
       "      <td>-22.171009</td>\n",
       "      <td>-42.322370</td>\n",
       "      <td>49.230968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>66.108764</td>\n",
       "      <td>-46.881516</td>\n",
       "      <td>-22.116621</td>\n",
       "      <td>-42.184221</td>\n",
       "      <td>49.661412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>66.025341</td>\n",
       "      <td>-47.106629</td>\n",
       "      <td>-22.047250</td>\n",
       "      <td>-42.008014</td>\n",
       "      <td>50.210434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>44.221899</td>\n",
       "      <td>-56.060397</td>\n",
       "      <td>-28.394633</td>\n",
       "      <td>-51.188993</td>\n",
       "      <td>51.907951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>149.792238</td>\n",
       "      <td>-31.602564</td>\n",
       "      <td>56.198244</td>\n",
       "      <td>-33.395595</td>\n",
       "      <td>15.385537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>225.825475</td>\n",
       "      <td>9.948655</td>\n",
       "      <td>-34.504424</td>\n",
       "      <td>13.353963</td>\n",
       "      <td>20.840602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>223.012868</td>\n",
       "      <td>-61.956960</td>\n",
       "      <td>-171.847387</td>\n",
       "      <td>-66.784559</td>\n",
       "      <td>-53.747323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>222.914760</td>\n",
       "      <td>-62.221698</td>\n",
       "      <td>-171.765805</td>\n",
       "      <td>-66.577335</td>\n",
       "      <td>-53.101658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>-1.136678</td>\n",
       "      <td>82.543813</td>\n",
       "      <td>-5.387125</td>\n",
       "      <td>90.513649</td>\n",
       "      <td>29.633744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>-156.081476</td>\n",
       "      <td>108.703771</td>\n",
       "      <td>-76.657203</td>\n",
       "      <td>115.607337</td>\n",
       "      <td>-20.655433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>-121.134048</td>\n",
       "      <td>101.901166</td>\n",
       "      <td>41.106822</td>\n",
       "      <td>110.702263</td>\n",
       "      <td>42.889521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>-153.862096</td>\n",
       "      <td>22.494281</td>\n",
       "      <td>-104.310135</td>\n",
       "      <td>31.324706</td>\n",
       "      <td>31.865290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>-147.289024</td>\n",
       "      <td>92.202096</td>\n",
       "      <td>36.874000</td>\n",
       "      <td>94.499392</td>\n",
       "      <td>-27.805356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>21.049110</td>\n",
       "      <td>112.518521</td>\n",
       "      <td>11.970516</td>\n",
       "      <td>114.959218</td>\n",
       "      <td>-31.919954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>-144.492524</td>\n",
       "      <td>-126.949852</td>\n",
       "      <td>-41.471612</td>\n",
       "      <td>73.147080</td>\n",
       "      <td>-1.527136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>25.308558</td>\n",
       "      <td>119.829549</td>\n",
       "      <td>-43.015339</td>\n",
       "      <td>5.450007</td>\n",
       "      <td>35.137479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>129.438869</td>\n",
       "      <td>-23.052226</td>\n",
       "      <td>40.085644</td>\n",
       "      <td>-20.339588</td>\n",
       "      <td>33.742853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>-132.811359</td>\n",
       "      <td>63.637837</td>\n",
       "      <td>29.530870</td>\n",
       "      <td>66.304927</td>\n",
       "      <td>-10.458285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>-129.250664</td>\n",
       "      <td>173.337401</td>\n",
       "      <td>87.137412</td>\n",
       "      <td>-33.266654</td>\n",
       "      <td>14.347987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>11.276394</td>\n",
       "      <td>74.988665</td>\n",
       "      <td>-74.871083</td>\n",
       "      <td>-48.023857</td>\n",
       "      <td>-18.582592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>49.556998</td>\n",
       "      <td>-30.470076</td>\n",
       "      <td>22.678059</td>\n",
       "      <td>87.296014</td>\n",
       "      <td>32.474164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>-122.896841</td>\n",
       "      <td>-108.441317</td>\n",
       "      <td>36.945910</td>\n",
       "      <td>99.844017</td>\n",
       "      <td>3.406691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>-172.510348</td>\n",
       "      <td>61.520233</td>\n",
       "      <td>-61.087987</td>\n",
       "      <td>65.415884</td>\n",
       "      <td>-19.625355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>11.632832</td>\n",
       "      <td>119.431391</td>\n",
       "      <td>-16.971712</td>\n",
       "      <td>125.791762</td>\n",
       "      <td>2.802914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>21.243809</td>\n",
       "      <td>120.174342</td>\n",
       "      <td>-95.847891</td>\n",
       "      <td>-18.103485</td>\n",
       "      <td>-1.609951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>58.119003</td>\n",
       "      <td>161.732352</td>\n",
       "      <td>-131.520916</td>\n",
       "      <td>4.489114</td>\n",
       "      <td>-11.130486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>-35.875593</td>\n",
       "      <td>56.743232</td>\n",
       "      <td>-141.167420</td>\n",
       "      <td>61.371612</td>\n",
       "      <td>-24.995649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>-49.714849</td>\n",
       "      <td>29.180676</td>\n",
       "      <td>-136.888287</td>\n",
       "      <td>38.225646</td>\n",
       "      <td>15.729862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>-92.240590</td>\n",
       "      <td>-84.867373</td>\n",
       "      <td>84.371428</td>\n",
       "      <td>86.278432</td>\n",
       "      <td>25.811127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>-130.685307</td>\n",
       "      <td>162.749176</td>\n",
       "      <td>94.746599</td>\n",
       "      <td>-49.860294</td>\n",
       "      <td>-7.874410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>-149.781795</td>\n",
       "      <td>126.685364</td>\n",
       "      <td>-65.980990</td>\n",
       "      <td>135.301558</td>\n",
       "      <td>5.144176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>15.247315</td>\n",
       "      <td>-62.675508</td>\n",
       "      <td>-102.593177</td>\n",
       "      <td>63.945970</td>\n",
       "      <td>18.020726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>46.541903</td>\n",
       "      <td>-23.725552</td>\n",
       "      <td>-76.391054</td>\n",
       "      <td>127.309862</td>\n",
       "      <td>39.601499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>0.365769</td>\n",
       "      <td>82.778988</td>\n",
       "      <td>-16.955338</td>\n",
       "      <td>86.868789</td>\n",
       "      <td>-3.949382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>21.630653</td>\n",
       "      <td>109.819870</td>\n",
       "      <td>-96.082369</td>\n",
       "      <td>-32.197108</td>\n",
       "      <td>-19.972482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>66.693455</td>\n",
       "      <td>-29.900808</td>\n",
       "      <td>-154.183156</td>\n",
       "      <td>139.479719</td>\n",
       "      <td>14.730047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>-189.240979</td>\n",
       "      <td>110.149434</td>\n",
       "      <td>-45.430252</td>\n",
       "      <td>113.222124</td>\n",
       "      <td>-30.252892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>42.685426</td>\n",
       "      <td>115.808573</td>\n",
       "      <td>6.393388</td>\n",
       "      <td>-11.965219</td>\n",
       "      <td>-0.535106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>-134.033967</td>\n",
       "      <td>-105.825691</td>\n",
       "      <td>-121.578276</td>\n",
       "      <td>127.234098</td>\n",
       "      <td>15.285852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>36.294729</td>\n",
       "      <td>-62.907950</td>\n",
       "      <td>-50.017179</td>\n",
       "      <td>67.086582</td>\n",
       "      <td>-1.994599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>38.998220</td>\n",
       "      <td>-49.117952</td>\n",
       "      <td>-93.878032</td>\n",
       "      <td>101.309000</td>\n",
       "      <td>9.463526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>-144.004613</td>\n",
       "      <td>124.944448</td>\n",
       "      <td>-0.065673</td>\n",
       "      <td>139.081924</td>\n",
       "      <td>28.186764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>-7.842226</td>\n",
       "      <td>47.411371</td>\n",
       "      <td>-89.556438</td>\n",
       "      <td>-54.742179</td>\n",
       "      <td>-0.921757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>31.482578</td>\n",
       "      <td>-27.780327</td>\n",
       "      <td>-61.993686</td>\n",
       "      <td>102.632311</td>\n",
       "      <td>48.509824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>-37.302681</td>\n",
       "      <td>52.869392</td>\n",
       "      <td>-123.419014</td>\n",
       "      <td>60.258292</td>\n",
       "      <td>9.186116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>-126.447188</td>\n",
       "      <td>164.449249</td>\n",
       "      <td>121.357213</td>\n",
       "      <td>-56.659551</td>\n",
       "      <td>-22.988948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>-158.834575</td>\n",
       "      <td>162.511583</td>\n",
       "      <td>-111.804224</td>\n",
       "      <td>-58.894932</td>\n",
       "      <td>-10.322820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>-24.192729</td>\n",
       "      <td>54.756569</td>\n",
       "      <td>-83.056260</td>\n",
       "      <td>59.198406</td>\n",
       "      <td>-10.337936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>34.253985</td>\n",
       "      <td>-44.948669</td>\n",
       "      <td>-154.772556</td>\n",
       "      <td>95.512011</td>\n",
       "      <td>26.644722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>-151.880101</td>\n",
       "      <td>48.138615</td>\n",
       "      <td>-51.531326</td>\n",
       "      <td>54.963318</td>\n",
       "      <td>10.463289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>-132.881933</td>\n",
       "      <td>85.865707</td>\n",
       "      <td>18.642001</td>\n",
       "      <td>-76.254754</td>\n",
       "      <td>-0.065123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>-28.753103</td>\n",
       "      <td>51.866565</td>\n",
       "      <td>-81.240784</td>\n",
       "      <td>60.309331</td>\n",
       "      <td>22.236083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>-31.939134</td>\n",
       "      <td>79.125895</td>\n",
       "      <td>-49.689529</td>\n",
       "      <td>95.461730</td>\n",
       "      <td>51.444109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>58.169527</td>\n",
       "      <td>-40.125467</td>\n",
       "      <td>65.342154</td>\n",
       "      <td>87.917199</td>\n",
       "      <td>7.697379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>-113.305728</td>\n",
       "      <td>110.844153</td>\n",
       "      <td>117.275369</td>\n",
       "      <td>-47.683700</td>\n",
       "      <td>21.765443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>-178.711879</td>\n",
       "      <td>127.716689</td>\n",
       "      <td>-158.737494</td>\n",
       "      <td>-64.644801</td>\n",
       "      <td>17.346328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>20.930804</td>\n",
       "      <td>-25.637875</td>\n",
       "      <td>-130.154765</td>\n",
       "      <td>108.431470</td>\n",
       "      <td>61.453791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>-164.959135</td>\n",
       "      <td>112.479644</td>\n",
       "      <td>-14.067163</td>\n",
       "      <td>-67.110235</td>\n",
       "      <td>17.310448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>8.085040</td>\n",
       "      <td>81.489739</td>\n",
       "      <td>-124.657539</td>\n",
       "      <td>-40.618298</td>\n",
       "      <td>-8.557003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>-115.710203</td>\n",
       "      <td>-105.766356</td>\n",
       "      <td>12.208305</td>\n",
       "      <td>24.066299</td>\n",
       "      <td>34.602219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>-128.396618</td>\n",
       "      <td>61.993197</td>\n",
       "      <td>87.830156</td>\n",
       "      <td>62.462093</td>\n",
       "      <td>-7.521722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>-150.308120</td>\n",
       "      <td>51.213434</td>\n",
       "      <td>-15.402830</td>\n",
       "      <td>57.204404</td>\n",
       "      <td>23.810525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>-182.387166</td>\n",
       "      <td>114.890503</td>\n",
       "      <td>-155.212734</td>\n",
       "      <td>-85.439538</td>\n",
       "      <td>-11.086018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>33.989387</td>\n",
       "      <td>-23.429863</td>\n",
       "      <td>-54.783506</td>\n",
       "      <td>121.468226</td>\n",
       "      <td>47.394482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-161.460054</td>\n",
       "      <td>37.048409</td>\n",
       "      <td>-97.316782</td>\n",
       "      <td>42.348318</td>\n",
       "      <td>-8.635846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>-128.123070</td>\n",
       "      <td>-125.202611</td>\n",
       "      <td>13.158540</td>\n",
       "      <td>30.130362</td>\n",
       "      <td>4.009702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>37.403101</td>\n",
       "      <td>-36.568182</td>\n",
       "      <td>-157.182333</td>\n",
       "      <td>129.450118</td>\n",
       "      <td>26.138230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>-133.305965</td>\n",
       "      <td>34.982629</td>\n",
       "      <td>10.309303</td>\n",
       "      <td>-90.166603</td>\n",
       "      <td>11.930399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>-25.949366</td>\n",
       "      <td>61.803076</td>\n",
       "      <td>-40.681891</td>\n",
       "      <td>66.806171</td>\n",
       "      <td>9.432499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>-107.016769</td>\n",
       "      <td>-53.102783</td>\n",
       "      <td>-6.190634</td>\n",
       "      <td>177.343951</td>\n",
       "      <td>62.346591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>-100.327259</td>\n",
       "      <td>-88.267573</td>\n",
       "      <td>156.867920</td>\n",
       "      <td>118.935464</td>\n",
       "      <td>6.340002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>9.521797</td>\n",
       "      <td>-47.860899</td>\n",
       "      <td>-26.905551</td>\n",
       "      <td>60.621681</td>\n",
       "      <td>41.631595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>-140.911929</td>\n",
       "      <td>19.055201</td>\n",
       "      <td>-1.820863</td>\n",
       "      <td>22.468209</td>\n",
       "      <td>7.864120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>-141.250919</td>\n",
       "      <td>103.201399</td>\n",
       "      <td>86.683790</td>\n",
       "      <td>118.642665</td>\n",
       "      <td>-2.206855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>-29.288630</td>\n",
       "      <td>28.796282</td>\n",
       "      <td>-23.968827</td>\n",
       "      <td>30.115936</td>\n",
       "      <td>-12.254217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>19.052392</td>\n",
       "      <td>110.085804</td>\n",
       "      <td>-48.092972</td>\n",
       "      <td>-27.975157</td>\n",
       "      <td>-11.993403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>-2.151410</td>\n",
       "      <td>44.480173</td>\n",
       "      <td>-19.019905</td>\n",
       "      <td>-60.106065</td>\n",
       "      <td>-10.318076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>74.936735</td>\n",
       "      <td>-59.090130</td>\n",
       "      <td>-24.349294</td>\n",
       "      <td>-56.719158</td>\n",
       "      <td>26.605592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>-126.312229</td>\n",
       "      <td>-107.641845</td>\n",
       "      <td>5.239748</td>\n",
       "      <td>47.234844</td>\n",
       "      <td>29.102619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>-128.320004</td>\n",
       "      <td>154.712311</td>\n",
       "      <td>146.830935</td>\n",
       "      <td>-54.795864</td>\n",
       "      <td>-12.068500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>-177.908647</td>\n",
       "      <td>74.698081</td>\n",
       "      <td>-128.491162</td>\n",
       "      <td>83.608376</td>\n",
       "      <td>-1.397260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>21.100635</td>\n",
       "      <td>129.422430</td>\n",
       "      <td>-161.195128</td>\n",
       "      <td>-11.155241</td>\n",
       "      <td>2.224809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>-91.910096</td>\n",
       "      <td>-74.243929</td>\n",
       "      <td>123.405897</td>\n",
       "      <td>89.433168</td>\n",
       "      <td>40.680027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>-155.167228</td>\n",
       "      <td>78.962458</td>\n",
       "      <td>-116.430011</td>\n",
       "      <td>-73.546975</td>\n",
       "      <td>20.078979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>-141.228354</td>\n",
       "      <td>-109.774748</td>\n",
       "      <td>-3.412307</td>\n",
       "      <td>81.196166</td>\n",
       "      <td>23.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>-25.449297</td>\n",
       "      <td>51.251558</td>\n",
       "      <td>-36.073506</td>\n",
       "      <td>54.595749</td>\n",
       "      <td>-8.829315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>14.130703</td>\n",
       "      <td>109.106999</td>\n",
       "      <td>-46.727467</td>\n",
       "      <td>112.580753</td>\n",
       "      <td>-27.616523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>11.077331</td>\n",
       "      <td>44.843945</td>\n",
       "      <td>-15.222998</td>\n",
       "      <td>-90.700966</td>\n",
       "      <td>-42.713131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>-146.847116</td>\n",
       "      <td>62.801493</td>\n",
       "      <td>2.337883</td>\n",
       "      <td>-87.093637</td>\n",
       "      <td>8.130880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>-152.695078</td>\n",
       "      <td>34.147055</td>\n",
       "      <td>-7.670339</td>\n",
       "      <td>37.075577</td>\n",
       "      <td>-3.597210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>-153.245610</td>\n",
       "      <td>-116.232839</td>\n",
       "      <td>-148.649997</td>\n",
       "      <td>97.791181</td>\n",
       "      <td>21.750601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>0.786182</td>\n",
       "      <td>82.394424</td>\n",
       "      <td>35.657701</td>\n",
       "      <td>85.352047</td>\n",
       "      <td>1.582110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>23.434342</td>\n",
       "      <td>-70.937970</td>\n",
       "      <td>-25.428095</td>\n",
       "      <td>51.296283</td>\n",
       "      <td>-4.377752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>41.148475</td>\n",
       "      <td>106.434527</td>\n",
       "      <td>60.489400</td>\n",
       "      <td>-20.504523</td>\n",
       "      <td>-7.442880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>-149.072709</td>\n",
       "      <td>114.181954</td>\n",
       "      <td>-17.571448</td>\n",
       "      <td>119.650352</td>\n",
       "      <td>-4.503232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>5.325693</td>\n",
       "      <td>86.731437</td>\n",
       "      <td>-38.284128</td>\n",
       "      <td>-25.672492</td>\n",
       "      <td>15.865296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>-147.930969</td>\n",
       "      <td>54.459501</td>\n",
       "      <td>7.126483</td>\n",
       "      <td>-99.214994</td>\n",
       "      <td>-5.531296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>-151.967251</td>\n",
       "      <td>-102.505068</td>\n",
       "      <td>-151.723821</td>\n",
       "      <td>110.067734</td>\n",
       "      <td>43.050878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>53.260180</td>\n",
       "      <td>-67.136036</td>\n",
       "      <td>-12.178700</td>\n",
       "      <td>-64.711497</td>\n",
       "      <td>27.149501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>-170.085160</td>\n",
       "      <td>56.863611</td>\n",
       "      <td>-15.825824</td>\n",
       "      <td>59.121397</td>\n",
       "      <td>-18.916583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>-133.771596</td>\n",
       "      <td>-106.125624</td>\n",
       "      <td>-110.299483</td>\n",
       "      <td>63.569893</td>\n",
       "      <td>38.993563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>-29.982770</td>\n",
       "      <td>40.099471</td>\n",
       "      <td>-28.911655</td>\n",
       "      <td>44.420794</td>\n",
       "      <td>8.343283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>-143.051268</td>\n",
       "      <td>170.233753</td>\n",
       "      <td>-31.701515</td>\n",
       "      <td>192.493025</td>\n",
       "      <td>10.453646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>-179.229281</td>\n",
       "      <td>106.533614</td>\n",
       "      <td>-89.075122</td>\n",
       "      <td>52.728022</td>\n",
       "      <td>6.672467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>-116.826250</td>\n",
       "      <td>107.578793</td>\n",
       "      <td>79.521206</td>\n",
       "      <td>112.336546</td>\n",
       "      <td>5.849716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>-152.950786</td>\n",
       "      <td>157.853755</td>\n",
       "      <td>-57.177627</td>\n",
       "      <td>163.156933</td>\n",
       "      <td>-6.832388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>-160.241167</td>\n",
       "      <td>150.122970</td>\n",
       "      <td>-70.765958</td>\n",
       "      <td>141.883997</td>\n",
       "      <td>-6.415745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>-138.624482</td>\n",
       "      <td>94.079618</td>\n",
       "      <td>71.969351</td>\n",
       "      <td>181.715507</td>\n",
       "      <td>-7.017760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>-140.969749</td>\n",
       "      <td>38.964064</td>\n",
       "      <td>88.564964</td>\n",
       "      <td>167.537036</td>\n",
       "      <td>10.287019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>-150.509757</td>\n",
       "      <td>151.877284</td>\n",
       "      <td>-27.682602</td>\n",
       "      <td>156.841984</td>\n",
       "      <td>-6.569507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>-121.118784</td>\n",
       "      <td>-78.932456</td>\n",
       "      <td>97.643175</td>\n",
       "      <td>127.484169</td>\n",
       "      <td>7.265627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>-137.135075</td>\n",
       "      <td>146.930816</td>\n",
       "      <td>3.881874</td>\n",
       "      <td>213.368717</td>\n",
       "      <td>29.962349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>-136.194144</td>\n",
       "      <td>124.929607</td>\n",
       "      <td>30.947373</td>\n",
       "      <td>183.248096</td>\n",
       "      <td>-27.347426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>-86.695286</td>\n",
       "      <td>50.859239</td>\n",
       "      <td>58.245060</td>\n",
       "      <td>196.145503</td>\n",
       "      <td>28.970469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>-137.280090</td>\n",
       "      <td>145.467793</td>\n",
       "      <td>9.637933</td>\n",
       "      <td>209.273344</td>\n",
       "      <td>19.993663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>-32.145801</td>\n",
       "      <td>78.575096</td>\n",
       "      <td>-49.963714</td>\n",
       "      <td>95.704954</td>\n",
       "      <td>51.291536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>58.510149</td>\n",
       "      <td>-39.899506</td>\n",
       "      <td>65.385854</td>\n",
       "      <td>88.134867</td>\n",
       "      <td>7.935165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>-113.525396</td>\n",
       "      <td>111.189858</td>\n",
       "      <td>117.793776</td>\n",
       "      <td>-47.734035</td>\n",
       "      <td>21.742625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>-178.900629</td>\n",
       "      <td>128.226265</td>\n",
       "      <td>-158.620424</td>\n",
       "      <td>-64.596218</td>\n",
       "      <td>17.385240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>20.917018</td>\n",
       "      <td>-25.756580</td>\n",
       "      <td>-130.207910</td>\n",
       "      <td>107.923650</td>\n",
       "      <td>61.666734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>-164.990392</td>\n",
       "      <td>112.361013</td>\n",
       "      <td>-13.933910</td>\n",
       "      <td>-67.470631</td>\n",
       "      <td>16.833062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>8.363499</td>\n",
       "      <td>81.489289</td>\n",
       "      <td>-124.536831</td>\n",
       "      <td>-40.676823</td>\n",
       "      <td>-8.486838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>-116.022400</td>\n",
       "      <td>-105.680927</td>\n",
       "      <td>12.332516</td>\n",
       "      <td>24.061822</td>\n",
       "      <td>35.016172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>-128.236434</td>\n",
       "      <td>62.207226</td>\n",
       "      <td>87.905831</td>\n",
       "      <td>62.680632</td>\n",
       "      <td>-7.213278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>-150.438979</td>\n",
       "      <td>50.639973</td>\n",
       "      <td>-15.598666</td>\n",
       "      <td>57.304856</td>\n",
       "      <td>23.881901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>-181.871432</td>\n",
       "      <td>115.104895</td>\n",
       "      <td>-155.285027</td>\n",
       "      <td>-85.223501</td>\n",
       "      <td>-11.178134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>33.944256</td>\n",
       "      <td>-23.287249</td>\n",
       "      <td>-54.373338</td>\n",
       "      <td>121.437447</td>\n",
       "      <td>47.401706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>-161.362032</td>\n",
       "      <td>37.036027</td>\n",
       "      <td>-97.164100</td>\n",
       "      <td>42.290664</td>\n",
       "      <td>-8.495022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>-127.969787</td>\n",
       "      <td>-125.055901</td>\n",
       "      <td>12.917541</td>\n",
       "      <td>29.869234</td>\n",
       "      <td>4.238459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>37.766447</td>\n",
       "      <td>-36.769784</td>\n",
       "      <td>-157.458320</td>\n",
       "      <td>129.063436</td>\n",
       "      <td>25.860863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>-133.539341</td>\n",
       "      <td>34.732968</td>\n",
       "      <td>10.009134</td>\n",
       "      <td>-90.098414</td>\n",
       "      <td>12.256943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>-25.818889</td>\n",
       "      <td>61.542995</td>\n",
       "      <td>-40.263231</td>\n",
       "      <td>67.122310</td>\n",
       "      <td>9.908448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>-106.619066</td>\n",
       "      <td>-52.938760</td>\n",
       "      <td>-6.448140</td>\n",
       "      <td>177.426665</td>\n",
       "      <td>62.227567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>-100.655595</td>\n",
       "      <td>-88.541680</td>\n",
       "      <td>157.329668</td>\n",
       "      <td>118.938888</td>\n",
       "      <td>6.056283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>9.210333</td>\n",
       "      <td>-47.961764</td>\n",
       "      <td>-26.713014</td>\n",
       "      <td>60.086107</td>\n",
       "      <td>41.732214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>-140.790218</td>\n",
       "      <td>18.576639</td>\n",
       "      <td>-1.661160</td>\n",
       "      <td>22.006026</td>\n",
       "      <td>7.961710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>-141.410600</td>\n",
       "      <td>103.227939</td>\n",
       "      <td>86.708425</td>\n",
       "      <td>117.929816</td>\n",
       "      <td>-2.681975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>-29.340055</td>\n",
       "      <td>28.458199</td>\n",
       "      <td>-24.136833</td>\n",
       "      <td>30.644423</td>\n",
       "      <td>-12.332299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>18.986150</td>\n",
       "      <td>109.545088</td>\n",
       "      <td>-48.669742</td>\n",
       "      <td>-28.024994</td>\n",
       "      <td>-11.890367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>-2.100422</td>\n",
       "      <td>44.063344</td>\n",
       "      <td>-18.798634</td>\n",
       "      <td>-60.295575</td>\n",
       "      <td>-10.216167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>75.426262</td>\n",
       "      <td>-58.919187</td>\n",
       "      <td>-24.487328</td>\n",
       "      <td>-56.529780</td>\n",
       "      <td>26.457533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>-126.283189</td>\n",
       "      <td>-107.453851</td>\n",
       "      <td>5.947481</td>\n",
       "      <td>47.013866</td>\n",
       "      <td>29.276072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>-128.211969</td>\n",
       "      <td>154.551817</td>\n",
       "      <td>147.189953</td>\n",
       "      <td>-54.779409</td>\n",
       "      <td>-12.078664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>-178.220261</td>\n",
       "      <td>74.754765</td>\n",
       "      <td>-128.551172</td>\n",
       "      <td>83.081676</td>\n",
       "      <td>-1.533535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>20.696821</td>\n",
       "      <td>128.935380</td>\n",
       "      <td>-161.276444</td>\n",
       "      <td>-11.242500</td>\n",
       "      <td>2.458862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>-91.968714</td>\n",
       "      <td>-74.144504</td>\n",
       "      <td>123.929717</td>\n",
       "      <td>89.309366</td>\n",
       "      <td>40.955319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>-155.390666</td>\n",
       "      <td>79.365156</td>\n",
       "      <td>-116.074419</td>\n",
       "      <td>-73.520145</td>\n",
       "      <td>20.111209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>-141.407904</td>\n",
       "      <td>-109.637575</td>\n",
       "      <td>-3.310939</td>\n",
       "      <td>81.040518</td>\n",
       "      <td>23.551262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>-25.363317</td>\n",
       "      <td>51.650649</td>\n",
       "      <td>-36.076377</td>\n",
       "      <td>55.295378</td>\n",
       "      <td>-9.157724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>13.954634</td>\n",
       "      <td>109.146096</td>\n",
       "      <td>-46.761988</td>\n",
       "      <td>112.522720</td>\n",
       "      <td>-27.995616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>10.843149</td>\n",
       "      <td>44.586555</td>\n",
       "      <td>-15.524337</td>\n",
       "      <td>-90.636767</td>\n",
       "      <td>-42.432827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>-146.962884</td>\n",
       "      <td>62.616663</td>\n",
       "      <td>2.336279</td>\n",
       "      <td>-86.828632</td>\n",
       "      <td>8.463381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>-153.067792</td>\n",
       "      <td>34.026090</td>\n",
       "      <td>-7.407634</td>\n",
       "      <td>36.832853</td>\n",
       "      <td>-3.997754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>-153.244165</td>\n",
       "      <td>-116.339263</td>\n",
       "      <td>-148.908365</td>\n",
       "      <td>97.757646</td>\n",
       "      <td>21.792615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>0.941037</td>\n",
       "      <td>82.254903</td>\n",
       "      <td>36.287272</td>\n",
       "      <td>85.393175</td>\n",
       "      <td>1.471886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>23.414727</td>\n",
       "      <td>-71.173262</td>\n",
       "      <td>-25.275368</td>\n",
       "      <td>51.561042</td>\n",
       "      <td>-4.885104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>41.489098</td>\n",
       "      <td>106.660488</td>\n",
       "      <td>60.533100</td>\n",
       "      <td>-20.286855</td>\n",
       "      <td>-7.205094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>-148.804973</td>\n",
       "      <td>114.387463</td>\n",
       "      <td>-17.650249</td>\n",
       "      <td>120.232595</td>\n",
       "      <td>-4.483695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>5.394262</td>\n",
       "      <td>86.419834</td>\n",
       "      <td>-38.246249</td>\n",
       "      <td>-25.728708</td>\n",
       "      <td>15.957768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>-148.253042</td>\n",
       "      <td>54.304115</td>\n",
       "      <td>6.877182</td>\n",
       "      <td>-99.485880</td>\n",
       "      <td>-5.577842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>-151.517578</td>\n",
       "      <td>-102.331535</td>\n",
       "      <td>-151.622834</td>\n",
       "      <td>110.135955</td>\n",
       "      <td>42.924438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>52.939462</td>\n",
       "      <td>-67.154665</td>\n",
       "      <td>-12.485265</td>\n",
       "      <td>-64.697416</td>\n",
       "      <td>27.327604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>-169.666628</td>\n",
       "      <td>56.534270</td>\n",
       "      <td>-16.443215</td>\n",
       "      <td>58.982051</td>\n",
       "      <td>-18.984971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>-133.833984</td>\n",
       "      <td>-105.969206</td>\n",
       "      <td>-109.938478</td>\n",
       "      <td>63.523257</td>\n",
       "      <td>39.323903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>-29.727683</td>\n",
       "      <td>39.788886</td>\n",
       "      <td>-29.134235</td>\n",
       "      <td>44.293426</td>\n",
       "      <td>8.020099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>-1.236239</td>\n",
       "      <td>82.788387</td>\n",
       "      <td>-5.196697</td>\n",
       "      <td>90.499351</td>\n",
       "      <td>29.701439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>-156.221937</td>\n",
       "      <td>108.519102</td>\n",
       "      <td>-76.798872</td>\n",
       "      <td>115.395910</td>\n",
       "      <td>-20.969952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>-121.593408</td>\n",
       "      <td>101.935864</td>\n",
       "      <td>41.389509</td>\n",
       "      <td>110.869509</td>\n",
       "      <td>42.791909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>-154.376359</td>\n",
       "      <td>21.822217</td>\n",
       "      <td>-104.494062</td>\n",
       "      <td>31.340336</td>\n",
       "      <td>31.920049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>-147.346947</td>\n",
       "      <td>92.507491</td>\n",
       "      <td>37.112076</td>\n",
       "      <td>94.466354</td>\n",
       "      <td>-27.779386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>20.923266</td>\n",
       "      <td>112.215338</td>\n",
       "      <td>11.797261</td>\n",
       "      <td>115.067830</td>\n",
       "      <td>-32.016736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>-144.946015</td>\n",
       "      <td>-127.060778</td>\n",
       "      <td>-41.926054</td>\n",
       "      <td>72.937460</td>\n",
       "      <td>-1.200706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>24.868058</td>\n",
       "      <td>119.311626</td>\n",
       "      <td>-42.829559</td>\n",
       "      <td>4.995224</td>\n",
       "      <td>34.799250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>129.626137</td>\n",
       "      <td>-23.262182</td>\n",
       "      <td>39.984075</td>\n",
       "      <td>-20.632570</td>\n",
       "      <td>33.588586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>-133.068840</td>\n",
       "      <td>63.600122</td>\n",
       "      <td>30.009561</td>\n",
       "      <td>66.373392</td>\n",
       "      <td>-10.218769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>-129.507014</td>\n",
       "      <td>173.184895</td>\n",
       "      <td>87.096493</td>\n",
       "      <td>-33.071595</td>\n",
       "      <td>14.693458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>11.339472</td>\n",
       "      <td>74.741426</td>\n",
       "      <td>-74.623766</td>\n",
       "      <td>-48.107523</td>\n",
       "      <td>-18.612444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>49.429174</td>\n",
       "      <td>-30.565369</td>\n",
       "      <td>22.920748</td>\n",
       "      <td>86.738663</td>\n",
       "      <td>32.596862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>-123.007228</td>\n",
       "      <td>-108.596157</td>\n",
       "      <td>37.012581</td>\n",
       "      <td>99.560145</td>\n",
       "      <td>3.232322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>-172.496062</td>\n",
       "      <td>61.233812</td>\n",
       "      <td>-61.565448</td>\n",
       "      <td>65.241132</td>\n",
       "      <td>-19.438746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>11.358603</td>\n",
       "      <td>119.372638</td>\n",
       "      <td>-16.783631</td>\n",
       "      <td>125.380950</td>\n",
       "      <td>2.768283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>21.462472</td>\n",
       "      <td>120.387007</td>\n",
       "      <td>-95.888676</td>\n",
       "      <td>-18.132332</td>\n",
       "      <td>-1.546783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>58.151888</td>\n",
       "      <td>161.719124</td>\n",
       "      <td>-131.211856</td>\n",
       "      <td>4.427400</td>\n",
       "      <td>-11.009072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>-36.091138</td>\n",
       "      <td>56.577533</td>\n",
       "      <td>-140.992233</td>\n",
       "      <td>61.726867</td>\n",
       "      <td>-24.936245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>-49.648824</td>\n",
       "      <td>29.039763</td>\n",
       "      <td>-136.735087</td>\n",
       "      <td>37.509698</td>\n",
       "      <td>15.474242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>-92.663961</td>\n",
       "      <td>-85.082615</td>\n",
       "      <td>84.741078</td>\n",
       "      <td>86.484608</td>\n",
       "      <td>25.540572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>-131.119865</td>\n",
       "      <td>163.276046</td>\n",
       "      <td>94.974805</td>\n",
       "      <td>-49.784880</td>\n",
       "      <td>-7.729036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>-149.628418</td>\n",
       "      <td>126.814068</td>\n",
       "      <td>-66.085588</td>\n",
       "      <td>135.884642</td>\n",
       "      <td>5.105555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>15.294997</td>\n",
       "      <td>-62.733100</td>\n",
       "      <td>-102.717354</td>\n",
       "      <td>63.857383</td>\n",
       "      <td>18.104430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>46.420436</td>\n",
       "      <td>-23.577153</td>\n",
       "      <td>-76.550683</td>\n",
       "      <td>128.060632</td>\n",
       "      <td>39.526342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.830114</td>\n",
       "      <td>82.343739</td>\n",
       "      <td>-16.620306</td>\n",
       "      <td>86.773758</td>\n",
       "      <td>-4.043042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>21.146330</td>\n",
       "      <td>110.218556</td>\n",
       "      <td>-96.351182</td>\n",
       "      <td>-32.116033</td>\n",
       "      <td>-19.909760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>66.611955</td>\n",
       "      <td>-30.061948</td>\n",
       "      <td>-154.067211</td>\n",
       "      <td>138.832645</td>\n",
       "      <td>14.880980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>-188.988132</td>\n",
       "      <td>110.001299</td>\n",
       "      <td>-45.287757</td>\n",
       "      <td>113.502289</td>\n",
       "      <td>-29.906860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>43.135581</td>\n",
       "      <td>115.277409</td>\n",
       "      <td>6.033963</td>\n",
       "      <td>-12.156370</td>\n",
       "      <td>-0.794206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>-133.866354</td>\n",
       "      <td>-105.912569</td>\n",
       "      <td>-121.356541</td>\n",
       "      <td>127.186847</td>\n",
       "      <td>15.211923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>36.230381</td>\n",
       "      <td>-62.843130</td>\n",
       "      <td>-49.694043</td>\n",
       "      <td>66.732831</td>\n",
       "      <td>-1.833255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>39.452374</td>\n",
       "      <td>-48.914764</td>\n",
       "      <td>-93.696047</td>\n",
       "      <td>101.390533</td>\n",
       "      <td>9.614882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>-144.095281</td>\n",
       "      <td>125.245112</td>\n",
       "      <td>-0.120137</td>\n",
       "      <td>139.245400</td>\n",
       "      <td>28.734468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-7.593041</td>\n",
       "      <td>47.259778</td>\n",
       "      <td>-89.975803</td>\n",
       "      <td>-54.956790</td>\n",
       "      <td>-0.992337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>31.607293</td>\n",
       "      <td>-27.772068</td>\n",
       "      <td>-62.467678</td>\n",
       "      <td>102.669693</td>\n",
       "      <td>48.344612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-37.958640</td>\n",
       "      <td>52.650415</td>\n",
       "      <td>-123.872617</td>\n",
       "      <td>60.581991</td>\n",
       "      <td>9.349424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-126.665060</td>\n",
       "      <td>164.287743</td>\n",
       "      <td>121.523825</td>\n",
       "      <td>-56.859725</td>\n",
       "      <td>-22.891056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-158.702524</td>\n",
       "      <td>162.448526</td>\n",
       "      <td>-111.842633</td>\n",
       "      <td>-58.657279</td>\n",
       "      <td>-9.942463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>-23.967349</td>\n",
       "      <td>54.487986</td>\n",
       "      <td>-83.204630</td>\n",
       "      <td>59.197239</td>\n",
       "      <td>-10.917843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>34.429094</td>\n",
       "      <td>-44.974716</td>\n",
       "      <td>-155.120712</td>\n",
       "      <td>95.055992</td>\n",
       "      <td>26.651649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>-152.353897</td>\n",
       "      <td>48.402649</td>\n",
       "      <td>-51.145431</td>\n",
       "      <td>54.438688</td>\n",
       "      <td>10.384346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>-132.694183</td>\n",
       "      <td>85.769111</td>\n",
       "      <td>18.353645</td>\n",
       "      <td>-76.000665</td>\n",
       "      <td>-0.026214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>-29.160409</td>\n",
       "      <td>51.746844</td>\n",
       "      <td>-81.101535</td>\n",
       "      <td>59.950307</td>\n",
       "      <td>21.446315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3          4\n",
       "0     291.717833    2.383732   65.360077   -3.845300 -29.559302\n",
       "1     292.000613   -1.890723   77.571212   -9.632689 -33.687925\n",
       "2      79.989142  173.926739   54.157869   59.619453  57.511260\n",
       "3      79.989142  173.926739   54.157869   59.619453  57.511260\n",
       "4     -89.622581   33.410107  -15.902141  -81.124320  14.768581\n",
       "5      10.904089  111.754315   23.207672   24.838846  74.919105\n",
       "6     136.672462  140.180891   47.576703   67.979597  64.232857\n",
       "7     136.755885  140.406004   47.507332   67.803390  63.683834\n",
       "8      11.193743  112.535925   22.966812   24.227042  73.012854\n",
       "9     250.122524   72.914308   34.345000   84.523679  77.127028\n",
       "10    -89.828811   32.853609  -15.730652  -80.688723  16.125810\n",
       "11    -89.539158   33.635219  -15.971512  -81.300527  14.219559\n",
       "12    193.355781  106.435043   40.995536   76.339741  70.954454\n",
       "13    -79.789222  165.747672   33.737538   11.462615  64.164551\n",
       "14     56.540399   85.539246   17.701879   30.915158  78.390132\n",
       "15    146.944056   30.764279    7.412873   44.903193  91.050938\n",
       "16   -159.978025   77.820031   58.272930 -110.839424 -14.738176\n",
       "17    101.803631   58.317455   12.506316   37.779480  84.316431\n",
       "18    136.466232  139.624394   47.748192   68.415194  65.590086\n",
       "19    250.039101   72.689195   34.414370   84.699886  77.676050\n",
       "20    193.355781  106.435043   40.995536   76.339741  70.954454\n",
       "21   -159.688371   78.601641   58.032070 -111.451227 -16.644427\n",
       "22   -159.571576   78.916806   57.934949 -111.697922 -17.413077\n",
       "23   -159.771795   78.376528   58.101441 -111.275021 -16.095405\n",
       "24    147.150286   31.320777    7.241383   44.467595  89.693709\n",
       "25    147.150286   31.320777    7.241383   44.467595  89.693709\n",
       "26    136.672462  140.180891   47.576703   67.979597  64.232857\n",
       "27    101.803631   58.317455   12.506316   37.779480  84.316431\n",
       "28    193.439205  106.660156   40.926166   76.163535  70.405431\n",
       "29    250.220633   73.179047   34.263418   84.316456  76.481362\n",
       "30     56.456975   85.314134   17.771249   31.091364  78.939154\n",
       "31     11.110319  112.310812   23.036182   24.403249  73.561877\n",
       "32    -89.622581   33.410107  -15.902141  -81.124320  14.768581\n",
       "33    250.039101   72.689195   34.414370   84.699886  77.676050\n",
       "34    -79.582992  166.304169   33.566049   11.027018  62.807322\n",
       "35    -33.377497  241.418435   67.320202   42.899164  44.068067\n",
       "36    -33.294073  241.643548   67.250831   42.722957  43.519044\n",
       "37     79.782912  173.370242   54.329359   60.055050  58.868489\n",
       "38    249.832871   72.132698   34.585860   85.135483  79.033279\n",
       "39    -33.377497  241.418435   67.320202   42.899164  44.068067\n",
       "40    101.597401   57.760958   12.677806   38.215077  85.673660\n",
       "41    193.355781  106.435043   40.995536   76.339741  70.954454\n",
       "42    -33.377497  241.418435   67.320202   42.899164  44.068067\n",
       "43    147.150286   31.320777    7.241383   44.467595  89.693709\n",
       "44    193.149551  105.878546   41.167026   76.775339  72.311682\n",
       "45    193.537313  106.924895   40.844584   75.956311  69.759765\n",
       "46     90.312363  -69.849101   28.922397  -74.842886  12.218552\n",
       "47    136.672462  140.180891   47.576703   67.979597  64.232857\n",
       "48    -33.195965  241.908287   67.169249   42.515733  42.873378\n",
       "49    136.853994  140.670743   47.425751   67.596167  63.038169\n",
       "50     79.989142  173.926739   54.157869   59.619453  57.511260\n",
       "51    -79.582992  166.304169   33.566049   11.027018  62.807322\n",
       "52    -33.583727  240.861938   67.491691   43.334761  45.425295\n",
       "53     56.250745   84.757636   17.942739   31.526961  80.296383\n",
       "54   -159.590263   78.866380   57.950489 -111.658451 -17.290093\n",
       "55    -89.441049   33.899958  -16.053093  -81.507751  13.573893\n",
       "56    250.039101   72.689195   34.414370   84.699886  77.676050\n",
       "57    -89.422362   33.950385  -16.068633  -81.547222  13.450909\n",
       "58     56.456975   85.314134   17.771249   31.091364  78.939154\n",
       "59     80.072566  174.151852   54.088498   59.443246  56.962238\n",
       "60     56.456975   85.314134   17.771249   31.091364  78.939154\n",
       "61     11.110319  112.310812   23.036182   24.403249  73.561877\n",
       "62     43.815268  -71.046434  -51.069868  -68.721741  34.526795\n",
       "63    -79.582992  166.304169   33.566049   11.027018  62.807322\n",
       "64     11.110319  112.310812   23.036182   24.403249  73.561877\n",
       "65    101.803631   58.317455   12.506316   37.779480  84.316431\n",
       "66   -159.771795   78.376528   58.101441 -111.275021 -16.095405\n",
       "67     80.170674  174.416591   54.006917   59.236022  56.316572\n",
       "68    -79.499568  166.529282   33.496678   10.850811  62.258299\n",
       "69    215.458549  -83.166143   70.011302 -101.498763 -74.468317\n",
       "70     66.619812  133.633617  -49.947654  -36.166913 -53.781544\n",
       "71     25.688999  220.296465  137.389439  -18.008902 -57.992566\n",
       "72    105.724568   31.351561 -189.541646  -63.105899 -55.646765\n",
       "73    126.131350   46.446079  -74.808866  -50.896810 -56.260965\n",
       "74     90.311301   74.658703 -117.271006    1.893465  13.214791\n",
       "75    171.331395   95.738693 -138.512940   -8.217333 -36.095912\n",
       "76    153.070058   66.524259 -170.353704  -39.499812 -49.195327\n",
       "77     66.897064    4.326012 -204.928020  -81.882027 -46.736771\n",
       "78    231.047177  -48.117634 -207.939132  -48.692109 -46.919594\n",
       "79    -19.462926  110.129019 -171.036587  -78.189171 -67.555099\n",
       "80     97.847379   10.044304  -88.984010  -79.120726 -60.203595\n",
       "81     56.896982  127.512083  -32.559205  -42.940853 -57.062281\n",
       "82     16.293824  244.512400   23.724098   -6.911576 -53.134675\n",
       "83    120.701350  115.345407  203.758213  -29.015230 -59.247547\n",
       "84    -25.264567   90.994917    1.219024  -94.300767 -75.363876\n",
       "85    139.191963  164.003997  -66.246772    8.408296 -38.274835\n",
       "86     81.316286  127.617853  -37.291546  -43.520931 -76.452797\n",
       "87     34.705084  126.822256  -28.463857  -42.494260 -43.517991\n",
       "88     66.601124  133.583191  -49.932115  -36.127442 -53.658560\n",
       "89     25.670312  220.246038  137.404979  -17.969430 -57.869582\n",
       "90    105.705881   31.301134 -189.526107  -63.066428 -55.523781\n",
       "91    126.112662   46.395653  -74.793327  -50.857339 -56.137981\n",
       "92     90.292614   74.608276 -117.255467    1.932937  13.337775\n",
       "93    171.312707   95.688267 -138.497401   -8.177862 -35.972928\n",
       "94    153.051371   66.473833 -170.338165  -39.460341 -49.072343\n",
       "95     66.878376    4.275586 -204.912481  -81.842556 -46.613787\n",
       "96    231.028490  -48.168061 -207.923592  -48.652638 -46.796610\n",
       "97    -19.481613  110.078592 -171.021047  -78.149700 -67.432115\n",
       "98     97.828692    9.993878  -88.968470  -79.081255 -60.080611\n",
       "99     56.878295  127.461657  -32.543666  -42.901382 -56.939297\n",
       "100    16.275137  244.461974   23.739638   -6.872105 -53.011691\n",
       "101   120.682663  115.294981  203.773753  -28.975759 -59.124563\n",
       "102   -25.283254   90.944490    1.234563  -94.261296 -75.240892\n",
       "103   139.173276  163.953570  -66.231232    8.447768 -38.151851\n",
       "104    81.297599  127.567426  -37.276007  -43.481460 -76.329813\n",
       "105    56.878295  127.461657  -32.543666  -42.901382 -56.939297\n",
       "106    34.686397  126.771829  -28.448318  -42.454788 -43.395007\n",
       "107    66.503016  133.318452  -49.850533  -35.920218 -53.012894\n",
       "108    25.572203  219.981299  137.486560  -17.762207 -57.223916\n",
       "109   105.607772   31.036395 -189.444525  -62.859204 -54.878115\n",
       "110   126.014554   46.130914  -74.711745  -50.650115 -55.492315\n",
       "111    90.194506   74.343537 -117.173885    2.140160  13.983440\n",
       "112   171.214599   95.423528 -138.415819   -7.970638 -35.327262\n",
       "113   152.953263   66.209094 -170.256583  -39.253117 -48.426677\n",
       "114    66.780268    4.010847 -204.830899  -81.635332 -45.968121\n",
       "115   230.930381  -48.432799 -207.842011  -48.445414 -46.150944\n",
       "116   -19.579722  109.813854 -170.939466  -77.942476 -66.786449\n",
       "117    97.730583    9.729139  -88.886889  -78.874031 -59.434945\n",
       "118    56.780186  127.196918  -32.462084  -42.694158 -56.293632\n",
       "119    16.177028  244.197235   23.821219   -6.664881 -52.366025\n",
       "120   120.584554  115.030242  203.855334  -28.768535 -58.478897\n",
       "121   -25.381362   90.679751    1.316145  -94.054072 -74.595226\n",
       "122   139.075167  163.688831  -66.149651    8.654991 -37.506185\n",
       "123    81.199490  127.302687  -37.194425  -43.274236 -75.684147\n",
       "124    34.588288  126.507090  -28.366736  -42.247564 -42.749341\n",
       "125    66.372204  132.965467  -49.741758  -35.643920 -52.152006\n",
       "126    25.441392  219.628314  137.595336  -17.485908 -56.363028\n",
       "127   105.476961   30.683410 -189.335749  -62.582905 -54.017227\n",
       "128   125.883742   45.777928  -74.602970  -50.373817 -54.631427\n",
       "129    90.063694   73.990552 -117.065109    2.416459  14.844328\n",
       "130   171.083788   95.070543 -138.307043   -7.694340 -34.466375\n",
       "131   152.822451   65.856109 -170.147808  -38.976819 -47.565790\n",
       "132    66.649457    3.657861 -204.722124  -81.359033 -45.107234\n",
       "133   230.799570  -48.785785 -207.733235  -48.169116 -45.290057\n",
       "134   -19.710533  109.460868 -170.830690  -77.666178 -65.925562\n",
       "135    97.599772    9.376153  -88.778113  -78.597732 -58.574057\n",
       "136    56.649375  126.843933  -32.353309  -42.417860 -55.432744\n",
       "137    16.046217  243.844250   23.929995   -6.388583 -51.505138\n",
       "138   120.453743  114.677256  203.964110  -28.492237 -57.618010\n",
       "139   -25.512174   90.326766    1.424920  -93.777773 -73.734339\n",
       "140   138.944356  163.335846  -66.040875    8.931290 -36.645297\n",
       "141    81.068679  126.949702  -37.085650  -42.997938 -74.823260\n",
       "142    34.457477  126.154105  -28.257961  -41.971266 -41.888453\n",
       "143    66.208690  132.524235  -49.605788  -35.298547 -51.075897\n",
       "144    25.277878  219.187083  137.731305  -17.140535 -55.286919\n",
       "145   105.313447   30.242178 -189.199780  -62.237532 -52.941118\n",
       "146   125.720228   45.336697  -74.467000  -50.028444 -53.555318\n",
       "147    89.900180   73.549320 -116.929140    2.761832  15.920437\n",
       "148   170.920273   94.629311 -138.171074   -7.348967 -33.390265\n",
       "149   152.658937   65.414877 -170.011838  -38.631446 -46.489680\n",
       "150    66.485942    3.216630 -204.586154  -81.013660 -44.031124\n",
       "151   230.636056  -49.227016 -207.597266  -47.823743 -44.213947\n",
       "152   -19.874047  109.019637 -170.694721  -77.320805 -64.849452\n",
       "153    97.436258    8.934922  -88.642144  -78.252359 -57.497948\n",
       "154    56.485861  126.402701  -32.217339  -42.072487 -54.356635\n",
       "155   120.290229  114.236025  204.100079  -28.146864 -56.541900\n",
       "156   -25.675688   89.885534    1.560890  -93.432400 -72.658229\n",
       "157   138.780842  162.894615  -65.904906    9.276663 -35.569188\n",
       "158    80.905165  126.508471  -36.949680  -42.652564 -73.747150\n",
       "159    34.293963  125.712873  -28.121991  -41.625893 -40.812344\n",
       "160   -61.384644 -114.506709  -49.828923   -6.974338  10.887453\n",
       "161   -61.436034 -114.645382  -49.786190   -6.865792  11.225658\n",
       "162   -61.501440 -114.821875  -49.731802   -6.727643  11.656102\n",
       "163   -61.632251 -115.174860  -49.623027   -6.451345  12.516990\n",
       "164   -61.837812 -115.729551  -49.452094   -6.017161  13.869813\n",
       "165   -46.792321  -98.272890  -57.784843    9.244535  22.520065\n",
       "166   -46.843711  -98.411563  -57.742110    9.353081  22.858271\n",
       "167   -46.909117  -98.588055  -57.687722    9.491230  23.288715\n",
       "168   -47.039928  -98.941040  -57.578946    9.767529  24.149603\n",
       "169   -47.245489  -99.495731  -57.408014   10.201712  25.502426\n",
       "170   -94.725208 -147.110499  -33.485191  -39.108344 -13.394956\n",
       "171   -94.776598 -147.249171  -33.442458  -38.999798 -13.056751\n",
       "172   -94.842004 -147.425664  -33.388070  -38.861649 -12.626307\n",
       "173   -94.972815 -147.778649  -33.279294  -38.585351 -11.765419\n",
       "174   -95.178376 -148.333340  -33.108361  -38.151167 -10.412596\n",
       "175   -79.301391 -131.263863   92.345676    1.129861 -20.206079\n",
       "176   -79.352781 -131.402536   92.388410    1.238407 -19.867873\n",
       "177   -79.418186 -131.579029   92.442797    1.376556 -19.437430\n",
       "178   -79.548998 -131.932014   92.551573    1.652854 -18.576542\n",
       "179   -79.754558 -132.486705   92.722506    2.087038 -17.223719\n",
       "180   -54.032101 -106.574416   76.494615   24.655566  -1.358398\n",
       "181   -54.083491 -106.713089   76.537348   24.764112  -1.020192\n",
       "182   -54.148897 -106.889581   76.591736   24.902261  -0.589748\n",
       "183   -54.279708 -107.242566   76.700511   25.178560   0.271139\n",
       "184   -54.485269 -107.797257   76.871444   25.612743   1.623963\n",
       "185   -32.862165  -85.533347   62.371227   44.709343  14.722223\n",
       "186   -32.913555  -85.672020   62.413960   44.817888  15.060429\n",
       "187   -32.978961  -85.848513   62.468348   44.956038  15.490873\n",
       "188   -33.109772  -86.201498   62.577123   45.232336  16.351760\n",
       "189   -33.315333  -86.756189   62.748056   45.666519  17.704584\n",
       "190   -79.287854 -130.041250   91.608480    2.512332 -19.379062\n",
       "191   -79.339245 -130.179922   91.651213    2.620878 -19.040856\n",
       "192   -79.404650 -130.356415   91.705601    2.759027 -18.610412\n",
       "193   -79.535462 -130.709400   91.814377    3.035326 -17.749524\n",
       "194   -79.741022 -131.264091   91.985309    3.469509 -16.396701\n",
       "195  -104.980807 -123.117439   84.851219   54.193666  -8.141046\n",
       "196  -105.032197 -123.256111   84.893953   54.302212  -7.802840\n",
       "197  -105.097603 -123.432604   84.948340   54.440361  -7.372396\n",
       "198  -105.228414 -123.785589   85.057116   54.716660  -6.511508\n",
       "199  -105.433975 -124.340280   85.228049   55.150843  -5.158685\n",
       "200  -115.643019  -90.383851   83.784081   47.213587 -27.450676\n",
       "201  -115.694409  -90.522523   83.826814   47.322133 -27.112470\n",
       "202  -115.759815  -90.699016   83.881202   47.460282 -26.682026\n",
       "203  -115.890626  -91.052001   83.989978   47.736581 -25.821139\n",
       "204  -116.096187  -91.606692   84.160911   48.170764 -24.468315\n",
       "205   -60.648751   -6.060534   75.924565  -70.052295  -5.246060\n",
       "206   -60.700141   -6.199207   75.967298  -69.943749  -4.907854\n",
       "207   -60.765547   -6.375699   76.021686  -69.805600  -4.477410\n",
       "208   -60.896358   -6.728685   76.130461  -69.529302  -3.616523\n",
       "209   -61.101919   -7.283376   76.301394  -69.095118  -2.263699\n",
       "210   -60.644284   -6.172869   76.006178  -70.203829  -5.331634\n",
       "211   -60.695674   -6.311542   76.048912  -70.095283  -4.993428\n",
       "212   -60.761080   -6.488034   76.103299  -69.957134  -4.562984\n",
       "213   -60.891891   -6.841019   76.212075  -69.680835  -3.702096\n",
       "214   -61.097452   -7.395711   76.383008  -69.246652  -2.349273\n",
       "215   -32.908041  -84.709356   61.868282   45.649633  15.280375\n",
       "216   -32.959431  -84.848029   61.911015   45.758179  15.618581\n",
       "217   -33.024837  -85.024521   61.965403   45.896328  16.049025\n",
       "218   -33.155648  -85.377507   62.074178   46.172626  16.909913\n",
       "219   -33.361209  -85.932198   62.245111   46.606810  18.262736\n",
       "220   -41.747870  -97.154170  -53.428604   10.152295  16.510239\n",
       "221   -41.799260  -97.292843  -53.385871   10.260841  16.848444\n",
       "222   -41.864666  -97.469335  -53.331483   10.398990  17.278888\n",
       "223   -41.995477  -97.822320  -53.222708   10.675289  18.139776\n",
       "224   -42.201038  -98.377012  -53.051775   11.109472  19.492599\n",
       "225   -34.374772 -105.494636  -57.519781    0.984433   6.056737\n",
       "226   -34.426162 -105.633309  -57.477047    1.092978   6.394943\n",
       "227   -34.491568 -105.809801  -57.422660    1.231128   6.825387\n",
       "228   -34.622379 -106.162787  -57.313884    1.507426   7.686275\n",
       "229   -34.827940 -106.717478  -57.142951    1.941609   9.039098\n",
       "230   -78.105667 -145.806971  -34.003392  -38.816216 -22.379766\n",
       "231   -78.157058 -145.945644  -33.960659  -38.707670 -22.041560\n",
       "232   -78.222463 -146.122136  -33.906271  -38.569521 -21.611116\n",
       "233   -78.353275 -146.475122  -33.797496  -38.293223 -20.750229\n",
       "234   -78.558835 -147.029813  -33.626563  -37.859039 -19.397405\n",
       "235   -78.194539 -144.770660  -37.401688  -37.316958 -21.502513\n",
       "236   -78.245929 -144.909333  -37.358954  -37.208412 -21.164307\n",
       "237   -78.311335 -145.085825  -37.304567  -37.070263 -20.733864\n",
       "238   -78.442146 -145.438810  -37.195791  -36.793964 -19.872976\n",
       "239   -78.647707 -145.993502  -37.024858  -36.359781 -18.520152\n",
       "240   -59.030383 -126.632822   87.636486    4.627766 -26.352869\n",
       "241   -59.081773 -126.771495   87.679219    4.736312 -26.014663\n",
       "242   -59.147179 -126.947987   87.733607    4.874461 -25.584219\n",
       "243   -59.277990 -127.300973   87.842382    5.150760 -24.723331\n",
       "244   -59.483551 -127.855664   88.013315    5.584943 -23.370508\n",
       "245   -36.159821 -105.145758   72.767560   25.274196 -10.765681\n",
       "246   -36.211211 -105.284431   72.810293   25.382742 -10.427475\n",
       "247   -36.276617 -105.460924   72.864681   25.520891  -9.997031\n",
       "248   -36.407428 -105.813909   72.973456   25.797189  -9.136144\n",
       "249   -36.612989 -106.368600   73.144389   26.231372  -7.783320\n",
       "250   -13.433588  -84.103659   58.516702   45.184684   4.351306\n",
       "251   -13.484978  -84.242331   58.559435   45.293230   4.689512\n",
       "252   -13.550384  -84.418824   58.613823   45.431379   5.119956\n",
       "253   -13.681195  -84.771809   58.722598   45.707678   5.980844\n",
       "254   -13.886756  -85.326500   58.893531   46.141861   7.333667\n",
       "255   -13.436893  -84.106811   58.508322   45.201809   4.295932\n",
       "256   -13.488283  -84.245484   58.551055   45.310355   4.634138\n",
       "257   -13.553688  -84.421976   58.605443   45.448504   5.064581\n",
       "258   -13.684500  -84.774962   58.714218   45.724802   5.925469\n",
       "259   -13.890060  -85.329653   58.885151   46.158986   7.278292\n",
       "260   -91.631373 -121.976582   81.175858   59.045731 -17.401602\n",
       "261   -91.682763 -122.115254   81.218591   59.154277 -17.063397\n",
       "262   -91.748169 -122.291747   81.272979   59.292426 -16.632953\n",
       "263   -91.878980 -122.644732   81.381754   59.568725 -15.772065\n",
       "264   -92.084541 -123.199423   81.552687   60.002908 -14.419242\n",
       "265   -94.727417  -75.589257   80.907875   15.149793 -19.067814\n",
       "266   -94.778807  -75.727930   80.950608   15.258339 -18.729608\n",
       "267   -94.844212  -75.904423   81.004996   15.396488 -18.299164\n",
       "268   -94.975024  -76.257408   81.113771   15.672786 -17.438276\n",
       "269   -95.180584  -76.812099   81.284704   16.106970 -16.085453\n",
       "270  -109.448945  -93.692364   91.716906    0.461408 -30.102445\n",
       "271  -109.500335  -93.831036   91.759640    0.569954 -29.764239\n",
       "272  -109.565741  -94.007529   91.814027    0.708103 -29.333795\n",
       "273  -109.696552  -94.360514   91.922803    0.984401 -28.472907\n",
       "274  -109.902113  -94.915205   92.093736    1.418585 -27.120084\n",
       "275     0.957657 -107.783720  -62.861744   -3.210510 -20.020074\n",
       "276     0.906267 -107.922393  -62.819011   -3.101964 -19.681868\n",
       "277     0.840861 -108.098885  -62.764623   -2.963815 -19.251424\n",
       "278     0.710050 -108.451871  -62.655847   -2.687517 -18.390536\n",
       "279     0.504489 -109.006562  -62.484914   -2.253333 -17.037713\n",
       "280   -13.543625 -118.150417  -56.396737  -13.083092 -26.118435\n",
       "281   -13.595016 -118.289090  -56.354004  -12.974546 -25.780229\n",
       "282   -13.660421 -118.465583  -56.299616  -12.836397 -25.349785\n",
       "283   -13.791233 -118.818568  -56.190841  -12.560098 -24.488898\n",
       "284   -13.996793 -119.373259  -56.019908  -12.125915 -23.136074\n",
       "285     7.141966 -102.581239  -65.363224    1.927945 -16.686756\n",
       "286     7.090576 -102.719912  -65.320490    2.036491 -16.348551\n",
       "287     7.025170 -102.896405  -65.266103    2.174640 -15.918107\n",
       "288     6.894359 -103.249390  -65.157327    2.450938 -15.057219\n",
       "289     6.688798 -103.804081  -64.986394    2.885122 -13.704396\n",
       "290   -41.857179 -142.055667  -39.827324  -36.979497 -40.894612\n",
       "291   -41.908569 -142.194340  -39.784591  -36.870951 -40.556406\n",
       "292   -41.973975 -142.370833  -39.730203  -36.732802 -40.125962\n",
       "293   -42.104786 -142.723818  -39.621428  -36.456503 -39.265075\n",
       "294   -42.310347 -143.278509  -39.450495  -36.022320 -37.912251\n",
       "295   -41.856439 -130.679683  -48.135589  -24.556947 -25.779641\n",
       "296   -41.907829 -130.818356  -48.092856  -24.448401 -25.441435\n",
       "297   -41.973235 -130.994848  -48.038468  -24.310252 -25.010991\n",
       "298   -42.104046 -131.347834  -47.929693  -24.033954 -24.150104\n",
       "299   -42.309607 -131.902525  -47.758760  -23.599771 -22.797280\n",
       "300   -39.063587 -131.411977  -48.806807  -25.004976 -32.524276\n",
       "301   -39.114977 -131.550649  -48.764074  -24.896430 -32.186070\n",
       "302   -39.180383 -131.727142  -48.709686  -24.758281 -31.755626\n",
       "303   -39.311194 -132.080127  -48.600910  -24.481982 -30.894739\n",
       "304   -39.516755 -132.634818  -48.429978  -24.047799 -29.541915\n",
       "305   -28.102231 -126.915631   82.218136    2.924417 -47.219297\n",
       "306   -28.153621 -127.054303   82.260869    3.032962 -46.881091\n",
       "307   -28.219027 -127.230796   82.315257    3.171112 -46.450647\n",
       "308   -28.349838 -127.583781   82.424032    3.447410 -45.589760\n",
       "309   -28.555399 -128.138472   82.594965    3.881593 -44.236936\n",
       "310     3.010960 -102.369356   63.873687   25.990411 -31.884359\n",
       "311     2.959570 -102.508029   63.916420   26.098957 -31.546153\n",
       "312     2.894164 -102.684522   63.970808   26.237107 -31.115709\n",
       "313     2.763353 -103.037507   64.079583   26.513405 -30.254821\n",
       "314     2.557792 -103.592198   64.250516   26.947588 -28.901998\n",
       "315    28.771611  -78.614653   48.798923   48.466443 -15.365526\n",
       "316    28.720220  -78.753326   48.841656   48.574988 -15.027320\n",
       "317    28.654815  -78.929819   48.896044   48.713138 -14.596876\n",
       "318    28.524003  -79.282804   49.004819   48.989436 -13.735989\n",
       "319    28.318443  -79.837495   49.175752   49.423619 -12.383165\n",
       "320   -64.005447 -122.310835   75.011768   65.602099 -38.801037\n",
       "321   -64.056837 -122.449507   75.054501   65.710645 -38.462832\n",
       "322   -64.122243 -122.626000   75.108889   65.848795 -38.032388\n",
       "323   -64.253054 -122.978985   75.217665   66.125093 -37.171500\n",
       "324   -64.458615 -123.533676   75.388598   66.559276 -35.818677\n",
       "325   -63.946154 -121.441914   74.527321   66.203032 -38.110515\n",
       "326   -63.997544 -121.580587   74.570055   66.311578 -37.772309\n",
       "327   -64.062950 -121.757080   74.624442   66.449727 -37.341865\n",
       "328   -64.193761 -122.110065   74.733218   66.726025 -36.480978\n",
       "329   -64.399322 -122.664756   74.904151   67.160209 -35.128154\n",
       "330    -2.919078   -1.541825   63.764758  -67.894718 -35.689412\n",
       "331    -2.970468   -1.680498   63.807491  -67.786173 -35.351206\n",
       "332    -3.035874   -1.856990   63.861879  -67.648023 -34.920762\n",
       "333    -3.166685   -2.209975   63.970655  -67.371725 -34.059875\n",
       "334    -3.372246   -2.764666   64.141588  -66.937542 -32.707051\n",
       "335   -67.894210  -79.314425   81.121858    0.822571 -59.286132\n",
       "336   -67.945600  -79.453098   81.164591    0.931117 -58.947926\n",
       "337   -68.011005  -79.629591   81.218979    1.069266 -58.517482\n",
       "338   -68.141817  -79.982576   81.327754    1.345564 -57.656594\n",
       "339   -68.347377  -80.537267   81.498687    1.779748 -56.303771\n",
       "340   -68.524311  -55.238321   38.603594   30.296193 -29.327118\n",
       "341   -68.575701  -55.376994   38.646328   30.404739 -28.988912\n",
       "342   -68.641106  -55.553487   38.700715   30.542888 -28.558468\n",
       "343   -68.771918  -55.906472   38.809491   30.819186 -27.697581\n",
       "344   -68.977478  -56.461163   38.980424   31.253370 -26.344757\n",
       "345   -51.808430 -121.996993   83.602873    9.265195 -25.848567\n",
       "346   -51.859820 -122.135666   83.645607    9.373740 -25.510361\n",
       "347   -51.925226 -122.312158   83.699994    9.511890 -25.079917\n",
       "348   -52.056037 -122.665143   83.808770    9.788188 -24.219029\n",
       "349   -52.261598 -123.219835   83.979703   10.222371 -22.866206\n",
       "350   124.102491  -33.173327   14.283977  -33.454705  37.729705\n",
       "351   124.051101  -33.312000   14.326710  -33.346159  38.067911\n",
       "352   123.985695  -33.488492   14.381098  -33.208010  38.498355\n",
       "353   123.854884  -33.841477   14.489873  -32.931712  39.359243\n",
       "354   123.649323  -34.396169   14.660806  -32.497528  40.712066\n",
       "355   214.036481  -63.767710  -87.421912  -70.617403 -55.549363\n",
       "356   228.768370  -21.343547  143.170256   34.918472 -51.384950\n",
       "357    34.781032   35.072810  132.971363  -99.782277 -70.363161\n",
       "358   257.253696    8.788452   89.810837   69.695177 -15.967173\n",
       "359   195.612072  -32.302990   32.901685  -36.132330 -14.344885\n",
       "360   237.044391    9.840916 -195.676891   21.247391   8.456216\n",
       "361   229.770886  -29.570621 -181.762030  -27.716391 -18.869109\n",
       "362   268.844013   16.949526  -54.726919   20.016148   5.468404\n",
       "363   241.397101   -9.971648 -141.623186   -6.563465  -6.510996\n",
       "364    98.046473  -53.438910  -70.839038   99.839590 -34.764378\n",
       "365   271.811922    8.386094  175.888747   -1.118459  -3.364481\n",
       "366   212.145270   43.908039  182.816290   -9.918611 -10.439846\n",
       "367   130.753057   -0.402251   54.660270  160.591561 -33.791214\n",
       "368    68.078225  -22.707579   78.022206  143.023229 -26.934099\n",
       "369    74.006304   -2.123908   65.058315  161.514527  -1.050926\n",
       "370   167.253716  -36.375349  141.666136  -43.837601  -3.027926\n",
       "371   -67.419410  115.890212  210.211641  -69.345073 -19.585577\n",
       "372   237.044060    9.840601 -195.677729   21.249103   8.450678\n",
       "373  -174.811614   -3.755620 -154.115532   35.323929   2.003436\n",
       "374  -165.404946    8.330354 -163.525298   39.225881  -8.965242\n",
       "375   -49.672905   83.686281   16.374014  -51.636546   5.961591\n",
       "376   -74.991947   87.140485 -106.415566   37.328128 -51.395820\n",
       "377   236.277190    3.905226   86.713855    2.581738  -4.373073\n",
       "378     4.117931  131.876397   89.673972  -38.158224 -33.563932\n",
       "379    95.707816   85.799668  119.810755  -22.340783 -25.355507\n",
       "380   -50.645372  106.128939 -114.914197   85.859236 -53.268087\n",
       "381   260.121068   10.972106   77.541999   10.007540 -13.233683\n",
       "382  -129.964695 -159.683911  -25.850796   -4.943051 -22.993472\n",
       "383  -129.881950   16.051939   57.416669   46.658218 -32.675687\n",
       "384  -115.447659   21.878833   56.325195   35.918578 -28.956482\n",
       "385  -127.379248   18.234894   57.372656   43.676632 -32.381280\n",
       "386  -123.691133 -137.534111   -1.638692   36.907759 -37.971516\n",
       "387  -119.243278  -79.578561   32.456123   65.239590 -35.644971\n",
       "388  -125.771436  -47.816445   46.768859   68.043695 -36.750629\n",
       "389  -117.908766  -19.678769   58.275271   72.594074 -34.127285\n",
       "390   -78.586855 -125.346855   86.312876    8.186720 -13.627226\n",
       "391   -33.590624 -101.018799  -61.732459    6.349455  11.435417\n",
       "392   -63.263771 -116.925542   69.494162   71.657876 -32.573945\n",
       "393   -93.920020 -142.439215  -37.984874  -33.493138  -7.816662\n",
       "394   -12.335439  -86.476881   72.855055   41.333678   3.216215\n",
       "395  -130.016085 -159.822584  -25.808063   -4.834506 -22.655267\n",
       "396  -129.933340   15.913266   57.459402   46.766764 -32.337482\n",
       "397  -115.499049   21.740160   56.367928   36.027124 -28.618276\n",
       "398  -127.430638   18.096221   57.415389   43.785178 -32.043075\n",
       "399  -123.742523 -137.672783   -1.595959   37.016304 -37.633310\n",
       "400  -119.294669  -79.717234   32.498856   65.348136 -35.306765\n",
       "401  -125.822826  -47.955117   46.811592   68.152241 -36.412423\n",
       "402  -117.960156  -19.817442   58.318005   72.702620 -33.789079\n",
       "403   -78.638245 -125.485528   86.355609    8.295265 -13.289020\n",
       "404   -33.642014 -101.157472  -61.689726    6.458001  11.773623\n",
       "405   -63.315161 -117.064215   69.536895   71.766422 -32.235739\n",
       "406   -93.971410 -142.577888  -37.942140  -33.384592  -7.478456\n",
       "407   -12.386829  -86.615554   72.897788   41.442224   3.554421\n",
       "408  -130.081491 -159.999076  -25.753675   -4.696356 -22.224823\n",
       "409  -129.998746   15.736774   57.513790   46.904913 -31.907038\n",
       "410  -115.564455   21.563667   56.422316   36.165273 -28.187832\n",
       "411  -127.496044   17.919728   57.469777   43.923328 -31.612631\n",
       "412  -123.807928 -137.849276   -1.541571   37.154454 -37.202867\n",
       "413  -119.360074  -79.893726   32.553244   65.486285 -34.876321\n",
       "414  -125.888231  -48.131610   46.865980   68.290390 -35.981980\n",
       "415  -118.025562  -19.993934   58.372392   72.840769 -33.358635\n",
       "416   -78.703651 -125.662020   86.409997    8.433415 -12.858576\n",
       "417   -33.707420 -101.333965  -61.635338    6.596150  12.204066\n",
       "418   -63.380567 -117.240708   69.591283   71.904571 -31.805295\n",
       "419   -94.036816 -142.754381  -37.887753  -33.246443  -7.048013\n",
       "420   -12.452235  -86.792047   72.952176   41.580373   3.984864\n",
       "421  -130.212302 -160.352062  -25.644900   -4.420058 -21.363935\n",
       "422  -130.129557   15.383788   57.622565   47.181212 -31.046150\n",
       "423  -115.695266   21.210682   56.531091   36.441572 -27.326945\n",
       "424  -127.626855   17.566743   57.578553   44.199626 -30.751743\n",
       "425  -123.938740 -138.202261   -1.432795   37.430752 -36.341979\n",
       "426  -119.490886  -80.246711   32.662019   65.762583 -34.015434\n",
       "427  -126.019043  -48.484595   46.974755   68.566689 -35.121092\n",
       "428  -118.156373  -20.346920   58.481168   73.117068 -32.497748\n",
       "429   -78.834462 -126.015006   86.518773    8.709713 -11.997689\n",
       "430   -33.838231 -101.686950  -61.526562    6.872449  13.064954\n",
       "431   -63.511378 -117.593693   69.700059   72.180870 -30.944408\n",
       "432   -94.167627 -143.107366  -37.778977  -32.970144  -6.187125\n",
       "433   -12.583046  -87.145032   73.060951   41.856672   4.845752\n",
       "434  -130.417863 -160.906753  -25.473967   -3.985875 -20.011112\n",
       "435  -130.335118   14.829097   57.793498   47.615395 -29.693327\n",
       "436  -115.900827   20.655991   56.702024   36.875755 -25.974121\n",
       "437  -127.832416   17.012052   57.749486   44.633809 -29.398920\n",
       "438  -124.144300 -138.756952   -1.261862   37.864935 -34.989156\n",
       "439  -119.696446  -80.801403   32.832952   66.196767 -32.662610\n",
       "440  -126.224604  -49.039286   47.145688   69.000872 -33.768268\n",
       "441  -118.361934  -20.901611   58.652101   73.551251 -31.144924\n",
       "442   -79.040023 -126.569697   86.689706    9.143896 -10.644865\n",
       "443   -34.043792 -102.241641  -61.355629    7.306632  14.417777\n",
       "444   -63.716939 -118.148384   69.870992   72.615053 -29.591584\n",
       "445   -94.373188 -143.662057  -37.608044  -32.535961  -4.834302\n",
       "446   -12.788607  -87.699723   73.231884   42.290855   6.198575\n",
       "447   172.745944   -5.293999    1.486961   58.923408 -38.752986\n",
       "448   172.745779   -5.294156    1.486542   58.924265 -38.755755\n",
       "449   172.745779   -5.294156    1.486542   58.924265 -38.755755\n",
       "450   172.753160   -5.287116    1.505257   58.886020 -38.632085\n",
       "451   172.862740   -4.978833    1.389840   58.676713 -39.521635\n",
       "452   172.862575   -4.978991    1.389421   58.677570 -39.524404\n",
       "453   172.862575   -4.978991    1.389421   58.677570 -39.524404\n",
       "454   172.844053   -5.029260    1.405379   58.716185 -39.398652\n",
       "455   172.843887   -5.029417    1.404960   58.717041 -39.401420\n",
       "456   172.843887   -5.029417    1.404960   58.717041 -39.401420\n",
       "457   172.615133   -5.646984    1.595736   59.199707 -37.892098\n",
       "458   172.614968   -5.647141    1.595317   59.200563 -37.894867\n",
       "459   172.614968   -5.647141    1.595317   59.200563 -37.894867\n",
       "460   172.622348   -5.640101    1.614033   59.162318 -37.771197\n",
       "461    86.668622  -71.138855  -86.597940   10.758772 -55.728227\n",
       "462    86.670770  -71.136806  -86.592493   10.747641 -55.692234\n",
       "463    86.683548  -71.124617  -86.560090   10.681425 -55.478119\n",
       "464    86.785417  -70.823689  -86.695061   10.512077 -56.496877\n",
       "465    86.787566  -70.821640  -86.689614   10.500946 -56.460883\n",
       "466    86.800344  -70.809451  -86.657211   10.434730 -56.246768\n",
       "467    86.766730  -70.874116  -86.679522   10.551548 -56.373893\n",
       "468    86.768878  -70.872067  -86.674075   10.540417 -56.337899\n",
       "469    86.781657  -70.859878  -86.641671   10.474202 -56.123784\n",
       "470    86.537810  -71.491840  -86.489165   11.035070 -54.867340\n",
       "471    86.539958  -71.489791  -86.483717   11.023939 -54.831346\n",
       "472    86.552737  -71.477602  -86.451314   10.957724 -54.617231\n",
       "473    51.999670  -96.143029  -72.421538  -12.344223 -66.222619\n",
       "474    52.004518  -96.138406  -72.409247  -12.369339 -66.141403\n",
       "475   204.717655   19.422387  -66.345558  131.844468 -27.697239\n",
       "476   203.513965   35.824627 -115.295489  154.634973 -15.344383\n",
       "477   204.834451   19.737553  -66.442679  131.597773 -28.465889\n",
       "478   204.815763   19.687126  -66.427139  131.637244 -28.342905\n",
       "479   204.586843   19.069402  -66.236782  132.120766 -26.836352\n",
       "480   203.630761   36.139793 -115.392610  154.388277 -16.113033\n",
       "481   203.612073   36.089366 -115.377071  154.427749 -15.990049\n",
       "482   203.383154   35.471642 -115.186714  154.911271 -14.483496\n",
       "483   130.485433    0.209172 -133.117752  134.137323 -19.716160\n",
       "484   131.733347  -16.573483  -84.370334  110.741073 -36.999302\n",
       "485   130.402375   -0.566007 -133.241001  133.750936 -24.380809\n",
       "486   130.583541    0.473911 -133.199334  133.930099 -20.361825\n",
       "487   130.354622   -0.143813 -133.008977  134.413621 -18.855272\n",
       "488   130.519171   -0.250842 -133.338122  133.504241 -25.149458\n",
       "489   130.500483   -0.301268 -133.322582  133.543713 -25.026474\n",
       "490   130.271563   -0.918992 -133.132225  134.027235 -23.519921\n",
       "491   -77.608821  -80.239701  -27.565840   70.990023  25.734183\n",
       "492   -77.492025  -79.924535  -27.662961   70.743328  24.965533\n",
       "493   -77.510712  -79.974962  -27.647422   70.782799  25.088517\n",
       "494   -77.739632  -80.592686  -27.457065   71.266321  26.595070\n",
       "495    -6.917301  -45.876768 -122.536873  107.523607   9.478677\n",
       "496    -6.800506  -45.561603 -122.633994  107.276912   8.710027\n",
       "497    -6.819193  -45.612029 -122.618454  107.316383   8.833011\n",
       "498    -7.048113  -46.229754 -122.428097  107.799905  10.339565\n",
       "499    61.235990  -68.778638  -53.574111   67.051092 -58.585067\n",
       "500    61.235990  -68.778638  -53.574111   67.051092 -58.585067\n",
       "501    61.352786  -68.463473  -53.671232   66.804397 -59.353717\n",
       "502    61.352786  -68.463473  -53.671232   66.804397 -59.353717\n",
       "503    61.334098  -68.513899  -53.655693   66.843868 -59.230733\n",
       "504    61.334098  -68.513899  -53.655693   66.843868 -59.230733\n",
       "505    61.105178  -69.131623  -53.465336   67.327391 -57.724180\n",
       "506    61.105178  -69.131623  -53.465336   67.327391 -57.724180\n",
       "507   184.675886   37.440797 -105.797518   53.181435  76.408948\n",
       "508    13.268191  -77.922649 -119.343110  -69.377348  47.857701\n",
       "509    13.674640  -76.825874 -119.681091  -70.235847  45.182800\n",
       "510   132.818013  -26.898240  -52.857495  -22.591060  31.997608\n",
       "511   132.411563  -27.995016  -52.519514  -21.732561  34.672508\n",
       "512   132.701217  -27.213405  -52.760374  -22.344365  32.766257\n",
       "513   227.701799   13.710208  -29.339516   18.229881  24.048953\n",
       "514   227.799907   13.974947  -29.421097   18.022658  23.403288\n",
       "515   227.412145   12.928598  -29.098656   18.841685  25.955204\n",
       "516   227.818594   14.025374  -29.436637   17.983186  23.280304\n",
       "517    65.623834  -54.574663  -82.688141  -49.187515  39.623529\n",
       "518   -29.082714  -96.629186 -160.658670  -86.781325  52.220788\n",
       "519   -28.694951  -95.582837 -160.981112  -87.600353  49.668871\n",
       "520    13.655953  -76.876300 -119.665552  -70.196375  45.305784\n",
       "521   -28.793060  -95.847576 -160.899530  -87.393129  50.314537\n",
       "522    65.507038  -54.889828  -82.591020  -48.940820  40.392179\n",
       "523    65.605147  -54.625089  -82.672602  -49.148044  39.746513\n",
       "524    13.557845  -77.141039 -119.583970  -69.989152  45.951450\n",
       "525    65.217384  -55.671438  -82.350160  -48.329017  42.298430\n",
       "526   132.799326  -26.948667  -52.841956  -22.551589  32.120592\n",
       "527   -28.676264  -95.532410 -160.996651  -87.639824  49.545887\n",
       "528  -134.412447  137.630923   89.448907  -75.890758 -18.893678\n",
       "529     0.817917   75.586989   38.497495   29.359087  81.868581\n",
       "530   -39.661803   81.222074   78.447968  -61.916117  -7.657998\n",
       "531  -119.753879  182.820821   73.290287  -60.447934 -30.097711\n",
       "532  -112.361431  205.656630   65.078652  -52.809806 -36.062181\n",
       "533   -25.405358   99.797367   69.613673  -53.315864 -12.771964\n",
       "534   -11.181797  118.506664   60.614431  -44.656482 -17.880363\n",
       "535     0.719808   75.322250   38.579077   29.566311  82.514247\n",
       "536   -54.069922   62.185079   87.707595  -70.445004  -1.923653\n",
       "537   149.741375  -31.860363   56.527672  -33.759610  15.459027\n",
       "538   135.763147  -36.861207   61.838708  -39.355707  16.536958\n",
       "539  -101.294974  239.980632   52.797265  -41.561476 -45.512456\n",
       "540  -134.510556  137.366184   89.530489  -75.683534 -18.248012\n",
       "541    51.583327  -68.550786   94.472082  -71.844585  26.662458\n",
       "542   -25.503466   99.532628   69.695255  -53.108640 -12.126299\n",
       "543   -69.222836   39.474087   99.534738  -84.704512  -0.854563\n",
       "544   149.839484  -31.595624   56.446090  -33.966834  14.813361\n",
       "545   125.570616  -74.515809   83.253408  -85.125362 -10.819713\n",
       "546    51.485218  -68.815525   94.553663  -71.637361  27.308124\n",
       "547   -90.363630  273.858133   40.660921  -29.917170 -53.756210\n",
       "548   -53.971813   62.449818   87.626014  -70.652228  -2.569319\n",
       "549    24.384220  164.835632   38.275585  -22.803532 -29.951921\n",
       "550  -150.130816   87.641845  108.928487  -96.637518 -10.448758\n",
       "551    -4.575863  -89.461005  114.936465  -92.654005  34.481863\n",
       "552    93.710806  -52.589028   77.821771  -55.446033  21.692140\n",
       "553  -150.228925   87.377106  109.010068  -96.430294  -9.803092\n",
       "554  -112.263322  205.921369   64.997070  -53.017029 -36.707847\n",
       "555   -69.320945   39.209348   99.616319  -84.497288  -0.208897\n",
       "556     3.131983  137.221927   51.599201  -35.997535 -23.024091\n",
       "557  -119.655771  183.085560   73.208705  -60.655158 -30.743376\n",
       "558   -98.061164   83.051620   83.632210  -50.068227  25.297721\n",
       "559  -101.393083  239.715893   52.878846  -41.354252 -44.866790\n",
       "560   -90.265521  274.122872   40.579340  -30.124394 -54.401876\n",
       "561     3.033874  136.957188   51.680782  -35.790312 -22.378425\n",
       "562   125.668724  -74.251070   83.171826  -85.332585 -11.465378\n",
       "563   -39.759912   80.957335   78.529550  -61.708893  -7.012333\n",
       "564   -82.448049   25.108235  105.622366  -87.989028   7.597998\n",
       "565    93.612697  -52.853766   77.903352  -55.238809  22.337806\n",
       "566    -4.477755  -89.196266  114.854884  -92.861229  33.836197\n",
       "567     9.410254  -84.201389  109.559835  -87.264696  32.793595\n",
       "568   135.665039  -37.125945   61.920290  -39.148483  17.182624\n",
       "569     9.508363  -83.936650  109.478253  -87.471920  32.147929\n",
       "570    24.482328  165.100371   38.194003  -23.010755 -30.597587\n",
       "571   -82.546158   24.843497  105.703948  -87.781804   8.243663\n",
       "572   -97.963055   83.316359   83.550628  -50.275451  24.652055\n",
       "573   -11.279906  118.241925   60.696013  -44.449258 -17.234697\n",
       "574    85.696487  -35.380924  -19.296054  -30.267853  47.150128\n",
       "575    85.677800  -35.431351  -19.280515  -30.228382  47.273112\n",
       "576    85.645097  -35.519597  -19.253321  -30.159308  47.488334\n",
       "577    85.579691  -35.696090  -19.198933  -30.021158  47.918778\n",
       "578    85.290037  -36.477700  -18.958073  -29.409355  49.825029\n",
       "579    85.496268  -35.921203  -19.129563  -29.844952  48.467800\n",
       "580    85.496268  -35.921203  -19.129563  -29.844952  48.467800\n",
       "581   -30.763786  -90.611241  -60.831899  -85.559853  52.669110\n",
       "582   -30.815176  -90.749914  -60.789166  -85.451308  53.007316\n",
       "583   -30.880582  -90.926406  -60.734778  -85.313158  53.437760\n",
       "584   -31.170236  -91.708016  -60.493918  -84.701355  55.344011\n",
       "585   -30.972069  -91.228806  -60.677118  -85.176846  53.524378\n",
       "586   -30.972069  -91.228806  -60.677118  -85.176846  53.524378\n",
       "587    12.706243  -74.913047  -51.215064  -70.239885  45.356257\n",
       "588    12.640837  -75.089540  -51.160676  -70.101736  45.786701\n",
       "589    12.757633  -74.774374  -51.257797  -70.348431  45.018051\n",
       "590    12.351183  -75.871150  -50.919816  -69.489932  47.692952\n",
       "591    12.557413  -75.314652  -51.091305  -69.925530  46.335723\n",
       "592    12.557413  -75.314652  -51.091305  -69.925530  46.335723\n",
       "593    -9.518736  -78.893844  -51.400380  -73.712707  54.396253\n",
       "594    -9.925185  -79.990620  -51.062399  -72.854208  57.071154\n",
       "595    -9.718955  -79.434122  -51.233889  -73.289806  55.713925\n",
       "596    -9.718955  -79.434122  -51.233889  -73.289806  55.713925\n",
       "597    49.585992  -52.701570  -31.339279  -46.444470  49.135368\n",
       "598    49.585992  -52.701570  -31.339279  -46.444470  49.135368\n",
       "599    49.786212  -52.161292  -31.505770  -46.867372  47.817696\n",
       "600    49.669416  -52.476457  -31.408649  -46.620677  48.586345\n",
       "601    49.379762  -53.258067  -31.167789  -46.008873  50.492596\n",
       "602   -30.790537  -90.738954  -60.828070  -85.560277  52.329690\n",
       "603   -51.371957 -119.841328   94.880403 -125.104095  27.163983\n",
       "604   -51.470065 -120.106067   94.961985 -124.896871  27.809649\n",
       "605   -26.322612 -109.215971   87.814927 -114.125379  25.498790\n",
       "606   -26.420720 -109.480710   87.896508 -113.918155  26.144455\n",
       "607    74.281124  -65.282420   59.027924  -68.409126  19.493083\n",
       "608    74.183016  -65.547159   59.109506  -68.201902  20.138749\n",
       "609    23.983288  -87.210552   73.427280  -91.247305  22.727138\n",
       "610    23.885179  -87.475291   73.508862  -91.040081  23.372804\n",
       "611    49.239843  -75.830491   66.105111  -79.347947  21.620681\n",
       "612    49.141734  -76.095230   66.186693  -79.140723  22.266346\n",
       "613   124.587024  -43.277001   44.640278  -45.531052  16.721432\n",
       "614   124.488915  -43.541740   44.721860  -45.323828  17.367097\n",
       "615   149.745470  -32.161678   37.399690  -33.424470  16.260640\n",
       "616   149.843579  -31.896940   37.318109  -33.631694  15.614974\n",
       "617    -1.066057  -97.835910   80.492757 -102.226021  24.392332\n",
       "618    -1.164165  -98.100648   80.574339 -102.018797  25.037998\n",
       "619    99.545743  -53.825072   51.717465  -56.469873  18.849029\n",
       "620    99.447634  -54.089811   51.799047  -56.262649  19.494695\n",
       "621   -91.353762  264.340705   76.368501   -1.910249  -8.839539\n",
       "622   -23.508863  125.264498   48.009794  -16.075436  23.663399\n",
       "623  -148.318391  143.217233  -21.602216  -58.909790   3.955417\n",
       "624  -147.034516  130.456218   29.172194  -51.221366  24.040355\n",
       "625  -122.325000  186.886416   58.434879  -30.038711  10.162514\n",
       "626  -167.935221   86.555874   -6.830471  -67.809348  35.572245\n",
       "627   -94.335997   43.864755  -14.791806  -58.211205  41.324849\n",
       "628  -210.630818   15.371860 -140.405631 -111.883526  29.516430\n",
       "629  -211.037268   14.275085 -140.067650 -111.025028  32.191330\n",
       "630  -167.645567   87.337485   -7.071331  -68.421152  33.665994\n",
       "631  -122.441795  186.571250   58.532000  -29.792016  10.931164\n",
       "632   -84.216053   47.266486  -16.130741  -66.323833  21.708991\n",
       "633  -185.718807   52.656030  -47.864196  -82.917178  40.998397\n",
       "634    29.939184  190.978357   63.334791   14.700392   4.731927\n",
       "635  -186.008461   51.874420  -47.623336  -82.305375  42.904648\n",
       "636  -192.473910   47.549273  -96.246564  -96.695689  25.276640\n",
       "637  -146.936408  130.720957   29.090613  -51.428590  23.394689\n",
       "638  -148.028737  143.998843  -21.843076  -59.521594   2.049165\n",
       "639  -172.462596   89.877931  -56.079231  -80.856913  14.100518\n",
       "640   -23.121101  126.310847   47.687353  -16.894464  21.111482\n",
       "641  -115.433853   14.044819  -54.781458  -82.986030  30.557352\n",
       "642  -116.863618  218.623561    3.082135  -32.322189 -16.817881\n",
       "643  -116.980413  218.308395    3.179256  -32.075494 -16.049231\n",
       "644  -150.000650  -21.662202 -147.270771 -103.881496  36.146217\n",
       "645    -2.646477  148.995948   -9.375333  -17.183903  -4.320652\n",
       "646    29.841075  190.713618   63.416373   14.907616   5.377593\n",
       "647   -45.699423   92.616910   15.305437  -43.009680  11.443758\n",
       "648  -115.415165   14.095245  -54.796997  -83.025502  30.434369\n",
       "649   -62.876692   79.332374   19.761512  -40.404722  32.533627\n",
       "650   -45.680735   92.667336   15.289897  -43.049152  11.320774\n",
       "651   -94.742447   42.767980  -14.453825  -57.352706  43.999750\n",
       "652  -122.343687  186.835989   58.450419  -29.999240  10.285498\n",
       "653  -210.649505   15.321434 -140.390091 -111.844055  29.639413\n",
       "654    -2.763273  148.680782   -9.278212  -16.937208  -3.552002\n",
       "655   -62.974801   79.067635   19.843094  -40.197498  33.179293\n",
       "656  -210.747614   15.056695 -140.308510 -111.636831  30.285079\n",
       "657  -115.531961   13.780080  -54.699876  -82.778807  31.203018\n",
       "658   -94.452793   43.549590  -14.694685  -57.964510  42.093499\n",
       "659  -172.752250   89.096321  -55.838371  -80.245109  16.006769\n",
       "660  -117.270067  217.526785    3.420116  -31.463691 -14.142980\n",
       "661  -172.364487   90.142670  -56.160812  -81.064137  13.454852\n",
       "662    29.957871  191.028784   63.319252   14.660921   4.608943\n",
       "663   -46.087185   91.570561   15.627878  -42.190653  13.995675\n",
       "664  -185.602011   52.971195  -47.961317  -83.163874  40.229747\n",
       "665  -147.930628  144.263582  -21.924658  -59.728817   1.403500\n",
       "666    -2.665165  148.945521   -9.359794  -17.144432  -4.197668\n",
       "667   -62.858005   79.382801   19.745973  -40.444193  32.410643\n",
       "668   -63.264454   78.286025   20.083954  -39.585695  35.085544\n",
       "669  -150.117445  -21.977367 -147.173650 -103.634801  36.914866\n",
       "670   -45.797531   92.352171   15.387018  -42.802457  12.089424\n",
       "671  -192.184257   48.330884  -96.487424  -97.307492  23.370389\n",
       "672   -94.354685   43.814329  -14.776267  -58.171734  41.447833\n",
       "673  -185.620698   52.920769  -47.945777  -83.124402  40.352731\n",
       "674   -91.451870  264.075966   76.450083   -1.703025  -8.193873\n",
       "675   -91.335074  264.391132   76.352962   -1.949720  -8.962523\n",
       "676  -172.345800   90.193096  -56.176352  -81.103608  13.331868\n",
       "677    -3.052927  147.899172   -9.037352  -16.325404  -1.645751\n",
       "678   -84.234741   47.216060  -16.115202  -66.284362  21.831975\n",
       "679   -84.332849   46.951321  -16.033620  -66.077138  22.477640\n",
       "680   -23.102413  126.361274   47.671813  -16.933935  20.988498\n",
       "681  -167.528771   87.652650   -7.168452  -68.667847  32.897344\n",
       "682  -150.407099  -22.758977 -146.932790 -103.022997  38.821117\n",
       "683   -84.622503   46.169710  -15.792760  -65.465334  24.383891\n",
       "684  -192.067461   48.646049  -96.584545  -97.554187  22.601739\n",
       "685  -115.821615   12.998470  -54.459016  -82.167003  33.109269\n",
       "686   -23.219209  126.046108   47.768934  -16.687240  21.757148\n",
       "687    29.551422  189.932008   63.657233   15.519420   7.283844\n",
       "688  -116.882305  218.573134    3.097674  -32.282718 -16.694897\n",
       "689  -147.911941  144.314008  -21.940197  -59.768289   1.280516\n",
       "690  -150.019337  -21.712628 -147.255231 -103.842025  36.269201\n",
       "691  -147.324170  129.674608   29.413054  -50.609563  25.946606\n",
       "692  -192.086148   48.595623  -96.569006  -97.514716  22.724723\n",
       "693  -146.917721  130.771383   29.075073  -51.468062  23.271705\n",
       "694  -167.547458   87.602224   -7.152912  -68.628376  33.020328\n",
       "695  -122.731449  185.789640   58.772860  -29.180213  12.837415\n",
       "696   -91.741524  263.294356   76.690943   -1.091221  -6.287622\n",
       "697    49.245083  -73.053303   -6.210673  -73.523376  29.081875\n",
       "698    49.226396  -73.103730   -6.195134  -73.483905  29.204859\n",
       "699    49.128288  -73.368468   -6.113552  -73.276681  29.850524\n",
       "700    48.838634  -74.150079   -5.872692  -72.664878  31.756775\n",
       "701    49.044864  -73.593581   -6.044182  -73.100475  30.399547\n",
       "702    70.470716  -71.277204    6.031382  -73.817231  20.635944\n",
       "703    70.452029  -71.327631    6.046921  -73.777760  20.758928\n",
       "704    70.353920  -71.592370    6.128503  -73.570536  21.404594\n",
       "705    70.064266  -72.373980    6.369363  -72.958732  23.310845\n",
       "706    70.270496  -71.817482    6.197873  -73.394329  21.953616\n",
       "707    90.007300  -73.400227   35.078574  -79.438434   9.146040\n",
       "708    89.988613  -73.450654   35.094113  -79.398963   9.269024\n",
       "709    89.890504  -73.715393   35.175695  -79.191739   9.914689\n",
       "710    89.600851  -74.497003   35.416555  -78.579935  11.820940\n",
       "711    89.807081  -73.940506   35.245065  -79.015533  10.463712\n",
       "712    -4.493965  -89.095117  115.204414  -92.765545  34.040248\n",
       "713    -4.592074  -89.359856  115.285996  -92.558321  34.685914\n",
       "714    51.807610  -67.975796   93.471129  -71.132886  27.200906\n",
       "715    51.709501  -68.240535   93.552710  -70.925662  27.846572\n",
       "716    59.679384  -37.227051   72.115881  -33.127357  50.531987\n",
       "717   225.708680    9.633490  -34.407303   13.600658  21.609252\n",
       "718   225.419026    8.851880  -34.166443   14.212462  23.515503\n",
       "719   149.800302  -31.525277   56.209955  -33.355701  15.847941\n",
       "720    37.408372  -75.208964  104.479398  -79.143198  27.229510\n",
       "721    37.302200  -75.550989  104.549270  -78.975869  27.412771\n",
       "722   271.920891    8.659238  176.441666   -1.594609  -3.990866\n",
       "723   271.911547    8.634024  176.449436   -1.574873  -3.929374\n",
       "724   271.892860    8.583598  176.464975   -1.535402  -3.806390\n",
       "725   271.860157    8.495352  176.492169   -1.466327  -3.591168\n",
       "726   271.794751    8.318859  176.546557   -1.328178  -3.160725\n",
       "727   307.762757    8.883460  169.753795   -2.786779 -30.423185\n",
       "728   307.730054    8.795214  169.780989   -2.717705 -30.207963\n",
       "729   307.664648    8.618722  169.835376   -2.579555 -29.777520\n",
       "730   307.374995    7.837111  170.076236   -1.967752 -27.871268\n",
       "731   307.581225    8.393609  169.904747   -2.403349 -29.228497\n",
       "732   307.581225    8.393609  169.904747   -2.403349 -29.228497\n",
       "733    97.119759  -33.202657  -12.740126  -29.142982  46.210785\n",
       "734    97.087057  -33.290903  -12.712932  -29.073908  46.426007\n",
       "735    97.021651  -33.467396  -12.658544  -28.935759  46.856450\n",
       "736    96.890839  -33.820381  -12.549769  -28.659460  47.717338\n",
       "737    96.731997  -34.249006  -12.417684  -28.323955  48.762702\n",
       "738    96.938227  -33.692508  -12.589174  -28.759552  47.405473\n",
       "739   131.149303  -24.436024  -18.382145  -20.528434  31.403904\n",
       "740   131.139960  -24.461238  -18.374375  -20.508699  31.465396\n",
       "741   131.121272  -24.511664  -18.358836  -20.469227  31.588380\n",
       "742   131.088569  -24.599910  -18.331642  -20.400153  31.803602\n",
       "743   131.023164  -24.776403  -18.277254  -20.262004  32.234046\n",
       "744    68.480204  -60.303149  -34.293215  -57.399779  33.755991\n",
       "745    68.480204  -60.303149  -34.293215  -57.399779  33.755991\n",
       "746    90.515820  -69.426335   29.424042  -74.361551  12.473696\n",
       "747    68.680424  -59.762871  -34.459707  -57.822680  32.438319\n",
       "748   135.367208  -36.498960   61.438113  -38.872455  17.157570\n",
       "749   135.269100  -36.763699   61.519695  -38.665231  17.803236\n",
       "750   126.400929  -75.874930   88.456713  -87.632071 -13.215133\n",
       "751    37.310263  -75.473703  104.560980  -78.935974  27.875175\n",
       "752    93.588772  -52.457147   77.849948  -55.235478  21.579213\n",
       "753    93.490663  -52.721886   77.931530  -55.028254  22.224879\n",
       "754    50.501464  -62.128510   76.523705  -63.066081  32.871872\n",
       "755    50.403356  -62.393249   76.605286  -62.858857  33.517537\n",
       "756    -4.618989  -89.152179  114.460210  -92.212390  34.498751\n",
       "757    52.665980  -64.208297   91.700545  -66.825123  32.485516\n",
       "758    52.567872  -64.473036   91.782126  -66.617899  33.131181\n",
       "759    52.278218  -65.254646   92.022986  -66.006095  35.037432\n",
       "760    66.814078  -31.551467 -115.053197  -19.625915  59.687232\n",
       "761    68.661736  -59.813297  -34.444167  -57.783209  32.561303\n",
       "762    68.563628  -60.078036  -34.362586  -57.575985  33.206969\n",
       "763    68.273974  -60.859646  -34.121726  -56.964182  35.113220\n",
       "764    90.497132  -69.476761   29.439581  -74.322079  12.596680\n",
       "765    90.399024  -69.741500   29.521163  -74.114855  13.242346\n",
       "766    90.109370  -70.523110   29.762023  -73.503052  15.148597\n",
       "767    90.315600  -69.966613   29.590534  -73.938649  13.791368\n",
       "768    90.315600  -69.966613   29.590534  -73.938649  13.791368\n",
       "769    44.287305  -55.883904  -28.449021  -51.327143  51.477507\n",
       "770    44.138475  -56.285510  -28.325262  -51.012787  52.456973\n",
       "771   294.177386    8.735220  172.490237   -1.699703 -16.530575\n",
       "772   271.505097    7.537249  176.787417   -0.716374  -1.254473\n",
       "773   271.711327    8.093746  176.615927   -1.151972  -2.611702\n",
       "774   271.711327    8.093746  176.615927   -1.151972  -2.611702\n",
       "775   307.781444    8.933887  169.738255   -2.826251 -30.546169\n",
       "776     9.108131  -83.708684  109.228763  -87.105728  32.251088\n",
       "777     9.010022  -83.973423  109.310345  -86.898504  32.896754\n",
       "778    93.320995  -50.157212   70.604849  -51.555821  24.702053\n",
       "779   139.046023  -13.762441  -37.962166   -7.598619  39.987195\n",
       "780   138.929227  -14.077606  -37.865045   -7.351924  40.755845\n",
       "781   138.639573  -14.859217  -37.624185   -6.740121  42.662096\n",
       "782   135.359145  -36.576247   61.426403  -38.912350  16.695166\n",
       "783   135.261036  -36.840986   61.507984  -38.705126  17.340831\n",
       "784     9.116194  -83.631397  109.240474  -87.065833  32.713492\n",
       "785    43.913366  -70.530053  -51.533975  -67.975554  35.095117\n",
       "786    43.815257  -70.794792  -51.452393  -67.768330  35.740783\n",
       "787    43.525604  -71.576402  -51.211533  -67.156526  37.647034\n",
       "788    43.731834  -71.019904  -51.383022  -67.592123  36.289805\n",
       "789    43.731834  -71.019904  -51.383022  -67.592123  36.289805\n",
       "790   294.377605    9.275498  172.323746   -2.122604 -17.848247\n",
       "791   294.358918    9.225072  172.339285   -2.083133 -17.725263\n",
       "792   294.326215    9.136825  172.366479   -2.014058 -17.510041\n",
       "793   294.260810    8.960333  172.420867   -1.875909 -17.079597\n",
       "794   293.971156    8.178723  172.661727   -1.264105 -15.173346\n",
       "795   294.177386    8.735220  172.490237   -1.699703 -16.530575\n",
       "796    66.174170  -46.705024  -22.171009  -42.322370  49.230968\n",
       "797    66.108764  -46.881516  -22.116621  -42.184221  49.661412\n",
       "798    66.025341  -47.106629  -22.047250  -42.008014  50.210434\n",
       "799    44.221899  -56.060397  -28.394633  -51.188993  51.907951\n",
       "800   149.792238  -31.602564   56.198244  -33.395595  15.385537\n",
       "801   225.825475    9.948655  -34.504424   13.353963  20.840602\n",
       "802   223.012868  -61.956960 -171.847387  -66.784559 -53.747323\n",
       "803   222.914760  -62.221698 -171.765805  -66.577335 -53.101658\n",
       "804    -1.136678   82.543813   -5.387125   90.513649  29.633744\n",
       "805  -156.081476  108.703771  -76.657203  115.607337 -20.655433\n",
       "806  -121.134048  101.901166   41.106822  110.702263  42.889521\n",
       "807  -153.862096   22.494281 -104.310135   31.324706  31.865290\n",
       "808  -147.289024   92.202096   36.874000   94.499392 -27.805356\n",
       "809    21.049110  112.518521   11.970516  114.959218 -31.919954\n",
       "810  -144.492524 -126.949852  -41.471612   73.147080  -1.527136\n",
       "811    25.308558  119.829549  -43.015339    5.450007  35.137479\n",
       "812   129.438869  -23.052226   40.085644  -20.339588  33.742853\n",
       "813  -132.811359   63.637837   29.530870   66.304927 -10.458285\n",
       "814  -129.250664  173.337401   87.137412  -33.266654  14.347987\n",
       "815    11.276394   74.988665  -74.871083  -48.023857 -18.582592\n",
       "816    49.556998  -30.470076   22.678059   87.296014  32.474164\n",
       "817  -122.896841 -108.441317   36.945910   99.844017   3.406691\n",
       "818  -172.510348   61.520233  -61.087987   65.415884 -19.625355\n",
       "819    11.632832  119.431391  -16.971712  125.791762   2.802914\n",
       "820    21.243809  120.174342  -95.847891  -18.103485  -1.609951\n",
       "821    58.119003  161.732352 -131.520916    4.489114 -11.130486\n",
       "822   -35.875593   56.743232 -141.167420   61.371612 -24.995649\n",
       "823   -49.714849   29.180676 -136.888287   38.225646  15.729862\n",
       "824   -92.240590  -84.867373   84.371428   86.278432  25.811127\n",
       "825  -130.685307  162.749176   94.746599  -49.860294  -7.874410\n",
       "826  -149.781795  126.685364  -65.980990  135.301558   5.144176\n",
       "827    15.247315  -62.675508 -102.593177   63.945970  18.020726\n",
       "828    46.541903  -23.725552  -76.391054  127.309862  39.601499\n",
       "829     0.365769   82.778988  -16.955338   86.868789  -3.949382\n",
       "830    21.630653  109.819870  -96.082369  -32.197108 -19.972482\n",
       "831    66.693455  -29.900808 -154.183156  139.479719  14.730047\n",
       "832  -189.240979  110.149434  -45.430252  113.222124 -30.252892\n",
       "833    42.685426  115.808573    6.393388  -11.965219  -0.535106\n",
       "834  -134.033967 -105.825691 -121.578276  127.234098  15.285852\n",
       "835    36.294729  -62.907950  -50.017179   67.086582  -1.994599\n",
       "836    38.998220  -49.117952  -93.878032  101.309000   9.463526\n",
       "837  -144.004613  124.944448   -0.065673  139.081924  28.186764\n",
       "838    -7.842226   47.411371  -89.556438  -54.742179  -0.921757\n",
       "839    31.482578  -27.780327  -61.993686  102.632311  48.509824\n",
       "840   -37.302681   52.869392 -123.419014   60.258292   9.186116\n",
       "841  -126.447188  164.449249  121.357213  -56.659551 -22.988948\n",
       "842  -158.834575  162.511583 -111.804224  -58.894932 -10.322820\n",
       "843   -24.192729   54.756569  -83.056260   59.198406 -10.337936\n",
       "844    34.253985  -44.948669 -154.772556   95.512011  26.644722\n",
       "845  -151.880101   48.138615  -51.531326   54.963318  10.463289\n",
       "846  -132.881933   85.865707   18.642001  -76.254754  -0.065123\n",
       "847   -28.753103   51.866565  -81.240784   60.309331  22.236083\n",
       "848   -31.939134   79.125895  -49.689529   95.461730  51.444109\n",
       "849    58.169527  -40.125467   65.342154   87.917199   7.697379\n",
       "850  -113.305728  110.844153  117.275369  -47.683700  21.765443\n",
       "851  -178.711879  127.716689 -158.737494  -64.644801  17.346328\n",
       "852    20.930804  -25.637875 -130.154765  108.431470  61.453791\n",
       "853  -164.959135  112.479644  -14.067163  -67.110235  17.310448\n",
       "854     8.085040   81.489739 -124.657539  -40.618298  -8.557003\n",
       "855  -115.710203 -105.766356   12.208305   24.066299  34.602219\n",
       "856  -128.396618   61.993197   87.830156   62.462093  -7.521722\n",
       "857  -150.308120   51.213434  -15.402830   57.204404  23.810525\n",
       "858  -182.387166  114.890503 -155.212734  -85.439538 -11.086018\n",
       "859    33.989387  -23.429863  -54.783506  121.468226  47.394482\n",
       "860  -161.460054   37.048409  -97.316782   42.348318  -8.635846\n",
       "861  -128.123070 -125.202611   13.158540   30.130362   4.009702\n",
       "862    37.403101  -36.568182 -157.182333  129.450118  26.138230\n",
       "863  -133.305965   34.982629   10.309303  -90.166603  11.930399\n",
       "864   -25.949366   61.803076  -40.681891   66.806171   9.432499\n",
       "865  -107.016769  -53.102783   -6.190634  177.343951  62.346591\n",
       "866  -100.327259  -88.267573  156.867920  118.935464   6.340002\n",
       "867     9.521797  -47.860899  -26.905551   60.621681  41.631595\n",
       "868  -140.911929   19.055201   -1.820863   22.468209   7.864120\n",
       "869  -141.250919  103.201399   86.683790  118.642665  -2.206855\n",
       "870   -29.288630   28.796282  -23.968827   30.115936 -12.254217\n",
       "871    19.052392  110.085804  -48.092972  -27.975157 -11.993403\n",
       "872    -2.151410   44.480173  -19.019905  -60.106065 -10.318076\n",
       "873    74.936735  -59.090130  -24.349294  -56.719158  26.605592\n",
       "874  -126.312229 -107.641845    5.239748   47.234844  29.102619\n",
       "875  -128.320004  154.712311  146.830935  -54.795864 -12.068500\n",
       "876  -177.908647   74.698081 -128.491162   83.608376  -1.397260\n",
       "877    21.100635  129.422430 -161.195128  -11.155241   2.224809\n",
       "878   -91.910096  -74.243929  123.405897   89.433168  40.680027\n",
       "879  -155.167228   78.962458 -116.430011  -73.546975  20.078979\n",
       "880  -141.228354 -109.774748   -3.412307   81.196166  23.174160\n",
       "881   -25.449297   51.251558  -36.073506   54.595749  -8.829315\n",
       "882    14.130703  109.106999  -46.727467  112.580753 -27.616523\n",
       "883    11.077331   44.843945  -15.222998  -90.700966 -42.713131\n",
       "884  -146.847116   62.801493    2.337883  -87.093637   8.130880\n",
       "885  -152.695078   34.147055   -7.670339   37.075577  -3.597210\n",
       "886  -153.245610 -116.232839 -148.649997   97.791181  21.750601\n",
       "887     0.786182   82.394424   35.657701   85.352047   1.582110\n",
       "888    23.434342  -70.937970  -25.428095   51.296283  -4.377752\n",
       "889    41.148475  106.434527   60.489400  -20.504523  -7.442880\n",
       "890  -149.072709  114.181954  -17.571448  119.650352  -4.503232\n",
       "891     5.325693   86.731437  -38.284128  -25.672492  15.865296\n",
       "892  -147.930969   54.459501    7.126483  -99.214994  -5.531296\n",
       "893  -151.967251 -102.505068 -151.723821  110.067734  43.050878\n",
       "894    53.260180  -67.136036  -12.178700  -64.711497  27.149501\n",
       "895  -170.085160   56.863611  -15.825824   59.121397 -18.916583\n",
       "896  -133.771596 -106.125624 -110.299483   63.569893  38.993563\n",
       "897   -29.982770   40.099471  -28.911655   44.420794   8.343283\n",
       "898  -143.051268  170.233753  -31.701515  192.493025  10.453646\n",
       "899  -179.229281  106.533614  -89.075122   52.728022   6.672467\n",
       "900  -116.826250  107.578793   79.521206  112.336546   5.849716\n",
       "901  -152.950786  157.853755  -57.177627  163.156933  -6.832388\n",
       "902  -160.241167  150.122970  -70.765958  141.883997  -6.415745\n",
       "903  -138.624482   94.079618   71.969351  181.715507  -7.017760\n",
       "904  -140.969749   38.964064   88.564964  167.537036  10.287019\n",
       "905  -150.509757  151.877284  -27.682602  156.841984  -6.569507\n",
       "906  -121.118784  -78.932456   97.643175  127.484169   7.265627\n",
       "907  -137.135075  146.930816    3.881874  213.368717  29.962349\n",
       "908  -136.194144  124.929607   30.947373  183.248096 -27.347426\n",
       "909   -86.695286   50.859239   58.245060  196.145503  28.970469\n",
       "910  -137.280090  145.467793    9.637933  209.273344  19.993663\n",
       "911   -32.145801   78.575096  -49.963714   95.704954  51.291536\n",
       "912    58.510149  -39.899506   65.385854   88.134867   7.935165\n",
       "913  -113.525396  111.189858  117.793776  -47.734035  21.742625\n",
       "914  -178.900629  128.226265 -158.620424  -64.596218  17.385240\n",
       "915    20.917018  -25.756580 -130.207910  107.923650  61.666734\n",
       "916  -164.990392  112.361013  -13.933910  -67.470631  16.833062\n",
       "917     8.363499   81.489289 -124.536831  -40.676823  -8.486838\n",
       "918  -116.022400 -105.680927   12.332516   24.061822  35.016172\n",
       "919  -128.236434   62.207226   87.905831   62.680632  -7.213278\n",
       "920  -150.438979   50.639973  -15.598666   57.304856  23.881901\n",
       "921  -181.871432  115.104895 -155.285027  -85.223501 -11.178134\n",
       "922    33.944256  -23.287249  -54.373338  121.437447  47.401706\n",
       "923  -161.362032   37.036027  -97.164100   42.290664  -8.495022\n",
       "924  -127.969787 -125.055901   12.917541   29.869234   4.238459\n",
       "925    37.766447  -36.769784 -157.458320  129.063436  25.860863\n",
       "926  -133.539341   34.732968   10.009134  -90.098414  12.256943\n",
       "927   -25.818889   61.542995  -40.263231   67.122310   9.908448\n",
       "928  -106.619066  -52.938760   -6.448140  177.426665  62.227567\n",
       "929  -100.655595  -88.541680  157.329668  118.938888   6.056283\n",
       "930     9.210333  -47.961764  -26.713014   60.086107  41.732214\n",
       "931  -140.790218   18.576639   -1.661160   22.006026   7.961710\n",
       "932  -141.410600  103.227939   86.708425  117.929816  -2.681975\n",
       "933   -29.340055   28.458199  -24.136833   30.644423 -12.332299\n",
       "934    18.986150  109.545088  -48.669742  -28.024994 -11.890367\n",
       "935    -2.100422   44.063344  -18.798634  -60.295575 -10.216167\n",
       "936    75.426262  -58.919187  -24.487328  -56.529780  26.457533\n",
       "937  -126.283189 -107.453851    5.947481   47.013866  29.276072\n",
       "938  -128.211969  154.551817  147.189953  -54.779409 -12.078664\n",
       "939  -178.220261   74.754765 -128.551172   83.081676  -1.533535\n",
       "940    20.696821  128.935380 -161.276444  -11.242500   2.458862\n",
       "941   -91.968714  -74.144504  123.929717   89.309366  40.955319\n",
       "942  -155.390666   79.365156 -116.074419  -73.520145  20.111209\n",
       "943  -141.407904 -109.637575   -3.310939   81.040518  23.551262\n",
       "944   -25.363317   51.650649  -36.076377   55.295378  -9.157724\n",
       "945    13.954634  109.146096  -46.761988  112.522720 -27.995616\n",
       "946    10.843149   44.586555  -15.524337  -90.636767 -42.432827\n",
       "947  -146.962884   62.616663    2.336279  -86.828632   8.463381\n",
       "948  -153.067792   34.026090   -7.407634   36.832853  -3.997754\n",
       "949  -153.244165 -116.339263 -148.908365   97.757646  21.792615\n",
       "950     0.941037   82.254903   36.287272   85.393175   1.471886\n",
       "951    23.414727  -71.173262  -25.275368   51.561042  -4.885104\n",
       "952    41.489098  106.660488   60.533100  -20.286855  -7.205094\n",
       "953  -148.804973  114.387463  -17.650249  120.232595  -4.483695\n",
       "954     5.394262   86.419834  -38.246249  -25.728708  15.957768\n",
       "955  -148.253042   54.304115    6.877182  -99.485880  -5.577842\n",
       "956  -151.517578 -102.331535 -151.622834  110.135955  42.924438\n",
       "957    52.939462  -67.154665  -12.485265  -64.697416  27.327604\n",
       "958  -169.666628   56.534270  -16.443215   58.982051 -18.984971\n",
       "959  -133.833984 -105.969206 -109.938478   63.523257  39.323903\n",
       "960   -29.727683   39.788886  -29.134235   44.293426   8.020099\n",
       "961    -1.236239   82.788387   -5.196697   90.499351  29.701439\n",
       "962  -156.221937  108.519102  -76.798872  115.395910 -20.969952\n",
       "963  -121.593408  101.935864   41.389509  110.869509  42.791909\n",
       "964  -154.376359   21.822217 -104.494062   31.340336  31.920049\n",
       "965  -147.346947   92.507491   37.112076   94.466354 -27.779386\n",
       "966    20.923266  112.215338   11.797261  115.067830 -32.016736\n",
       "967  -144.946015 -127.060778  -41.926054   72.937460  -1.200706\n",
       "968    24.868058  119.311626  -42.829559    4.995224  34.799250\n",
       "969   129.626137  -23.262182   39.984075  -20.632570  33.588586\n",
       "970  -133.068840   63.600122   30.009561   66.373392 -10.218769\n",
       "971  -129.507014  173.184895   87.096493  -33.071595  14.693458\n",
       "972    11.339472   74.741426  -74.623766  -48.107523 -18.612444\n",
       "973    49.429174  -30.565369   22.920748   86.738663  32.596862\n",
       "974  -123.007228 -108.596157   37.012581   99.560145   3.232322\n",
       "975  -172.496062   61.233812  -61.565448   65.241132 -19.438746\n",
       "976    11.358603  119.372638  -16.783631  125.380950   2.768283\n",
       "977    21.462472  120.387007  -95.888676  -18.132332  -1.546783\n",
       "978    58.151888  161.719124 -131.211856    4.427400 -11.009072\n",
       "979   -36.091138   56.577533 -140.992233   61.726867 -24.936245\n",
       "980   -49.648824   29.039763 -136.735087   37.509698  15.474242\n",
       "981   -92.663961  -85.082615   84.741078   86.484608  25.540572\n",
       "982  -131.119865  163.276046   94.974805  -49.784880  -7.729036\n",
       "983  -149.628418  126.814068  -66.085588  135.884642   5.105555\n",
       "984    15.294997  -62.733100 -102.717354   63.857383  18.104430\n",
       "985    46.420436  -23.577153  -76.550683  128.060632  39.526342\n",
       "986     0.830114   82.343739  -16.620306   86.773758  -4.043042\n",
       "987    21.146330  110.218556  -96.351182  -32.116033 -19.909760\n",
       "988    66.611955  -30.061948 -154.067211  138.832645  14.880980\n",
       "989  -188.988132  110.001299  -45.287757  113.502289 -29.906860\n",
       "990    43.135581  115.277409    6.033963  -12.156370  -0.794206\n",
       "991  -133.866354 -105.912569 -121.356541  127.186847  15.211923\n",
       "992    36.230381  -62.843130  -49.694043   66.732831  -1.833255\n",
       "993    39.452374  -48.914764  -93.696047  101.390533   9.614882\n",
       "994  -144.095281  125.245112   -0.120137  139.245400  28.734468\n",
       "995    -7.593041   47.259778  -89.975803  -54.956790  -0.992337\n",
       "996    31.607293  -27.772068  -62.467678  102.669693  48.344612\n",
       "997   -37.958640   52.650415 -123.872617   60.581991   9.349424\n",
       "998  -126.665060  164.287743  121.523825  -56.859725 -22.891056\n",
       "999  -158.702524  162.448526 -111.842633  -58.657279  -9.942463\n",
       "1000  -23.967349   54.487986  -83.204630   59.197239 -10.917843\n",
       "1001   34.429094  -44.974716 -155.120712   95.055992  26.651649\n",
       "1002 -152.353897   48.402649  -51.145431   54.438688  10.384346\n",
       "1003 -132.694183   85.769111   18.353645  -76.000665  -0.026214\n",
       "1004  -29.160409   51.746844  -81.101535   59.950307  21.446315"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "86238cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pca = lr.fit(x_pca,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "d2801f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-38\" type=\"checkbox\" checked><label for=\"sk-estimator-id-38\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "id": "a3cfe1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.989142</td>\n",
       "      <td>173.926739</td>\n",
       "      <td>54.157869</td>\n",
       "      <td>59.619453</td>\n",
       "      <td>57.51126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.989142</td>\n",
       "      <td>173.926739</td>\n",
       "      <td>54.157869</td>\n",
       "      <td>59.619453</td>\n",
       "      <td>57.51126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1          2          3         4\n",
       "2  79.989142  173.926739  54.157869  59.619453  57.51126\n",
       "3  79.989142  173.926739  54.157869  59.619453  57.51126"
      ]
     },
     "execution_count": 559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = df_pca[2:4]\n",
    "list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "cf069504",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_pca = lr_pca.predict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "b576437e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([36.19525088, 36.19525088])"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "07f07236",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "b516e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_r2 = r2_score(pre,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "88a05977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6568689250010493"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "82c0e93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_r2 = r2_score(y_pred,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "c8817265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6308931594712167"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48022117",
   "metadata": {},
   "source": [
    "# ann grid_search cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "99ddf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "rf_params = {\n",
    "'optimizer': ['adam','rmsprop'],\n",
    "#'activation': ['relu','tanh'],\n",
    "#'loss': ['mse','mae'],\n",
    "'batch_size': [16,32],\n",
    "#'neurons':[32,48],\n",
    "'epochs':[50,100],\n",
    "#'patience':[2,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f2300bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from skkeras import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "005d8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer = 'rmsprop', units = 16, learning_rate = 0.001):\n",
    "    ann = Sequential() # Initialising ANN\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding First Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding Second Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding Third Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = 1)) # Adding Output Layer   \n",
    "    ann.compile(optimizer = optimizer, loss = 'mean_absolute_error',metrics=['MeanSquaredLogarithmicError'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "546d4290",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_ann = KerasRegressor(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7ca9b445",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_ann = GridSearchCV(clf_ann, rf_params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6cb50ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE72A8D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE72A8D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE741FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE741FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153B9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153B9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7DA550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7DA550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7DAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7DAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153B280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153B280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA04DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA04DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC6753A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC6753A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75C6EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75C6EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7532CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7532CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3DCD3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3DCD3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE768E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE768E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6755E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6755E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2A953A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2A953A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6D6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6D6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA59280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA59280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC69C1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC69C1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB0D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB0D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A95F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A95F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6BBC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6BBC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC6751F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC6751F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE74C9F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE74C9F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED99E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED99E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA59DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA59DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE1546C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE1546C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC675160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC675160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE754B040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE754B040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB0DEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB0DEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC69C670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEC69C670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE1723700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE1723700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE74FE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE74FE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE292A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE292A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB0D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB0D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2A95E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2A95E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE754B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE754B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED935D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED935D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6755E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEC6755E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7532E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7532E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE15460D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE15460D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7532430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7532430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA04040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2B84040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2B84040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A52040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A52040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE1723DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE1723DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE74FEA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE74FEA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE145F3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE145F3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145F9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145F9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF1D7AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF1D7AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145FA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145FA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDA59160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA594C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDA594C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE1723CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE1723CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A95940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2A95940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754BA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE754BA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE740D8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE740D8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE1329F10&gt;,\n",
       "             param_grid={&#x27;batch_size&#x27;: [16, 32], &#x27;epochs&#x27;: [50, 100],\n",
       "                         &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE1329F10&gt;,\n",
       "             param_grid={&#x27;batch_size&#x27;: [16, 32], &#x27;epochs&#x27;: [50, 100],\n",
       "                         &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE1329F10&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE1329F10&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "             estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE1329F10>,\n",
       "             param_grid={'batch_size': [16, 32], 'epochs': [50, 100],\n",
       "                         'optimizer': ['adam', 'rmsprop']})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ann.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "4c46c3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7365670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7365670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73519D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73519D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2B37820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE2B37820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7365E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7365E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76460D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76460D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06DDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06DDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7646A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7646A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7356A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7356A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75C65E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75C65E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE728DCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE728DCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7423430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73654C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73654C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2B84670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2B84670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDAB7B0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDAB7B0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75724C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75724C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA9310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA9310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75725E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75725E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764FE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764FE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76469D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76469D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE762B700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE762B700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29C040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29C040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2B84670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE2B84670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7572E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7572430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7572430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA93A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA93A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1CA8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1CA8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3E3E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA9310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA9310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA94C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA94C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7625550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7423E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1A790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1A790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A06D430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0661F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0661F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAF040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAF040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0661F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0661F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06D8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06D8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75729D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75729D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE742E700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7351310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7351310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE153B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06D430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A06D430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7598160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE7598160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAF430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAF430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12DAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A147E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A147E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7572B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7572B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40EB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7625940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3708B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3708B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A7B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6BE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6BE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E8A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E8A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6B430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B49D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B49D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE73515E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76253A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE76253A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15279D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15279D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75A78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE153BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E6BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B4160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15271F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15271F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7351310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7351310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAF040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAF040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A147EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B41F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2B41F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3FA2CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE3FA2CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160BC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160BC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1527280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1527280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBC8700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBC8700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B40D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B40D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE764F1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1A790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC1A790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F42160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D53A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D53A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D5430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D5430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A3003A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A3003A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160BE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA160BE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F425E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F425E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163A4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75A7C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A3000D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A3000D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB18790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB18790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A211790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A211790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D5AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D5AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC85E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC85E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1551550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160BAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6BCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E6BCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D59D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D59D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2115E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2115E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D61F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D61F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D69D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D69D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB22700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB22700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19AE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F641F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F641F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1527700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1551310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0660D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0660D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15513A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15513A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163ACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D69D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D69D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8779D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8779D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F425E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F425E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77F7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77F7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBC8DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A211160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A211160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B370670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7356CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DEDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DEDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB22280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB22280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7ADC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7ADC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB22CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB22CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F64160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FDDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FDDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A0C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A066790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE762B940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB22F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB22F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE75D6700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED877A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15279D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15279D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2B4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE627E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17150D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17150D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7365700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77A05E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77A05E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA3EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA3EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77A08B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77A08B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A211820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4603A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4603A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A03A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A03A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1FD700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A65E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA37A65E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17154C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17154C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38AB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A12D5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F14C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F14C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B49E280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B49E280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A08B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77A08B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D58B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16D58B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "grid_ann_score=cross_val_score(grid_ann,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "e80bbb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -9.06809902,  -6.56144714,  -5.90325212, -10.48354626,\n",
       "        -6.00620031])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ann_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fc5f63fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mse_ann = np.mean(grid_ann_score**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b3754887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.68946510374334"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2543ee21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Results from Grid Search \n",
      "\n",
      " The best score across ALL searched params:\n",
      " -5.903486061096191\n",
      "\n",
      " The best parameters across ALL searched params:\n",
      " {'batch_size': 16, 'epochs': 100, 'optimizer': 'adam'}\n"
     ]
    }
   ],
   "source": [
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best score across ALL searched params:\\n\",grid_ann.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\",grid_ann.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174bd9b0",
   "metadata": {},
   "source": [
    "# ann random_search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "483d1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "ann_rand_params = {\n",
    "'optimizer': ['adam','rmsprop'],\n",
    "#'activation': ['relu','tanh'],\n",
    "#'loss': ['mse','mae'],\n",
    "'batch_size': [16,32],\n",
    "#'neurons':[32,48],\n",
    "'epochs':[50,100],\n",
    "#'patience':[2,5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "efdaaf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# from scikeras.wrappers import KerasRegressor\n",
    "# from skkeras import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e16ff9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_ann(optimizer = 'rmsprop', units = 16, learning_rate = 0.001):\n",
    "    ann = Sequential() # Initialising ANN\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding First Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding Second Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = units, activation = \"relu\")) # Adding Third Hidden Layer\n",
    "    ann.add(tf.keras.layers.Dense(units = 1)) # Adding Output Layer   \n",
    "    ann.compile(optimizer = optimizer, loss = 'mean_absolute_error',metrics=['MeanSquaredLogarithmicError'])\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f0845f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ann = KerasRegressor(build_fn=create_model_ann, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "e16667a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_ann1 = RandomizedSearchCV(rand_ann, ann_rand_params, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "0e050a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17158B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17158B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1B5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1B5040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38A9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A38A9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2DE5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F64E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA33A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA33A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4DC280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4DC280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A40D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A40D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D45E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D45E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4600D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4600D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FA3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163A3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DE0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE7598AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA9D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA9D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8D3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8D3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1715700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2DECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A300B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FA3160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA3F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA3F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7931F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7931F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F314C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F314C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CE75D6670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA9160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA9160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F308B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F308B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8DAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8DAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F30F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F30F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4DC700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B4DC700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED877DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8A160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16D5940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F31AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145FB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CE145FB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160B670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA160B670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38AAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38AAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F30EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F30EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBF2820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBF2820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E8DB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99E8DB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CDF256C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F315E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F315E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED793940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A45E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A45E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF24C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF24C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-23 {color: black;background-color: white;}#sk-container-id-23 pre{padding: 0;}#sk-container-id-23 div.sk-toggleable {background-color: white;}#sk-container-id-23 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-23 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-23 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-23 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-23 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-23 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-23 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-23 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-23 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-23 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-23 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-23 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-23 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-23 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-23 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-23 div.sk-item {position: relative;z-index: 1;}#sk-container-id-23 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-23 div.sk-item::before, #sk-container-id-23 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-23 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-23 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-23 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-23 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-23 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-23 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-23 div.sk-label-container {text-align: center;}#sk-container-id-23 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-23 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-23\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE7449B20&gt;,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [16, 32],\n",
       "                                        &#x27;epochs&#x27;: [50, 100],\n",
       "                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-67\" type=\"checkbox\" ><label for=\"sk-estimator-id-67\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE7449B20&gt;,\n",
       "                   param_distributions={&#x27;batch_size&#x27;: [16, 32],\n",
       "                                        &#x27;epochs&#x27;: [50, 100],\n",
       "                                        &#x27;optimizer&#x27;: [&#x27;adam&#x27;, &#x27;rmsprop&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-68\" type=\"checkbox\" ><label for=\"sk-estimator-id-68\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE7449B20&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-69\" type=\"checkbox\" ><label for=\"sk-estimator-id-69\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE7449B20&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000024CE7449B20>,\n",
       "                   param_distributions={'batch_size': [16, 32],\n",
       "                                        'epochs': [50, 100],\n",
       "                                        'optimizer': ['adam', 'rmsprop']})"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ann1.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1d8bf870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F31AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A300EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA95E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EA95E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8DA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99E8DA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B4DC280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F305E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F305E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F42E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA35E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2895E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2895E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED8F1310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCEF0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCEF0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16BA790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16BA790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B460940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80FCA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7A0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1715DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29C8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCEF430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB9F940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2724C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2724C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B40A040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BACA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA95E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EA95E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1738CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB9FF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADCA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADCA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A29CF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F39D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F39D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC08670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC08670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2720D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A2720D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBCDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBCDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2721F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2721F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB7AC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B40A940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA153F670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16453A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA16453A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA78034C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA78034C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F30550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F30550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A272C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A272C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC088B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC088B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADCD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B3A4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B460A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B460A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC08550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC08550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBCD790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBCD790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78034C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78034C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BA3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B49EF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED893A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED893A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED89DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED89DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F319D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F319D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A38A550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43B160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBCDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBCDA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78030D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78030D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F319D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F319D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED70700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED70700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED70D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED70D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780EA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B3A4E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDC08670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F23A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F23A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F2C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164BD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164BD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78039D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78039D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A272430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A272430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED898B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED898B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DD040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DD040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCEC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCEC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED39D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED39D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153F700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A1D4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A272160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17618B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17618B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B49E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA164B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7803A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43B670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43B670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED38B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E60D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E60D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFA670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFA670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB70D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB70D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8ED89700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153FA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA153FA60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9B43BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78031F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78031F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F23A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F23A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DDDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DDDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1761280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E3A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA14E6E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA14E6E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1500040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1500040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FACEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FACEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED80F820> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC080D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC080D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFA550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFA550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFAB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFAB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DDF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DDF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FB7430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780E430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9B43BDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19E1F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDADC430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FB78B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1761700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77DD9D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA164B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF7D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF7D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF74C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DD550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77DD550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15009D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15009D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19ED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19ED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EF01280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EF01280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCEDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCEDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA163AEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA8B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF79D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF79D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCE3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCE3790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7634C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7634C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2729D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A2729D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0F2D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EF01160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EF01160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FCE310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1645670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15FBB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA15FBB80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17851F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17851F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED953940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED953940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED726430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED726430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A14C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A14C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED953CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED953CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7634C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7634C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF73A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF73A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDBF20D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0F3B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCE310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCE310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7EAF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC4C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF9C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF9C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EE4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EE4940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA16BAD30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A19EC10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC084C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDC084C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDFA5E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17855E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA17855E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7639D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7639D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7268B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7268B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED726310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED726310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED726D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED726D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EDF7700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F304C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99F304C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA780E670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCED30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01AF0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB143A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB143A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB14E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB14E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA14E6160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDCE3C10> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED953CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED953CA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED726B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED726B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE43A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EE2BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EE2BF70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA7805940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA7805940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EE2B0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EE2B0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7260D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7260D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFAE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDFAE50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99ED3DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EF01160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF99D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EDF99D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7805430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7805430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919EE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB14790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB14790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99FAC040> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCE670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FCE670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA780EEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1785B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1785B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED763D30> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A1790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EE4B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99EE4B80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA78051F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA78051F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7805A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA7805A60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EEF4160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EEF4160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78053A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78053A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99EE4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A15E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A0A15E0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7633A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED7633A0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCE3940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDCE3940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FAC0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB148B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CEDB148B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA17FD280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CC2919F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CC2919F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA15FB280> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19ECA0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA1785670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED763DC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C9A0A1550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8ED70790> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE2BEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE2BEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78054C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA78054C0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EEF4430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EEF4430> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1667550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1667550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77D7550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CA77D7550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77D7F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA77D7F70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE6D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE6D700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1667160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1667160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE2B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C8EE2B310> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7268B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CED7268B0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED953940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CED953940> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C9A19EDC0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024C99F7E0D0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FACEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C99FACEE0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EEF4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EEF4670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CC2919550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EEF41F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024C8EEF41F0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x0000024CEDB14550> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x0000024CA1500E50> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "rand_ann1_score=cross_val_score(rand_ann1,X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "11b38cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-8.33716202, -5.154737  , -6.99299097, -4.84687901, -6.46030855])"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_ann1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "6c3a21ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.04186587977779"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "mse = np.mean(rand_ann1_score**2)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf7d5056",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 =LinearRegression()\n",
    "model2 =RandomForestRegressor()\n",
    "model3 =GradientBoostingRegressor()\n",
    "model4 =XGBRegressor()\n",
    "model5 =Ridge()\n",
    "model6 =Lasso()\n",
    "model7 =KNeighborsRegressor()\n",
    "model8 =AdaBoostRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857c41f",
   "metadata": {},
   "source": [
    "# Getting all models with accuracys in DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "12e21ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models =[]\n",
    "predictions = []\n",
    "r2_scores =[]\n",
    "all_models = [model1,model2,model3,model4,model5,model6,model7,model8]\n",
    "for mode in all_models:\n",
    "    model_all2=mode.fit(X, Y)\n",
    "    models.append(model_all2)-\n",
    "    y_predection2 =mode.predict(X_teX_testst)\n",
    "    predictions.append(y_predection2)\n",
    "    accuracy2=r2_score(Y_test,y_predection2)\n",
    "    r2_scores.append(accuracy2)\n",
    "final_DF = pd.DataFrame({'Name of model': models, 'predicted_value': predictions, 'r2_score': r2_scores})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "79206cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of model</th>\n",
       "      <th>predicted_value</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>[28.07098324527337, 10.42528168538626, 25.9860...</td>\n",
       "      <td>0.698813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeRegressor(max_features=1.0, rando...</td>\n",
       "      <td>[49.66796688266905, 10.4108196893454, 23.94352...</td>\n",
       "      <td>0.984112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>[48.60398304526231, 9.291089565794644, 24.9758...</td>\n",
       "      <td>0.936876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>[50.271072, 9.46352, 23.672647, 25.384586, 11....</td>\n",
       "      <td>0.991221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>[28.07097053172747, 10.425304104743766, 25.986...</td>\n",
       "      <td>0.698813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>[28.04953332220886, 10.559311997418632, 26.090...</td>\n",
       "      <td>0.698762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>[46.892641712, 11.403933040000002, 32.97625812...</td>\n",
       "      <td>0.810354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>[42.27636246339145, 19.93904750686794, 28.5966...</td>\n",
       "      <td>0.784383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of model   \n",
       "0                                 LinearRegression()  \\\n",
       "1  (DecisionTreeRegressor(max_features=1.0, rando...   \n",
       "2  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "3  XGBRegressor(base_score=None, booster=None, ca...   \n",
       "4                                            Ridge()   \n",
       "5                                            Lasso()   \n",
       "6                              KNeighborsRegressor()   \n",
       "7  (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "\n",
       "                                     predicted_value  r2_score  \n",
       "0  [28.07098324527337, 10.42528168538626, 25.9860...  0.698813  \n",
       "1  [49.66796688266905, 10.4108196893454, 23.94352...  0.984112  \n",
       "2  [48.60398304526231, 9.291089565794644, 24.9758...  0.936876  \n",
       "3  [50.271072, 9.46352, 23.672647, 25.384586, 11....  0.991221  \n",
       "4  [28.07097053172747, 10.425304104743766, 25.986...  0.698813  \n",
       "5  [28.04953332220886, 10.559311997418632, 26.090...  0.698762  \n",
       "6  [46.892641712, 11.403933040000002, 32.97625812...  0.810354  \n",
       "7  [42.27636246339145, 19.93904750686794, 28.5966...  0.784383  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a1dab",
   "metadata": {},
   "source": [
    "# for 2 rows of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4700b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "models1 =[]\n",
    "predictions1 = []\n",
    "r2_scores1 =[]\n",
    "all_models1 = [model1,model2,model3,model4,model5,model6,model7,model8]\n",
    "for mode in all_models1:\n",
    "    model_all1=mode.fit(X, Y)\n",
    "    models1.append(model_all1)\n",
    "    y_predection =mode.predict(abc)\n",
    "    predictions1.append(y_predection)\n",
    "    accuracy=r2_score(b,y_predection1)\n",
    "    r2_scores1.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5375b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = pd.DataFrame({'Name of model': models1, 'predicted_value': predictions1, 'r2_score': r2_scores1})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "486c28e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of model</th>\n",
       "      <th>predicted_value</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression()</td>\n",
       "      <td>[40.1476382660447, 40.1476382660447]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeRegressor(max_features=1.0, rando...</td>\n",
       "      <td>[40.51181899383486, 40.51181899383486]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>[40.275067929479086, 40.275067929479086]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBRegressor(base_score=None, booster=None, ca...</td>\n",
       "      <td>[40.34815, 40.34815]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ridge()</td>\n",
       "      <td>[40.147640125297755, 40.147640125297755]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lasso()</td>\n",
       "      <td>[40.15154284806479, 40.15154284806479]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNeighborsRegressor()</td>\n",
       "      <td>[36.8792438688, 36.8792438688]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeRegressor(max_depth=3, random_sta...</td>\n",
       "      <td>[47.70289552117337, 47.70289552117337]</td>\n",
       "      <td>-183.058809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of model   \n",
       "0                                 LinearRegression()  \\\n",
       "1  (DecisionTreeRegressor(max_features=1.0, rando...   \n",
       "2  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "3  XGBRegressor(base_score=None, booster=None, ca...   \n",
       "4                                            Ridge()   \n",
       "5                                            Lasso()   \n",
       "6                              KNeighborsRegressor()   \n",
       "7  (DecisionTreeRegressor(max_depth=3, random_sta...   \n",
       "\n",
       "                            predicted_value    r2_score  \n",
       "0      [40.1476382660447, 40.1476382660447] -183.058809  \n",
       "1    [40.51181899383486, 40.51181899383486] -183.058809  \n",
       "2  [40.275067929479086, 40.275067929479086] -183.058809  \n",
       "3                      [40.34815, 40.34815] -183.058809  \n",
       "4  [40.147640125297755, 40.147640125297755] -183.058809  \n",
       "5    [40.15154284806479, 40.15154284806479] -183.058809  \n",
       "6            [36.8792438688, 36.8792438688] -183.058809  \n",
       "7    [47.70289552117337, 47.70289552117337] -183.058809  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d0f96",
   "metadata": {},
   "source": [
    "# best scores for Random search cv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f78e13fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "models3 =[]\n",
    "predictions3 = []\n",
    "r2_scores3 =[]\n",
    "scores3 =[]\n",
    "all_models3 = [rand_rfr,rand_gbr,rand_dtr,rand_xgb,rand_ridge,rand_lasso,rand_ada]\n",
    "for mode in all_models3:\n",
    "    model_all3=mode.fit(X, Y)\n",
    "    models3.append(model_all3)\n",
    "    score=cross_val_score(mode,X,Y)\n",
    "    sco =score.mean()\n",
    "    scores3.append(sco)\n",
    "    y_predection3 =mode.predict(X_test)\n",
    "    predictions3.append(y_predection3)\n",
    "    accuracy3=r2_score(Y_test,y_predection3)\n",
    "    r2_scores3.append(accuracy3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "b4a1498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF1 = pd.DataFrame({'Name of model': all_models3, 'predicted_value': predictions3, 'cross_val_scores':scores3, 'r2_score': r2_scores3})    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "943a7675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=RandomForestRegressor(),\n",
       "                    param_distributions={'max_depth': [1, 2],\n",
       "                                         'min_samples_leaf': [1, 2],\n",
       "                                         'min_samples_split': [2, 4],\n",
       "                                         'n_estimators': [150, 200]}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=GradientBoostingRegressor(),\n",
       "                    param_distributions={'learning_rate': [0.01, 0.02],\n",
       "                                         'max_depth': [4, 6],\n",
       "                                         'n_estimators': [50, 100],\n",
       "                                         'subsample': [0.9, 0.5]}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=DecisionTreeRegressor(),\n",
       "                    param_distributions={'criterion': ['squared_error',\n",
       "                                                       'friedman_mse',\n",
       "                                                       'absolute_error'],\n",
       "                                         'max_depth': [1, 2, 3],\n",
       "                                         'min_samples_leaf': [1, 2, 3],\n",
       "                                         'min_samples_split': [2, 3, 4],\n",
       "                                         'splitter': ['best', 'random']}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, feature_types=None,\n",
       "                                           gamma=None, gpu_id=None,\n",
       "                                           grow_policy=None,\n",
       "                                           importance_type=N...\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           max_leaves=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints=None,\n",
       "                                           n_estimators=100, n_jobs=None,\n",
       "                                           num_parallel_tree=None,\n",
       "                                           predictor=None, random_state=None, ...),\n",
       "                    param_distributions={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                                         'learning_rate': [0.03, 0.05, 0.07],\n",
       "                                         'max_depth': [5, 6, 7],\n",
       "                                         'n_estimators': [100, 500, 1000],\n",
       "                                         'subsample': [0.7, 0.8, 0.9]}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=Ridge(),\n",
       "                    param_distributions={'alpha': [1, 0.1, 0.01, 0.0001],\n",
       "                                         'fit_intercept': [True, False],\n",
       "                                         'solver': ['cholesky', 'lsqr',\n",
       "                                                    'sparse_cg', 'sag']}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=Lasso(),\n",
       "                    param_distributions={'alpha': [1.0, 2.0],\n",
       "                                         'max_iter': [1000, 2000],\n",
       "                                         'selection': ['cyclic', 'random'],\n",
       "                                         'tol': [0.0001, 0.01]}),\n",
       " RandomizedSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "                    estimator=AdaBoostRegressor(),\n",
       "                    param_distributions={'learning_rate': [1.0, 2.0],\n",
       "                                         'loss': ['linear', 'square'],\n",
       "                                         'n_estimators': [50, 100]})]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b7c2845f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of model</th>\n",
       "      <th>predicted_value</th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[36.80033880795913, 18.92062191419552, 34.5524...</td>\n",
       "      <td>-0.086106</td>\n",
       "      <td>0.556429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[46.37971647324425, 14.82695952310154, 26.5592...</td>\n",
       "      <td>0.422520</td>\n",
       "      <td>0.931464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[40.23041156748905, 15.713853209477595, 25.996...</td>\n",
       "      <td>-0.103641</td>\n",
       "      <td>0.585869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[50.49613, 10.184825, 24.03848, 25.249578, 11....</td>\n",
       "      <td>0.543251</td>\n",
       "      <td>0.989523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[28.07097053172747, 10.425304104743766, 25.986...</td>\n",
       "      <td>0.622726</td>\n",
       "      <td>0.698813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[28.062072885252544, 10.58836057470942, 26.094...</td>\n",
       "      <td>0.623558</td>\n",
       "      <td>0.698674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomizedSearchCV(cv=KFold(n_splits=5, random...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.394753</td>\n",
       "      <td>0.808909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of model   \n",
       "0  RandomizedSearchCV(cv=KFold(n_splits=5, random...  \\\n",
       "1  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "2  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "3  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "4  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "5  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "6  RandomizedSearchCV(cv=KFold(n_splits=5, random...   \n",
       "\n",
       "                                     predicted_value  cross_val_scores   \n",
       "0  [36.80033880795913, 18.92062191419552, 34.5524...         -0.086106  \\\n",
       "1  [46.37971647324425, 14.82695952310154, 26.5592...          0.422520   \n",
       "2  [40.23041156748905, 15.713853209477595, 25.996...         -0.103641   \n",
       "3  [50.49613, 10.184825, 24.03848, 25.249578, 11....          0.543251   \n",
       "4  [28.07097053172747, 10.425304104743766, 25.986...          0.622726   \n",
       "5  [28.062072885252544, 10.58836057470942, 26.094...          0.623558   \n",
       "6  [41.822949018447055, 18.819611671471712, 27.05...          0.394753   \n",
       "\n",
       "   r2_score  \n",
       "0  0.556429  \n",
       "1  0.931464  \n",
       "2  0.585869  \n",
       "3  0.989523  \n",
       "4  0.698813  \n",
       "5  0.698674  \n",
       "6  0.808909  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_DF1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c951b1c",
   "metadata": {},
   "source": [
    "# best scores for grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "37c6e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "models4 =[]\n",
    "predictions4 = []\n",
    "r2_scores4 =[]\n",
    "scores4 =[]\n",
    "all_models4 = [clf,grid_GBR,grid_dtr,grid_xgb,Ridge_GS,grid_lasso,grid_ada]\n",
    "for mode in all_models4:\n",
    "    model_all4=mode.fit(X, Y)\n",
    "    models4.append(model_all4)\n",
    "    score1=cross_val_score(mode,X,Y)\n",
    "    sco1 =score1.mean()\n",
    "    scores4.append(sco1)\n",
    "    y_predection4 =mode.predict(X_test)\n",
    "    predictions4.append(y_predection3)\n",
    "    accuracy4=r2_score(Y_test,y_predection4)\n",
    "    r2_scores4.append(accuracy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "783d8b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF2 = pd.DataFrame({'Name of model': models4, 'predicted_value': predictions4, 'cross_val_scores':scores4, 'r2_score': r2_scores4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "810494ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=RandomForestRegressor(),\n",
       "              param_grid={'max_depth': [1, 2], 'min_samples_leaf': [1, 2],\n",
       "                          'min_samples_split': [2, 4],\n",
       "                          'n_estimators': [150, 200]}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=GradientBoostingRegressor(),\n",
       "              param_grid={'learning_rate': [0.01, 0.02], 'max_depth': [4, 6],\n",
       "                          'n_estimators': [50, 100], 'subsample': [0.9, 0.5]}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=DecisionTreeRegressor(),\n",
       "              param_grid={'criterion': ['squared_error', 'friedman_mse',\n",
       "                                        'absolute_error'],\n",
       "                          'max_depth': [1, 2, 3], 'min_samples_leaf': [1, 2, 3],\n",
       "                          'min_samples_split': [2, 3, 4],\n",
       "                          'splitter': ['best', 'random']}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None, gpu_id=None,\n",
       "                                     grow_policy=None, importance_type=None,\n",
       "                                     in...\n",
       "                                     max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                     max_depth=None, max_leaves=None,\n",
       "                                     min_child_weight=None, missing=nan,\n",
       "                                     monotone_constraints=None, n_estimators=100,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     predictor=None, random_state=None, ...),\n",
       "              param_grid={'colsample_bytree': [0.7, 0.8, 0.9],\n",
       "                          'learning_rate': [0.03, 0.05, 0.07],\n",
       "                          'max_depth': [5, 6, 7],\n",
       "                          'n_estimators': [100, 500, 1000],\n",
       "                          'subsample': [0.7, 0.8, 0.9]}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=Ridge(),\n",
       "              param_grid={'alpha': [1, 0.1, 0.01, 0.0001],\n",
       "                          'fit_intercept': [True, False],\n",
       "                          'solver': ['cholesky', 'lsqr', 'sparse_cg', 'sag']}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=Lasso(),\n",
       "              param_grid={'alpha': [1.0, 2.0], 'max_iter': [1000, 2000],\n",
       "                          'selection': ['cyclic', 'random'],\n",
       "                          'tol': [0.0001, 0.01]}),\n",
       " GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "              estimator=AdaBoostRegressor(),\n",
       "              param_grid={'learning_rate': [1.0, 2.0],\n",
       "                          'loss': ['linear', 'square'],\n",
       "                          'n_estimators': [50, 100]})]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "814f9b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name of model</th>\n",
       "      <th>predicted_value</th>\n",
       "      <th>cross_val_scores</th>\n",
       "      <th>r2_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>-0.066565</td>\n",
       "      <td>0.556407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.421012</td>\n",
       "      <td>0.925880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>-0.103641</td>\n",
       "      <td>0.585869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.586187</td>\n",
       "      <td>0.987829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.623019</td>\n",
       "      <td>0.698813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.624198</td>\n",
       "      <td>0.698687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GridSearchCV(cv=KFold(n_splits=5, random_state...</td>\n",
       "      <td>[41.822949018447055, 18.819611671471712, 27.05...</td>\n",
       "      <td>0.434815</td>\n",
       "      <td>0.801939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name of model   \n",
       "0  GridSearchCV(cv=KFold(n_splits=5, random_state...  \\\n",
       "1  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "2  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "3  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "4  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "5  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "6  GridSearchCV(cv=KFold(n_splits=5, random_state...   \n",
       "\n",
       "                                     predicted_value  cross_val_scores   \n",
       "0  [41.822949018447055, 18.819611671471712, 27.05...         -0.066565  \\\n",
       "1  [41.822949018447055, 18.819611671471712, 27.05...          0.421012   \n",
       "2  [41.822949018447055, 18.819611671471712, 27.05...         -0.103641   \n",
       "3  [41.822949018447055, 18.819611671471712, 27.05...          0.586187   \n",
       "4  [41.822949018447055, 18.819611671471712, 27.05...          0.623019   \n",
       "5  [41.822949018447055, 18.819611671471712, 27.05...          0.624198   \n",
       "6  [41.822949018447055, 18.819611671471712, 27.05...          0.434815   \n",
       "\n",
       "   r2_score  \n",
       "0  0.556407  \n",
       "1  0.925880  \n",
       "2  0.585869  \n",
       "3  0.987829  \n",
       "4  0.698813  \n",
       "5  0.698687  \n",
       "6  0.801939  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78227de5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
